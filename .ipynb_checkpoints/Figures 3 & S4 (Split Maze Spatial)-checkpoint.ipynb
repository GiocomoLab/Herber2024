{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0bf253f9",
   "metadata": {},
   "source": [
    "# Setup for Figure 3 & S4A-C, E (right), G, I (Split Maze)\n",
    "\n",
    "Note exact results for K-Means based analysis will change slightly each time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "65739ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' magic 4u'''\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e61fd4ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Get Stuff You Need'''\n",
    "import numpy as np\n",
    "import math as math\n",
    "from tqdm import tnrange\n",
    "from tqdm.notebook import tqdm as tdqm\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams.update(mpl.rcParamsDefault)\n",
    "from matplotlib import gridspec\n",
    "from scipy.interpolate import interp1d\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "from scipy import stats\n",
    "import scipy.io\n",
    "import scipy.ndimage.filters as filt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from pipeline import get_data as get\n",
    "from pipeline import process_spikes as ps\n",
    "\n",
    "from statsmodels.tsa.stattools import acf\n",
    "from scipy.signal import find_peaks\n",
    "from itertools import combinations\n",
    "\n",
    "from matplotlib import rc \n",
    "mpl.rcParams['font.sans-serif'] = 'Arial'\n",
    "mpl.rcParams['font.family'] = 'sans-serif'\n",
    "mpl.rcParams['svg.fonttype'] = 'none'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ecfac020",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Define some functions for later '''\n",
    "def count_consec(lst):\n",
    "    consec = [1]\n",
    "    for x, y in zip(lst, lst[1:]):\n",
    "        if x == y - 1:\n",
    "            consec[-1] += 1\n",
    "        else:\n",
    "            consec.append(1)\n",
    "    return consec\n",
    "\n",
    "def tuning_curve_bytrial(x, trial, Y, dt, b, sigma, smooth=True, normalize=False, occupancy=True):\n",
    "    '''\n",
    "    Params\n",
    "    ------\n",
    "    x : ndarray\n",
    "        variable of interest by observation; shape (n_obs, )\n",
    "    trial : ndarray\n",
    "        trial num for each observation; shape (n_obs, )\n",
    "    Y : ndarray\n",
    "        spikes per observation; shape (n_obs, n_cells)\n",
    "    dt : int\n",
    "        time per observation in seconds\n",
    "    b : int\n",
    "        bin size\n",
    "    sigma : int\n",
    "        SD of Gaussian filter\n",
    "    smooth : bool\n",
    "        apply gaussian filter to firing rate; optional, default is True\n",
    "    normalize : bool\n",
    "        normalize the firing rate of each cell such that its max FR is 1, min is 0;\n",
    "        optional, default is False\n",
    "    occupancy : bool\n",
    "        return occupancy (dwell time in each bin); optional, default is True\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    firing_rate : ndarray\n",
    "        binned firing rate for each trial for each cell; shape (n_trials, n_bins, n_cells)\n",
    "    centers : ndarray\n",
    "        center of each bin\n",
    "    occ : ndarray\n",
    "       dwell time in each bin; shape (n_bins, n_cells)\n",
    "    '''\n",
    "    edges = np.arange(0, np.max(x) + b, b)\n",
    "    centers = (edges[:-1] + edges[1:])/2\n",
    "    b_idx = np.digitize(x, edges)\n",
    "    if np.max(x) == edges[-1]:\n",
    "        b_idx[b_idx==np.max(b_idx)] = np.max(b_idx) - 1\n",
    "    unique_bdx = np.unique(b_idx)\n",
    "\n",
    "    # find FR in each bin\n",
    "    firing_rate = np.zeros((np.unique(trial).shape[0], unique_bdx.shape[0], Y.shape[1]))\n",
    "    occ = np.zeros((np.unique(trial).shape[0], unique_bdx.shape[0], Y.shape[1]))\n",
    "    for j in range(unique_bdx.shape[0]):\n",
    "        idx1 = (b_idx == unique_bdx[j])\n",
    "        for i, t in enumerate(np.unique(trial)):\n",
    "            idx = idx1 & (trial == t)\n",
    "            if np.sum(idx)==0:\n",
    "                #print('warning: zero occupancy!')\n",
    "                firing_rate[i, j, :] = firing_rate[i, j-1, :]\n",
    "                occ[i, j, :] = 0\n",
    "            else:    \n",
    "                spike_ct = np.sum(Y[idx, :], axis=0)\n",
    "                occupancy = dt * np.sum(idx)\n",
    "                occ[i, j, :] = occupancy\n",
    "                firing_rate[i, j, :] = spike_ct / occupancy\n",
    "    if smooth:\n",
    "        firing_rate = gaussian_filter1d(firing_rate, sigma, axis=1, mode='wrap')\n",
    "\n",
    "    if normalize:\n",
    "        for c in range(firing_rate.shape[2]):\n",
    "            firing_rate[:, :, c] = (firing_rate[:, :, c] - np.min(firing_rate[:, :, c]))/np.max(firing_rate[:, :, c] - np.min(firing_rate[:, :, c]))\n",
    "    \n",
    "    if occupancy:\n",
    "        return firing_rate, centers, occ\n",
    "    else: \n",
    "        return firing_rate, centers\n",
    "    \n",
    "def find8adjacentElements(test_list):\n",
    "    ''' \n",
    "    Params\n",
    "    ------\n",
    "    test_list : ndarray\n",
    "        1d array to be sorted\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    neighbors : list\n",
    "        nested list where each element is a list of 8 adjacent elements to the element with the same \n",
    "        index in test_list, adjusting for the first and last four elements and not including \n",
    "    '''\n",
    "    \n",
    "    neighbors = []\n",
    "    for idx, ele in enumerate(test_list):\n",
    "    # Checking for all cases to append\n",
    "        if idx == 0:\n",
    "            neighbors.append(test_list[(idx+1):(idx + 9)])\n",
    "        elif idx == 1:\n",
    "            neighbors.append(np.concatenate((test_list[(idx - 1)],test_list[(idx+1):(idx + 8)]),axis=None))\n",
    "        elif idx == 2:\n",
    "            neighbors.append(np.concatenate((test_list[:idx],test_list[(idx+1):(idx + 7)]),axis=None))\n",
    "        elif idx == 3:\n",
    "            neighbors.append(np.concatenate((test_list[:idx],test_list[(idx+1):(idx + 6)]),axis=None))\n",
    "        elif idx == len(test_list) - 1:\n",
    "            neighbors.append(np.concatenate((test_list[(idx-8):idx]),axis=None))                     \n",
    "        elif idx == len(test_list) - 2:\n",
    "            neighbors.append(np.concatenate((test_list[(idx-7):idx],test_list[(idx + 1):]),axis=None))\n",
    "        elif idx == len(test_list) - 3:\n",
    "            neighbors.append(np.concatenate((test_list[(idx-6):idx],test_list[(idx + 1):]),axis=None))\n",
    "        elif idx == len(test_list) - 4:\n",
    "            neighbors.append(np.concatenate((test_list[(idx-5):idx],test_list[(idx + 1):]),axis = None))\n",
    "        else:\n",
    "            neighbors.append(np.concatenate((test_list[(idx - 4):idx],test_list[(idx+1):(idx + 5)]),axis=None))\n",
    "    return neighbors \n",
    "\n",
    "def find(x):\n",
    "    return x.nonzero()[0]\n",
    "\n",
    "def circ_autocorr(x):\n",
    "    Fx = np.fft.fft(x)\n",
    "    Fxp = np.conj(np.fft.fft(x))\n",
    "    return np.roll(np.fft.ifft(Fx * Fxp).real, x.size // 2)\n",
    "\n",
    "def ar1_acf(nt, phi, sigma2):\n",
    "    \"\"\"\n",
    "    Computes the theoretical autocorrelation function for an AR(1) model.\n",
    "    This serves as our null distribution for computing significance\n",
    "    \n",
    "    Params:\n",
    "    -------\n",
    "    nt : number of timesteps\n",
    "    phi : autoregressive coefficient\n",
    "    sigma2 : variance of gaussian noise\n",
    "    \"\"\"\n",
    "    return (phi ** np.arange(nt)) * sigma2 / (1 - phi ** 2)\n",
    "\n",
    "def autocorr(x,lags):\n",
    "    '''numpy.correlate'''\n",
    "    mean=x.mean()\n",
    "    var=np.var(x)\n",
    "    xp=x-mean\n",
    "    corr=np.correlate(xp,xp,'full')[len(x)-1:]/var/len(x)\n",
    "\n",
    "    return corr[:len(lags)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a8847f53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Animal_ID</th>\n",
       "      <th>Task</th>\n",
       "      <th>Cohort</th>\n",
       "      <th>Probe_Control</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Sac_Date</th>\n",
       "      <th>Frozen_Hemisphere</th>\n",
       "      <th>DOB</th>\n",
       "      <th>Age_WholeMonth</th>\n",
       "      <th>Age_ExtraDays</th>\n",
       "      <th>...</th>\n",
       "      <th>Aged_Days</th>\n",
       "      <th>Age_Group</th>\n",
       "      <th>Behavior_Sessions</th>\n",
       "      <th>Neural_Sessions</th>\n",
       "      <th>Total_Cells</th>\n",
       "      <th>visualacuity</th>\n",
       "      <th>perchangespeedgain</th>\n",
       "      <th>perchangekurt</th>\n",
       "      <th>perchangeskew</th>\n",
       "      <th>perchangeIQR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A3</td>\n",
       "      <td>RF</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "      <td>F</td>\n",
       "      <td>1/27/2021</td>\n",
       "      <td>R</td>\n",
       "      <td>4/23/2019</td>\n",
       "      <td>21</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>645</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>1540.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.367862</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A4</td>\n",
       "      <td>RF</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "      <td>F</td>\n",
       "      <td>1/27/2021</td>\n",
       "      <td>R</td>\n",
       "      <td>4/23/2019</td>\n",
       "      <td>21</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>645</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>1574.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22.050636</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A5</td>\n",
       "      <td>RF</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "      <td>F</td>\n",
       "      <td>4/6/2021</td>\n",
       "      <td>L</td>\n",
       "      <td>4/23/2019</td>\n",
       "      <td>23</td>\n",
       "      <td>14</td>\n",
       "      <td>...</td>\n",
       "      <td>714</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>1002.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21.328531</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A6</td>\n",
       "      <td>RF</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "      <td>F</td>\n",
       "      <td>4/6/2021</td>\n",
       "      <td>R</td>\n",
       "      <td>4/23/2019</td>\n",
       "      <td>23</td>\n",
       "      <td>14</td>\n",
       "      <td>...</td>\n",
       "      <td>714</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>985.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.687094</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A7</td>\n",
       "      <td>RF</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "      <td>F</td>\n",
       "      <td>4/19/2021</td>\n",
       "      <td>L</td>\n",
       "      <td>5/29/2019</td>\n",
       "      <td>22</td>\n",
       "      <td>21</td>\n",
       "      <td>...</td>\n",
       "      <td>691</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>1691.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>52.102357</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Animal_ID Task Cohort  Probe_Control Sex   Sac_Date Frozen_Hemisphere  \\\n",
       "0        A3   RF      A              0   F  1/27/2021                 R   \n",
       "1        A4   RF      A              0   F  1/27/2021                 R   \n",
       "2        A5   RF      A              0   F   4/6/2021                 L   \n",
       "3        A6   RF      A              0   F   4/6/2021                 R   \n",
       "4        A7   RF      A              0   F  4/19/2021                 L   \n",
       "\n",
       "         DOB  Age_WholeMonth  Age_ExtraDays  ...  Aged_Days  Age_Group  \\\n",
       "0  4/23/2019              21              4  ...        645          3   \n",
       "1  4/23/2019              21              4  ...        645          3   \n",
       "2  4/23/2019              23             14  ...        714          3   \n",
       "3  4/23/2019              23             14  ...        714          3   \n",
       "4  5/29/2019              22             21  ...        691          3   \n",
       "\n",
       "   Behavior_Sessions  Neural_Sessions  Total_Cells  visualacuity  \\\n",
       "0                  6                6       1540.0           NaN   \n",
       "1                  6                6       1574.0           NaN   \n",
       "2                  6                6       1002.0           NaN   \n",
       "3                  6                6        985.0           NaN   \n",
       "4                  6                6       1691.0           NaN   \n",
       "\n",
       "   perchangespeedgain  perchangekurt  perchangeskew  perchangeIQR  \n",
       "0           17.367862            NaN            NaN           NaN  \n",
       "1           22.050636            NaN            NaN           NaN  \n",
       "2           21.328531            NaN            NaN           NaN  \n",
       "3           15.687094            NaN            NaN           NaN  \n",
       "4           52.102357            NaN            NaN           NaN  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' Load Animal Metadata '''\n",
    "#adjust path\n",
    "\n",
    "animalmeta = pd.read_csv('C:/Users/Python/Desktop/LocalData/animalmeta.csv')\n",
    "animalmeta.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7bacbb42",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Find names of specific animals groups'''\n",
    "all_aged_mice = np.array(animalmeta.loc[(animalmeta.Age_Group == 3),'Animal_ID'])\n",
    "all_MA_mice = np.array(animalmeta.loc[(animalmeta.Age_Group == 2),'Animal_ID'])\n",
    "all_young_mice = np.array(animalmeta.loc[(animalmeta.Age_Group == 1),'Animal_ID'])\n",
    "\n",
    "cohorta_mice = np.array(animalmeta.loc[(animalmeta.Cohort == 'A'),'Animal_ID'])\n",
    "cohortb_mice = np.array(animalmeta.loc[(animalmeta.Cohort == 'B'),'Animal_ID'])\n",
    "cohortc_mice = np.array(animalmeta.loc[(animalmeta.Cohort == 'C'),'Animal_ID'])\n",
    "cohortd_mice = np.array(animalmeta.loc[(animalmeta.Cohort == 'D'),'Animal_ID'])\n",
    "\n",
    "RF_aged_mice = np.array(animalmeta.loc[(animalmeta.Age_Group == 3) & (animalmeta.Task == 'RF'),'Animal_ID'])\n",
    "RF_young_mice = np.array(animalmeta.loc[(animalmeta.Age_Group == 1) & (animalmeta.Task == 'RF'),'Animal_ID'])\n",
    "SM_aged_mice = np.array(animalmeta.loc[(animalmeta.Age_Group == 3) & (animalmeta.Task == 'SM'),'Animal_ID'])\n",
    "SM_MA_mice = np.array(animalmeta.loc[(animalmeta.Age_Group == 2) & (animalmeta.Task == 'SM'),'Animal_ID'])\n",
    "SM_young_mice = np.array(animalmeta.loc[(animalmeta.Age_Group == 1) & (animalmeta.Task == 'SM'),'Animal_ID'])\n",
    "\n",
    "all_female_mice = np.array(animalmeta.loc[(animalmeta.Sex == 'F'),'Animal_ID'])\n",
    "all_male_mice = np.array(animalmeta.loc[(animalmeta.Sex == 'M'), 'Animal_ID'])\n",
    "RF_female_mice = np.array(animalmeta.loc[(animalmeta.Sex == 'F') & (animalmeta.Task == 'RF'),'Animal_ID'])\n",
    "RF_male_mice = np.array(animalmeta.loc[(animalmeta.Sex == 'M') & (animalmeta.Task == 'RF'),'Animal_ID'])\n",
    "SM_female_mice = np.array(animalmeta.loc[(animalmeta.Sex == 'F') & (animalmeta.Task == 'SM'),'Animal_ID'])\n",
    "SM_male_mice = np.array(animalmeta.loc[(animalmeta.Sex == 'M') & (animalmeta.Task == 'SM'),'Animal_ID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "03eeac98",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Complete List of Mice & Sessions for Neural Data '''\n",
    "all_mice = np.array(animalmeta.Animal_ID)\n",
    "\n",
    "all_sessions = ([['0122_record1','0123_record2','0124_record3','0125_record4','0126_record5','0127_record6'], \n",
    "             ['0122_record1','0123_record2','0124_record3','0125_record4','0126_record5','0127_record6'],\n",
    "             ['0401_record1','0401_record2b','0403_record3','0404_record4','0405_record5','0406_record6'],\n",
    "             ['0401_record1','0402_record2','0403_record3','0404_record4','0405_record5','0406_record6'],\n",
    "             ['0414_record1','0415_record2','0416_record3','0417_record4','0418_record5','0419_record6'],\n",
    "             ['1024_record1','1025_record2','1026_record3','1027_record4','1028_record5_2'], #Y2_6 excluded\n",
    "             ['1016_record1','1019_record3','1020_record4','1021_record5','1022_record6'], #Y3_2 not collected\n",
    "             ['1114_record1','1115_record2','1116_record3','1117_record4','1118_record5','1119_record6'], # end cohort A\n",
    "             ['051822_record1','051922_record2', '052022_record3','052122_record4','052222_record5','052322_record6'], \n",
    "             ['050522_record1','050622_record2','050722_record3','050822_record4','050922_record5','051022_record6'],\n",
    "             ['050522_record1','050622_record2','050722_record3','050822_record4','051022_record6'], #Y11_5 not collected\n",
    "             ['062222_record3','062322_record4','062522_record5'], #Y16_1 & 2 not collected, neural _6 excluded\n",
    "             ['062822_record1','062922_record2','063022_record3','070122_record4','070222_record5','070322_record6'],\n",
    "             ['062022_record1','062122_record2','062222_record3','062322_record4','062522_record5','062622_record6'],\n",
    "             ['062822_record1','062922_record2','063022_record3','070122_record4','070222_record5','070322_record6'], \n",
    "             ['051922_record2','052022_record3'], # Y9 051822_record excluded for syncing issue, end cohort B\n",
    "             ['083022_record1','083122_record2','090122_record3'], \n",
    "             ['083022_record1','083122_record2','090122_record3','090222_record4','090322_record5','090422_record6'],\n",
    "             ['083022_record1','083122_record2','090122_record3','090222_record4'], #behavior of A16_4, both of 5 excluded, 6 not collected \n",
    "             ['082322_record1','082422_record2','082522_record3','082622_record4','082722_record5','082822_record6'],\n",
    "             ['082322_record1real','082422_record2','082522_record3','082622_record4','082722_record5','082822_record6'],\n",
    "             ['102322_record1','102422_record2','102522_record3','102622_record4','102722_record5','102822_record6'],\n",
    "             ['102322_record1','102422_record2','102522_record3','102622_record4','102722_record5','102822_record6'],\n",
    "             ['102322_record1','102422_record2','102522_record3','102622_record4','102722_record5','102822_record6'],\n",
    "             ['103122_record2','110122_record3','110222_record4','110322_record5rep','110422_record6','110522_record7'], #behavior of MA4M6, 7 excluded\n",
    "             ['110622_record1','110722_record2','110822_record3','110922_record4','111022_record5','111122_record6'],\n",
    "             ['103022_record1','103122_record2','110122_record3','110222_record4','110322_record5','110422_record6'],\n",
    "             ['103022_record1','103122_record2','110122_record3','110222_record4'], #behavior of MA7_4, both 5 excluded, 6 not collected\n",
    "             ['111322_record1','111422_record2','111522_record3','111622_record4','111722_record5','111822_record6'],\n",
    "             ['111322_record1','111422_record2','111522_record3','111622_record4','111722_record5','111822_record6'],\n",
    "             ['111322_record1','111422_record2','111522_record3','111622_record4','111722_record5','111822_record6'], \n",
    "             ['092522_record1','092622_record2','092722_record3','092822_record4','092922_record5','093022_record6'],\n",
    "             ['091822_record1','091922_record2','092022_record3','092122_record4','092222_record5','092322_record6'],\n",
    "             ['092522_record1','092622_record2','092722_record3','092822_record4','092922_record5','093022_record6'],\n",
    "             ['092522_record1','092622_record2','092722_record3','092822_record4','092922_record5','093022_record6'],\n",
    "             ['091822_record1','091922_record2','092022_record3','092122_record4','092222_record5','092322_record6'], #end cohortc\n",
    "             ['012723_record2','012823_record3','012923_record4','013023_record5','013123_record6','020123_record7'],\n",
    "             ['012623_record1','012723_record2','012823_record3','012923_record4','013023_record5','013123_record6'],\n",
    "             ['012923_record2','013023_record3','013123_record4','020123_record5','020223_record6','020323_record7'],\n",
    "             ['020923_record1','021023_record2','021123_record3','021223_record4','021323_record5','021423_record6'],\n",
    "             ['022623_record1','022723_record2','022823_record3','030123_record4','030223_record5','030323_record6'],\n",
    "             ['021623_record1','021723_record2','021823_record3','021923_record4','022023_record5','022123_record6'],\n",
    "             ['021623_record1','021723_record2','021823_record3','021923_record4','022023_record5','022123_record6'],\n",
    "             ['021623_record1','021723_record2','021823_record3','021923_record4','022023_record5rep','022123_record6'],\n",
    "             ['022623_record1','022723_record2','022823_record3','030123_record4','030223_record5','030323_record6'] #end cohort d \n",
    "            ]) #list of sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "679c1916",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Define which mice & sessions to load based on metadata'''\n",
    "# Define mice, sessions for particular cohorts\n",
    "mice , mice_ind, _  = np.intersect1d(all_mice, np.union1d(cohortc_mice, cohortd_mice), return_indices = True) # SM mice\n",
    "\n",
    "sessions = []\n",
    "for i in mice_ind:\n",
    "    sessions.append(all_sessions[i])\n",
    "\n",
    "# Make a dict to hold data\n",
    "data = {}\n",
    "\n",
    "for session, m in zip(sessions, mice):\n",
    "    data[m] = {}\n",
    "    \n",
    "    for s in session:\n",
    "        data[m][s] = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ebe3d6e8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a16d7f1bc49499ebe6dff6e384ea24c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped trials, n skipped = 3[ 6  7 83]\n",
      "Skipped trials, n skipped = 11[ 39  40  41  74  75  76  77  78 108 127 180]\n",
      "Skipped trials, n skipped = 1[160]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5bee09adb0941768909bb18d8fabbc5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped trials, n skipped = 1[168]\n",
      "Skipped trials, n skipped = 1[130]\n",
      "Skipped trials, n skipped = 2[ 29 144]\n",
      "Skipped trials, n skipped = 4[161 164 165 166]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e87e4fbff5e84f30803911784c819f30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped trials, n skipped = 15[100 101 102 110 111 112 113 114 115 116 117 118 119 172 181]\n",
      "Skipped trials, n skipped = 4[141 188 189 190]\n",
      "Skipped trials, n skipped = 11[ 82 109 110 130 149 150 157 169 170 178 179]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a05e935072424697b1d8b976cac4be50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped trials, n skipped = 1[167]\n",
      "Skipped trials, n skipped = 9[185 186 187 188 189 190 191 192 193]\n",
      "Skipped trials, n skipped = 5[108 109 110 111 208]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e5571856eaa43e886c19f5f0d1eb723",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped trials, n skipped = 4[  5  87  88 100]\n",
      "Skipped trials, n skipped = 1[132]\n",
      "Skipped trials, n skipped = 4[177 178 179 180]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7c8ee88ecd24fe794c71e11cb3e2498",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "498663e263b74a98b03419e45b6b8de2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A20013123_record6 did not reach gain change\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a433794dffa4d73bc5e334fb162b476",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "242bde4e2f8b4b4bae1a69faed6c6bf4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b8b78816caf470e9c3008e844b444fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd06f47a0c774af8920083fb2f17c7af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12c7a7179fce42d08ffec31fb2429b7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f600a32fdfed47a59ccce1b3da497d8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38aab1b45e58498098c5dfaeea9ca6e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7aa2540ea33d4f2a9ec7c5c10a3445a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c31abc335d8470f8826f54bf3c92fd7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9faa2503e83c445dbb06b0864ada24a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d679da820bf5476d8579c4d0e6e822bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee384d2ca32b46b4b24b641c7759e260",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f7f46dcbdc245e6911da79b8ee722ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8836e312137c40789bacf5577b0c95ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped trials, n skipped = 3[120 121 122]\n",
      "Skipped trials, n skipped = 3[127 128 143]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "919282b7e899470b98ded3d0367a7c28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb07d491297f4a07b7810a88bc2c1098",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped trials, n skipped = 3[169 170 171]\n",
      "Skipped trials, n skipped = 23[105 106 107 108 109 110 111 112 113 114 138 139 140 141 142 143 144 145\n",
      " 146 147 148 188 189]\n",
      "Skipped trials, n skipped = 1[22]\n",
      "Skipped trials, n skipped = 2[166 178]\n",
      "Skipped trials, n skipped = 2[175 202]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3803876c691b40469d09c69e7fc1dce1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped trials, n skipped = 1[144]\n",
      "Skipped trials, n skipped = 1[212]\n",
      "Skipped trials, n skipped = 2[115 152]\n",
      "Skipped trials, n skipped = 3[ 21 161 177]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21681aa0dc7d4f238a09911b9d59efad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped trials, n skipped = 2[137 138]\n",
      "Skipped trials, n skipped = 2[ 52 167]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b7fc99ddb354b34a19266f721757b07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90980e512dca44fda63204e180b2ef2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1437bd246d5341a19784d063ac26bf77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe28641bf7294aa5a42faefba044a056",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "''' Find & save indices corresponding to quarters of the task sorted by context, making sure skipped trials are excluded''' \n",
    "load_folder = 'C:/Users/Python/Desktop/LocalData/filtered/'\n",
    "save_folder = 'C:/Users/Python/Desktop/LocalData/spatialcellssm/indices/'\n",
    "\n",
    "\n",
    "for m, session in zip(mice,sessions):\n",
    "    for s in tdqm(session):\n",
    "        d = data[m][s]\n",
    "        \n",
    "        #load data\n",
    "        rawdata_file = 'RAW_' + m + '_' + s + '.npy'\n",
    "        behavior_file = 'BEHAVIOR_' + m + '_' + s + '.npy'\n",
    "        \n",
    "        raw = np.load(load_folder + rawdata_file, allow_pickle=True)\n",
    "        behaviorfil = np.load(load_folder + behavior_file, allow_pickle=False)        \n",
    "        posx = behaviorfil[:,0]\n",
    "        trial = behaviorfil[:,2]\n",
    "        \n",
    "        #define indices for first two quarters accounting for skipped trials\n",
    "        start_idx = (np.where(trial >= 20)[0][0]).astype(int) # trial is zero-indexed, 20 full dark trials\n",
    "        enda_idx = (np.where(trial <= 79)[0][-1]).astype(int) # get indices of all 60 context_a trials that follow dark\n",
    "        endb_idx = (np.where(trial <= 139)[0][-1]).astype(int) # last index before alternation\n",
    "        Aidx = np.arange(start_idx, enda_idx + 1, 1)\n",
    "        Bidx = np.arange(enda_idx + 1, endb_idx + 1, 1)\n",
    "        \n",
    "        #find context A / B trials in alternation, removing skipped trials\n",
    "        trialinfo = raw.item().get('trialinfo')\n",
    "        left = trialinfo['left']\n",
    "               \n",
    "        A_trials = np.where((left == 1))[0]\n",
    "        A_trials = list(A_trials[A_trials >= 140])\n",
    "        B_trials = np.where((left == 0))[0]\n",
    "        B_trials = list(B_trials[B_trials >= 140])\n",
    "    \n",
    "        try:\n",
    "            _ = raw.item().get('correctedtrial').shape\n",
    "            if (len(np.unique(trial)) < 220): \n",
    "                alltrial = np.arange(0, np.max(np.unique(trial)) + 1 , 1)\n",
    "            else:    \n",
    "                alltrial = np.arange(0,220,1)\n",
    "            skippedtrials = np.setdiff1d(alltrial, np.unique(trial)).astype(int)\n",
    "            print('Skipped trials, n skipped = ' + str(len(skippedtrials)) + str(skippedtrials))\n",
    "        except: \n",
    "            skippedtrials = []\n",
    "            \n",
    "        for n, t in enumerate(skippedtrials):\n",
    "            if t in A_trials:\n",
    "                A_trials.remove(t)\n",
    "            elif t in B_trials:\n",
    "                B_trials.remove(t)\n",
    "    \n",
    "        A_idx = []\n",
    "        for t in A_trials:\n",
    "            A_idx = np.append(A_idx, np.where(trial == t)[0])\n",
    "            A_idx = A_idx.astype(int)\n",
    "            \n",
    "        B_idx = []\n",
    "        for t in B_trials:\n",
    "            B_idx = np.append(B_idx, np.where(trial == t)[0])\n",
    "            B_idx = B_idx.astype(int)\n",
    "            \n",
    "        #save indices for session section\n",
    "        d['Aidx'] = Aidx\n",
    "        d['Bidx'] = Bidx\n",
    "        d['A_idx'] = A_idx\n",
    "        d['B_idx'] = B_idx\n",
    "                \n",
    "        # get non-gain change A' and B' indices \n",
    "        gain = trialinfo['gain']\n",
    "        \n",
    "        #check if mouse reached gain period; if not append NaN to all arrays & continue \n",
    "        if len(gain) < 200:\n",
    "            print(str(m) + str(s) + ' did not reach gain change')\n",
    "            \n",
    "            d['A_ngidx'] = A_idx\n",
    "            d['B_ngidx'] = B_idx\n",
    "            \n",
    "            continue \n",
    "            \n",
    "        #get count of gain in each context & select equal number of last Context A or B alt trials before gain\n",
    "        gain_trials = np.where((gain == 0.7))[0]\n",
    "        gain_trials = list(gain_trials)\n",
    "\n",
    "        Agtrials = np.intersect1d(A_trials, np.asarray(gain_trials))\n",
    "        Agtrials = list(np.sort(Agtrials.astype(int)))\n",
    "        Bgtrials = np.intersect1d(B_trials, np.asarray(gain_trials))                   \n",
    "        Bgtrials = list(np.sort(Bgtrials.astype(int)))\n",
    "    \n",
    "        #get indices of observations corresponding to the selected trials\n",
    "        Agidx = []\n",
    "        for t in Agtrials:\n",
    "            Agidx = np.append(Agidx, np.where(trial == t)[0])\n",
    "        Agidx = Agidx.astype(int)\n",
    "            \n",
    "        Bgidx = []\n",
    "        for t in Bgtrials:\n",
    "            Bgidx = np.append(Bgidx, np.where(trial == t)[0])\n",
    "        Bgidx = Bgidx.astype(int)\n",
    "        \n",
    "        A_ngidx = np.setdiff1d(A_idx,Agidx).astype(int)\n",
    "        B_ngidx = np.setdiff1d(B_idx,Bgidx).astype(int)\n",
    "        \n",
    "        d['A_ngidx'] = A_ngidx\n",
    "        d['B_ngidx'] = B_ngidx\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6d68a2c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped & dark trials omitted from reward data, n skipped = 3\n",
      "Mouse A14 with n_misses: 183\n",
      "got lick indices for mouse A14 session 083022_record1\n",
      "got reward indices for mouse A14 session 083022_record1\n",
      "Skipped & dark trials omitted from reward data, n skipped = 11\n",
      "Mouse A14 with n_misses: 154\n",
      "got lick indices for mouse A14 session 083122_record2\n",
      "got reward indices for mouse A14 session 083122_record2\n",
      "Skipped & dark trials omitted from reward data, n skipped = 1\n",
      "Mouse A14 with n_misses: 145\n",
      "got lick indices for mouse A14 session 090122_record3\n",
      "got reward indices for mouse A14 session 090122_record3\n",
      "No trials skipped; only dark trials omitted from reward data\n",
      "Mouse A15 with n_misses: 105\n",
      "got lick indices for mouse A15 session 083022_record1\n",
      "got reward indices for mouse A15 session 083022_record1\n",
      "Skipped & dark trials omitted from reward data, n skipped = 1\n",
      "Mouse A15 with n_misses: 80\n",
      "got lick indices for mouse A15 session 083122_record2\n",
      "got reward indices for mouse A15 session 083122_record2\n",
      "Skipped & dark trials omitted from reward data, n skipped = 1\n",
      "Mouse A15 with n_misses: 39\n",
      "got lick indices for mouse A15 session 090122_record3\n",
      "got reward indices for mouse A15 session 090122_record3\n",
      "Skipped & dark trials omitted from reward data, n skipped = 2\n",
      "Mouse A15 with n_misses: 63\n",
      "got lick indices for mouse A15 session 090222_record4\n",
      "got reward indices for mouse A15 session 090222_record4\n",
      "Skipped & dark trials omitted from reward data, n skipped = 4\n",
      "Mouse A15 with n_misses: 53\n",
      "got lick indices for mouse A15 session 090322_record5\n",
      "got reward indices for mouse A15 session 090322_record5\n",
      "No trials skipped; only dark trials omitted from reward data\n",
      "Mouse A15 with n_misses: 54\n",
      "got lick indices for mouse A15 session 090422_record6\n",
      "got reward indices for mouse A15 session 090422_record6\n",
      "Skipped & dark trials omitted from reward data, n skipped = 15\n",
      "Mouse A16 with n_misses: 127\n",
      "got lick indices for mouse A16 session 083022_record1\n",
      "got reward indices for mouse A16 session 083022_record1\n",
      "Skipped & dark trials omitted from reward data, n skipped = 4\n",
      "Mouse A16 with n_misses: 71\n",
      "got lick indices for mouse A16 session 083122_record2\n",
      "got reward indices for mouse A16 session 083122_record2\n",
      "Skipped & dark trials omitted from reward data, n skipped = 11\n",
      "Mouse A16 with n_misses: 105\n",
      "got lick indices for mouse A16 session 090122_record3\n",
      "got reward indices for mouse A16 session 090122_record3\n",
      "No trials skipped; only dark trials omitted from reward data\n",
      "Mouse A16 with n_misses: 178\n",
      "got lick indices for mouse A16 session 090222_record4\n",
      "got reward indices for mouse A16 session 090222_record4\n",
      "No trials skipped; only dark trials omitted from reward data\n",
      "Mouse A17 with n_misses: 134\n",
      "got lick indices for mouse A17 session 082322_record1\n",
      "got reward indices for mouse A17 session 082322_record1\n",
      "No trials skipped; only dark trials omitted from reward data\n",
      "Mouse A17 with n_misses: 85\n",
      "got lick indices for mouse A17 session 082422_record2\n",
      "got reward indices for mouse A17 session 082422_record2\n",
      "No trials skipped; only dark trials omitted from reward data\n",
      "Mouse A17 with n_misses: 93\n",
      "got lick indices for mouse A17 session 082522_record3\n",
      "got reward indices for mouse A17 session 082522_record3\n",
      "Skipped & dark trials omitted from reward data, n skipped = 1\n",
      "Mouse A17 with n_misses: 85\n",
      "got lick indices for mouse A17 session 082622_record4\n",
      "got reward indices for mouse A17 session 082622_record4\n",
      "Skipped & dark trials omitted from reward data, n skipped = 9\n",
      "Mouse A17 with n_misses: 170\n",
      "got lick indices for mouse A17 session 082722_record5\n",
      "got reward indices for mouse A17 session 082722_record5\n",
      "Skipped & dark trials omitted from reward data, n skipped = 5\n",
      "Mouse A17 with n_misses: 98\n",
      "got lick indices for mouse A17 session 082822_record6\n",
      "got reward indices for mouse A17 session 082822_record6\n",
      "No trials skipped; only dark trials omitted from reward data\n",
      "Mouse A18 with n_misses: 150\n",
      "got lick indices for mouse A18 session 082322_record1real\n",
      "got reward indices for mouse A18 session 082322_record1real\n",
      "Skipped & dark trials omitted from reward data, n skipped = 4\n",
      "Mouse A18 with n_misses: 119\n",
      "got lick indices for mouse A18 session 082422_record2\n",
      "got reward indices for mouse A18 session 082422_record2\n",
      "No trials skipped; only dark trials omitted from reward data\n",
      "Mouse A18 with n_misses: 63\n",
      "got lick indices for mouse A18 session 082522_record3\n",
      "got reward indices for mouse A18 session 082522_record3\n",
      "Skipped & dark trials omitted from reward data, n skipped = 1\n",
      "Mouse A18 with n_misses: 94\n",
      "got lick indices for mouse A18 session 082622_record4\n",
      "got reward indices for mouse A18 session 082622_record4\n",
      "Skipped & dark trials omitted from reward data, n skipped = 4\n",
      "Mouse A18 with n_misses: 54\n",
      "got lick indices for mouse A18 session 082722_record5\n",
      "got reward indices for mouse A18 session 082722_record5\n",
      "No trials skipped; only dark trials omitted from reward data\n",
      "Mouse A18 with n_misses: 59\n",
      "got lick indices for mouse A18 session 082822_record6\n",
      "got reward indices for mouse A18 session 082822_record6\n",
      "No trials skipped; only dark trials omitted from reward data\n",
      "Mouse A19 with n_misses: 53\n",
      "got lick indices for mouse A19 session 012723_record2\n",
      "got reward indices for mouse A19 session 012723_record2\n",
      "No trials skipped; only dark trials omitted from reward data\n",
      "Mouse A19 with n_misses: 47\n",
      "got lick indices for mouse A19 session 012823_record3\n",
      "got reward indices for mouse A19 session 012823_record3\n",
      "No trials skipped; only dark trials omitted from reward data\n",
      "Mouse A19 with n_misses: 48\n",
      "got lick indices for mouse A19 session 012923_record4\n",
      "got reward indices for mouse A19 session 012923_record4\n",
      "No trials skipped; only dark trials omitted from reward data\n",
      "Mouse A19 with n_misses: 89\n",
      "got lick indices for mouse A19 session 013023_record5\n",
      "got reward indices for mouse A19 session 013023_record5\n",
      "No trials skipped; only dark trials omitted from reward data\n",
      "Mouse A19 with n_misses: 107\n",
      "got lick indices for mouse A19 session 013123_record6\n",
      "got reward indices for mouse A19 session 013123_record6\n",
      "No trials skipped; only dark trials omitted from reward data\n",
      "Mouse A19 with n_misses: 101\n",
      "got lick indices for mouse A19 session 020123_record7\n",
      "got reward indices for mouse A19 session 020123_record7\n",
      "No trials skipped; only dark trials omitted from reward data\n",
      "Mouse A20 with n_misses: 83\n",
      "got lick indices for mouse A20 session 012623_record1\n",
      "got reward indices for mouse A20 session 012623_record1\n",
      "No trials skipped; only dark trials omitted from reward data\n",
      "Mouse A20 with n_misses: 57\n",
      "got lick indices for mouse A20 session 012723_record2\n",
      "got reward indices for mouse A20 session 012723_record2\n",
      "No trials skipped; only dark trials omitted from reward data\n",
      "Mouse A20 with n_misses: 40\n",
      "got lick indices for mouse A20 session 012823_record3\n",
      "got reward indices for mouse A20 session 012823_record3\n",
      "No trials skipped; only dark trials omitted from reward data\n",
      "Mouse A20 with n_misses: 67\n",
      "got lick indices for mouse A20 session 012923_record4\n",
      "got reward indices for mouse A20 session 012923_record4\n",
      "No trials skipped; only dark trials omitted from reward data\n",
      "Mouse A20 with n_misses: 55\n",
      "got lick indices for mouse A20 session 013023_record5\n",
      "got reward indices for mouse A20 session 013023_record5\n",
      "No trials skipped; only dark trials omitted from reward data\n",
      "Mouse A20 with n_misses: 71\n",
      "got lick indices for mouse A20 session 013123_record6\n",
      "got reward indices for mouse A20 session 013123_record6\n",
      "No trials skipped; only dark trials omitted from reward data\n",
      "Mouse A22 with n_misses: 86\n",
      "got lick indices for mouse A22 session 012923_record2\n",
      "got reward indices for mouse A22 session 012923_record2\n",
      "No trials skipped; only dark trials omitted from reward data\n",
      "Mouse A22 with n_misses: 72\n",
      "got lick indices for mouse A22 session 013023_record3\n",
      "got reward indices for mouse A22 session 013023_record3\n",
      "No trials skipped; only dark trials omitted from reward data\n",
      "Mouse A22 with n_misses: 56\n",
      "got lick indices for mouse A22 session 013123_record4\n",
      "got reward indices for mouse A22 session 013123_record4\n",
      "No trials skipped; only dark trials omitted from reward data\n",
      "Mouse A22 with n_misses: 27\n",
      "got lick indices for mouse A22 session 020123_record5\n",
      "got reward indices for mouse A22 session 020123_record5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No trials skipped; only dark trials omitted from reward data\n",
      "Mouse A22 with n_misses: 104\n",
      "got lick indices for mouse A22 session 020223_record6\n",
      "got reward indices for mouse A22 session 020223_record6\n",
      "No trials skipped; only dark trials omitted from reward data\n",
      "Mouse A22 with n_misses: 84\n",
      "got lick indices for mouse A22 session 020323_record7\n",
      "got reward indices for mouse A22 session 020323_record7\n",
      "No trials skipped; only dark trials omitted from reward data\n",
      "Mouse A23 with n_misses: 141\n",
      "got lick indices for mouse A23 session 020923_record1\n",
      "got reward indices for mouse A23 session 020923_record1\n",
      "No trials skipped; only dark trials omitted from reward data\n",
      "Mouse A23 with n_misses: 102\n",
      "got lick indices for mouse A23 session 021023_record2\n",
      "got reward indices for mouse A23 session 021023_record2\n",
      "No trials skipped; only dark trials omitted from reward data\n",
      "Mouse A23 with n_misses: 52\n",
      "got lick indices for mouse A23 session 021123_record3\n",
      "got reward indices for mouse A23 session 021123_record3\n",
      "No trials skipped; only dark trials omitted from reward data\n",
      "Mouse A23 with n_misses: 73\n",
      "got lick indices for mouse A23 session 021223_record4\n",
      "got reward indices for mouse A23 session 021223_record4\n",
      "No trials skipped; only dark trials omitted from reward data\n",
      "Mouse A23 with n_misses: 73\n",
      "got lick indices for mouse A23 session 021323_record5\n",
      "got reward indices for mouse A23 session 021323_record5\n",
      "No trials skipped; only dark trials omitted from reward data\n",
      "Mouse A23 with n_misses: 3\n",
      "got lick indices for mouse A23 session 021423_record6\n",
      "got reward indices for mouse A23 session 021423_record6\n",
      "No trials skipped; only dark trials omitted from reward data\n",
      "Mouse A24 with n_misses: 35\n",
      "got lick indices for mouse A24 session 022623_record1\n",
      "got reward indices for mouse A24 session 022623_record1\n",
      "No trials skipped; only dark trials omitted from reward data\n",
      "Mouse A24 with n_misses: 27\n",
      "got lick indices for mouse A24 session 022723_record2\n",
      "got reward indices for mouse A24 session 022723_record2\n",
      "No trials skipped; only dark trials omitted from reward data\n",
      "Mouse A24 with n_misses: 33\n",
      "got lick indices for mouse A24 session 022823_record3\n",
      "got reward indices for mouse A24 session 022823_record3\n",
      "No trials skipped; only dark trials omitted from reward data\n",
      "Mouse A24 with n_misses: 10\n",
      "got lick indices for mouse A24 session 030123_record4\n",
      "got reward indices for mouse A24 session 030123_record4\n",
      "No trials skipped; only dark trials omitted from reward data\n",
      "Mouse A24 with n_misses: 9\n",
      "got lick indices for mouse A24 session 030223_record5\n",
      "got reward indices for mouse A24 session 030223_record5\n",
      "No trials skipped; only dark trials omitted from reward data\n",
      "Mouse A24 with n_misses: 10\n",
      "got lick indices for mouse A24 session 030323_record6\n",
      "got reward indices for mouse A24 session 030323_record6\n",
      "No trials skipped; only dark trials omitted from reward data\n",
      "Mouse MA10F with n_misses: 89\n",
      "got lick indices for mouse MA10F session 111322_record1\n",
      "got reward indices for mouse MA10F session 111322_record1\n",
      "No trials skipped; only dark trials omitted from reward data\n",
      "Mouse MA10F with n_misses: 41\n",
      "got lick indices for mouse MA10F session 111422_record2\n",
      "got reward indices for mouse MA10F session 111422_record2\n",
      "No trials skipped; only dark trials omitted from reward data\n",
      "Mouse MA10F with n_misses: 22\n",
      "got lick indices for mouse MA10F session 111522_record3\n",
      "got reward indices for mouse MA10F session 111522_record3\n",
      "No trials skipped; only dark trials omitted from reward data\n",
      "Mouse MA10F with n_misses: 21\n",
      "got lick indices for mouse MA10F session 111622_record4\n",
      "got reward indices for mouse MA10F session 111622_record4\n",
      "No trials skipped; only dark trials omitted from reward data\n",
      "Mouse MA10F with n_misses: 3\n",
      "got lick indices for mouse MA10F session 111722_record5\n",
      "got reward indices for mouse MA10F session 111722_record5\n",
      "No trials skipped; only dark trials omitted from reward data\n",
      "Mouse MA10F with n_misses: 0\n",
      "got lick indices for mouse MA10F session 111822_record6\n",
      "got reward indices for mouse MA10F session 111822_record6\n",
      "No trials skipped; only dark trials omitted from reward data\n",
      "Mouse MA1F with n_misses: 130\n",
      "got lick indices for mouse MA1F session 102322_record1\n",
      "got reward indices for mouse MA1F session 102322_record1\n",
      "No trials skipped; only dark trials omitted from reward data\n",
      "Mouse MA1F with n_misses: 18\n",
      "got lick indices for mouse MA1F session 102422_record2\n",
      "got reward indices for mouse MA1F session 102422_record2\n",
      "No trials skipped; only dark trials omitted from reward data\n",
      "Mouse MA1F with n_misses: 7\n",
      "got lick indices for mouse MA1F session 102522_record3\n",
      "got reward indices for mouse MA1F session 102522_record3\n",
      "No trials skipped; only dark trials omitted from reward data\n",
      "Mouse MA1F with n_misses: 15\n",
      "got lick indices for mouse MA1F session 102622_record4\n",
      "got reward indices for mouse MA1F session 102622_record4\n",
      "No trials skipped; only dark trials omitted from reward data\n",
      "Mouse MA1F with n_misses: 7\n",
      "got lick indices for mouse MA1F session 102722_record5\n",
      "got reward indices for mouse MA1F session 102722_record5\n",
      "No trials skipped; only dark trials omitted from reward data\n",
      "Mouse MA1F with n_misses: 0\n",
      "got lick indices for mouse MA1F session 102822_record6\n",
      "got reward indices for mouse MA1F session 102822_record6\n",
      "No trials skipped; only dark trials omitted from reward data\n",
      "Mouse MA2F with n_misses: 46\n",
      "got lick indices for mouse MA2F session 102322_record1\n",
      "got reward indices for mouse MA2F session 102322_record1\n",
      "No trials skipped; only dark trials omitted from reward data\n",
      "Mouse MA2F with n_misses: 25\n",
      "got lick indices for mouse MA2F session 102422_record2\n",
      "got reward indices for mouse MA2F session 102422_record2\n",
      "No trials skipped; only dark trials omitted from reward data\n",
      "Mouse MA2F with n_misses: 3\n",
      "got lick indices for mouse MA2F session 102522_record3\n",
      "got reward indices for mouse MA2F session 102522_record3\n",
      "No trials skipped; only dark trials omitted from reward data\n",
      "Mouse MA2F with n_misses: 26\n",
      "got lick indices for mouse MA2F session 102622_record4\n",
      "got reward indices for mouse MA2F session 102622_record4\n",
      "No trials skipped; only dark trials omitted from reward data\n",
      "Mouse MA2F with n_misses: 3\n",
      "got lick indices for mouse MA2F session 102722_record5\n",
      "got reward indices for mouse MA2F session 102722_record5\n",
      "No trials skipped; only dark trials omitted from reward data\n",
      "Mouse MA2F with n_misses: 3\n",
      "got lick indices for mouse MA2F session 102822_record6\n",
      "got reward indices for mouse MA2F session 102822_record6\n",
      "No trials skipped; only dark trials omitted from reward data\n",
      "Mouse MA3M with n_misses: 84\n",
      "got lick indices for mouse MA3M session 102322_record1\n",
      "got reward indices for mouse MA3M session 102322_record1\n",
      "No trials skipped; only dark trials omitted from reward data\n",
      "Mouse MA3M with n_misses: 30\n",
      "got lick indices for mouse MA3M session 102422_record2\n",
      "got reward indices for mouse MA3M session 102422_record2\n",
      "No trials skipped; only dark trials omitted from reward data\n",
      "Mouse MA3M with n_misses: 5\n",
      "got lick indices for mouse MA3M session 102522_record3\n",
      "got reward indices for mouse MA3M session 102522_record3\n",
      "No trials skipped; only dark trials omitted from reward data\n",
      "Mouse MA3M with n_misses: 0\n",
      "got lick indices for mouse MA3M session 102622_record4\n",
      "got reward indices for mouse MA3M session 102622_record4\n",
      "No trials skipped; only dark trials omitted from reward data\n",
      "Mouse MA3M with n_misses: 0\n",
      "got lick indices for mouse MA3M session 102722_record5\n",
      "got reward indices for mouse MA3M session 102722_record5\n",
      "No trials skipped; only dark trials omitted from reward data\n",
      "Mouse MA3M with n_misses: 1\n",
      "got lick indices for mouse MA3M session 102822_record6\n",
      "got reward indices for mouse MA3M session 102822_record6\n",
      "No trials skipped; only dark trials omitted from reward data\n",
      "Mouse MA4M with n_misses: 88\n",
      "got lick indices for mouse MA4M session 103122_record2\n",
      "got reward indices for mouse MA4M session 103122_record2\n",
      "No trials skipped; only dark trials omitted from reward data\n",
      "Mouse MA4M with n_misses: 45\n",
      "got lick indices for mouse MA4M session 110122_record3\n",
      "got reward indices for mouse MA4M session 110122_record3\n",
      "No trials skipped; only dark trials omitted from reward data\n",
      "Mouse MA4M with n_misses: 38\n",
      "got lick indices for mouse MA4M session 110222_record4\n",
      "got reward indices for mouse MA4M session 110222_record4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No trials skipped; only dark trials omitted from reward data\n",
      "Mouse MA4M with n_misses: 46\n",
      "got lick indices for mouse MA4M session 110322_record5rep\n",
      "got reward indices for mouse MA4M session 110322_record5rep\n",
      "No trials skipped; only dark trials omitted from reward data\n",
      "Mouse MA4M with n_misses: 15\n",
      "got lick indices for mouse MA4M session 110422_record6\n",
      "got reward indices for mouse MA4M session 110422_record6\n",
      "No trials skipped; only dark trials omitted from reward data\n",
      "Mouse MA4M with n_misses: 116\n",
      "got lick indices for mouse MA4M session 110522_record7\n",
      "got reward indices for mouse MA4M session 110522_record7\n",
      "No trials skipped; only dark trials omitted from reward data\n",
      "Mouse MA5M with n_misses: 98\n",
      "got lick indices for mouse MA5M session 110622_record1\n",
      "got reward indices for mouse MA5M session 110622_record1\n",
      "No trials skipped; only dark trials omitted from reward data\n",
      "Mouse MA5M with n_misses: 89\n",
      "got lick indices for mouse MA5M session 110722_record2\n",
      "got reward indices for mouse MA5M session 110722_record2\n",
      "No trials skipped; only dark trials omitted from reward data\n",
      "Mouse MA5M with n_misses: 40\n",
      "got lick indices for mouse MA5M session 110822_record3\n",
      "got reward indices for mouse MA5M session 110822_record3\n",
      "No trials skipped; only dark trials omitted from reward data\n",
      "Mouse MA5M with n_misses: 17\n",
      "got lick indices for mouse MA5M session 110922_record4\n",
      "got reward indices for mouse MA5M session 110922_record4\n",
      "No trials skipped; only dark trials omitted from reward data\n",
      "Mouse MA5M with n_misses: 21\n",
      "got lick indices for mouse MA5M session 111022_record5\n",
      "got reward indices for mouse MA5M session 111022_record5\n",
      "No trials skipped; only dark trials omitted from reward data\n",
      "Mouse MA5M with n_misses: 2\n",
      "got lick indices for mouse MA5M session 111122_record6\n",
      "got reward indices for mouse MA5M session 111122_record6\n",
      "No trials skipped; only dark trials omitted from reward data\n",
      "Mouse MA6M with n_misses: 26\n",
      "got lick indices for mouse MA6M session 103022_record1\n",
      "got reward indices for mouse MA6M session 103022_record1\n",
      "No trials skipped; only dark trials omitted from reward data\n",
      "Mouse MA6M with n_misses: 75\n",
      "got lick indices for mouse MA6M session 103122_record2\n",
      "got reward indices for mouse MA6M session 103122_record2\n",
      "No trials skipped; only dark trials omitted from reward data\n",
      "Mouse MA6M with n_misses: 50\n",
      "got lick indices for mouse MA6M session 110122_record3\n",
      "got reward indices for mouse MA6M session 110122_record3\n",
      "No trials skipped; only dark trials omitted from reward data\n",
      "Mouse MA6M with n_misses: 35\n",
      "got lick indices for mouse MA6M session 110222_record4\n",
      "got reward indices for mouse MA6M session 110222_record4\n",
      "No trials skipped; only dark trials omitted from reward data\n",
      "Mouse MA6M with n_misses: 16\n",
      "got lick indices for mouse MA6M session 110322_record5\n",
      "got reward indices for mouse MA6M session 110322_record5\n",
      "No trials skipped; only dark trials omitted from reward data\n",
      "Mouse MA6M with n_misses: 10\n",
      "got lick indices for mouse MA6M session 110422_record6\n",
      "got reward indices for mouse MA6M session 110422_record6\n",
      "No trials skipped; only dark trials omitted from reward data\n",
      "Mouse MA7M with n_misses: 106\n",
      "got lick indices for mouse MA7M session 103022_record1\n",
      "got reward indices for mouse MA7M session 103022_record1\n",
      "No trials skipped; only dark trials omitted from reward data\n",
      "Mouse MA7M with n_misses: 18\n",
      "got lick indices for mouse MA7M session 103122_record2\n",
      "got reward indices for mouse MA7M session 103122_record2\n",
      "No trials skipped; only dark trials omitted from reward data\n",
      "Mouse MA7M with n_misses: 34\n",
      "got lick indices for mouse MA7M session 110122_record3\n",
      "got reward indices for mouse MA7M session 110122_record3\n",
      "No trials skipped; only dark trials omitted from reward data\n",
      "Mouse MA7M with n_misses: 87\n",
      "got lick indices for mouse MA7M session 110222_record4\n",
      "got reward indices for mouse MA7M session 110222_record4\n",
      "No trials skipped; only dark trials omitted from reward data\n",
      "Mouse MA8F with n_misses: 47\n",
      "got lick indices for mouse MA8F session 111322_record1\n",
      "got reward indices for mouse MA8F session 111322_record1\n",
      "No trials skipped; only dark trials omitted from reward data\n",
      "Mouse MA8F with n_misses: 70\n",
      "got lick indices for mouse MA8F session 111422_record2\n",
      "got reward indices for mouse MA8F session 111422_record2\n",
      "No trials skipped; only dark trials omitted from reward data\n",
      "Mouse MA8F with n_misses: 59\n",
      "got lick indices for mouse MA8F session 111522_record3\n",
      "got reward indices for mouse MA8F session 111522_record3\n",
      "No trials skipped; only dark trials omitted from reward data\n",
      "Mouse MA8F with n_misses: 15\n",
      "got lick indices for mouse MA8F session 111622_record4\n",
      "got reward indices for mouse MA8F session 111622_record4\n",
      "No trials skipped; only dark trials omitted from reward data\n",
      "Mouse MA8F with n_misses: 9\n",
      "got lick indices for mouse MA8F session 111722_record5\n",
      "got reward indices for mouse MA8F session 111722_record5\n",
      "No trials skipped; only dark trials omitted from reward data\n",
      "Mouse MA8F with n_misses: 5\n",
      "got lick indices for mouse MA8F session 111822_record6\n",
      "got reward indices for mouse MA8F session 111822_record6\n",
      "No trials skipped; only dark trials omitted from reward data\n",
      "Mouse MA9F with n_misses: 97\n",
      "got lick indices for mouse MA9F session 111322_record1\n",
      "got reward indices for mouse MA9F session 111322_record1\n",
      "No trials skipped; only dark trials omitted from reward data\n",
      "Mouse MA9F with n_misses: 95\n",
      "got lick indices for mouse MA9F session 111422_record2\n",
      "got reward indices for mouse MA9F session 111422_record2\n",
      "No trials skipped; only dark trials omitted from reward data\n",
      "Mouse MA9F with n_misses: 36\n",
      "got lick indices for mouse MA9F session 111522_record3\n",
      "got reward indices for mouse MA9F session 111522_record3\n",
      "No trials skipped; only dark trials omitted from reward data\n",
      "Mouse MA9F with n_misses: 10\n",
      "got lick indices for mouse MA9F session 111622_record4\n",
      "got reward indices for mouse MA9F session 111622_record4\n",
      "No trials skipped; only dark trials omitted from reward data\n",
      "Mouse MA9F with n_misses: 5\n",
      "got lick indices for mouse MA9F session 111722_record5\n",
      "got reward indices for mouse MA9F session 111722_record5\n",
      "No trials skipped; only dark trials omitted from reward data\n",
      "Mouse MA9F with n_misses: 7\n",
      "got lick indices for mouse MA9F session 111822_record6\n",
      "got reward indices for mouse MA9F session 111822_record6\n",
      "No trials skipped; only dark trials omitted from reward data\n",
      "Mouse Y20 with n_misses: 17\n",
      "got lick indices for mouse Y20 session 092522_record1\n",
      "got reward indices for mouse Y20 session 092522_record1\n",
      "No trials skipped; only dark trials omitted from reward data\n",
      "Mouse Y20 with n_misses: 11\n",
      "got lick indices for mouse Y20 session 092622_record2\n",
      "got reward indices for mouse Y20 session 092622_record2\n",
      "No trials skipped; only dark trials omitted from reward data\n",
      "Mouse Y20 with n_misses: 9\n",
      "got lick indices for mouse Y20 session 092722_record3\n",
      "got reward indices for mouse Y20 session 092722_record3\n",
      "No trials skipped; only dark trials omitted from reward data\n",
      "Mouse Y20 with n_misses: 1\n",
      "got lick indices for mouse Y20 session 092822_record4\n",
      "got reward indices for mouse Y20 session 092822_record4\n",
      "Skipped & dark trials omitted from reward data, n skipped = 3\n",
      "Mouse Y20 with n_misses: 3\n",
      "got lick indices for mouse Y20 session 092922_record5\n",
      "got reward indices for mouse Y20 session 092922_record5\n",
      "Skipped & dark trials omitted from reward data, n skipped = 3\n",
      "Mouse Y20 with n_misses: 6\n",
      "got lick indices for mouse Y20 session 093022_record6\n",
      "got reward indices for mouse Y20 session 093022_record6\n",
      "No trials skipped; only dark trials omitted from reward data\n",
      "Mouse Y21 with n_misses: 77\n",
      "got lick indices for mouse Y21 session 091822_record1\n",
      "got reward indices for mouse Y21 session 091822_record1\n",
      "No trials skipped; only dark trials omitted from reward data\n",
      "Mouse Y21 with n_misses: 50\n",
      "got lick indices for mouse Y21 session 091922_record2\n",
      "got reward indices for mouse Y21 session 091922_record2\n",
      "No trials skipped; only dark trials omitted from reward data\n",
      "Mouse Y21 with n_misses: 39\n",
      "got lick indices for mouse Y21 session 092022_record3\n",
      "got reward indices for mouse Y21 session 092022_record3\n",
      "No trials skipped; only dark trials omitted from reward data\n",
      "Mouse Y21 with n_misses: 40\n",
      "got lick indices for mouse Y21 session 092122_record4\n",
      "got reward indices for mouse Y21 session 092122_record4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No trials skipped; only dark trials omitted from reward data\n",
      "Mouse Y21 with n_misses: 8\n",
      "got lick indices for mouse Y21 session 092222_record5\n",
      "got reward indices for mouse Y21 session 092222_record5\n",
      "No trials skipped; only dark trials omitted from reward data\n",
      "Mouse Y21 with n_misses: 4\n",
      "got lick indices for mouse Y21 session 092322_record6\n",
      "got reward indices for mouse Y21 session 092322_record6\n",
      "Skipped & dark trials omitted from reward data, n skipped = 3\n",
      "Mouse Y22 with n_misses: 134\n",
      "got lick indices for mouse Y22 session 092522_record1\n",
      "got reward indices for mouse Y22 session 092522_record1\n",
      "Skipped & dark trials omitted from reward data, n skipped = 23\n",
      "Mouse Y22 with n_misses: 49\n",
      "got lick indices for mouse Y22 session 092622_record2\n",
      "got reward indices for mouse Y22 session 092622_record2\n",
      "No trials skipped; only dark trials omitted from reward data\n",
      "Mouse Y22 with n_misses: 24\n",
      "got lick indices for mouse Y22 session 092722_record3\n",
      "got reward indices for mouse Y22 session 092722_record3\n",
      "Skipped & dark trials omitted from reward data, n skipped = 1\n",
      "Mouse Y22 with n_misses: 17\n",
      "got lick indices for mouse Y22 session 092822_record4\n",
      "got reward indices for mouse Y22 session 092822_record4\n",
      "Skipped & dark trials omitted from reward data, n skipped = 2\n",
      "Mouse Y22 with n_misses: 1\n",
      "got lick indices for mouse Y22 session 092922_record5\n",
      "got reward indices for mouse Y22 session 092922_record5\n",
      "Skipped & dark trials omitted from reward data, n skipped = 2\n",
      "Mouse Y22 with n_misses: 26\n",
      "got lick indices for mouse Y22 session 093022_record6\n",
      "got reward indices for mouse Y22 session 093022_record6\n",
      "No trials skipped; only dark trials omitted from reward data\n",
      "Mouse Y23 with n_misses: 72\n",
      "got lick indices for mouse Y23 session 092522_record1\n",
      "got reward indices for mouse Y23 session 092522_record1\n",
      "Skipped & dark trials omitted from reward data, n skipped = 1\n",
      "Mouse Y23 with n_misses: 71\n",
      "got lick indices for mouse Y23 session 092622_record2\n",
      "got reward indices for mouse Y23 session 092622_record2\n",
      "No trials skipped; only dark trials omitted from reward data\n",
      "Mouse Y23 with n_misses: 32\n",
      "got lick indices for mouse Y23 session 092722_record3\n",
      "got reward indices for mouse Y23 session 092722_record3\n",
      "Skipped & dark trials omitted from reward data, n skipped = 1\n",
      "Mouse Y23 with n_misses: 21\n",
      "got lick indices for mouse Y23 session 092822_record4\n",
      "got reward indices for mouse Y23 session 092822_record4\n",
      "Skipped & dark trials omitted from reward data, n skipped = 2\n",
      "Mouse Y23 with n_misses: 18\n",
      "got lick indices for mouse Y23 session 092922_record5\n",
      "got reward indices for mouse Y23 session 092922_record5\n",
      "Skipped & dark trials omitted from reward data, n skipped = 3\n",
      "Mouse Y23 with n_misses: 18\n",
      "got lick indices for mouse Y23 session 093022_record6\n",
      "got reward indices for mouse Y23 session 093022_record6\n",
      "Skipped & dark trials omitted from reward data, n skipped = 2\n",
      "Mouse Y24 with n_misses: 48\n",
      "got lick indices for mouse Y24 session 091822_record1\n",
      "got reward indices for mouse Y24 session 091822_record1\n",
      "No trials skipped; only dark trials omitted from reward data\n",
      "Mouse Y24 with n_misses: 31\n",
      "got lick indices for mouse Y24 session 091922_record2\n",
      "got reward indices for mouse Y24 session 091922_record2\n",
      "Skipped & dark trials omitted from reward data, n skipped = 2\n",
      "Mouse Y24 with n_misses: 20\n",
      "got lick indices for mouse Y24 session 092022_record3\n",
      "got reward indices for mouse Y24 session 092022_record3\n",
      "No trials skipped; only dark trials omitted from reward data\n",
      "Mouse Y24 with n_misses: 15\n",
      "got lick indices for mouse Y24 session 092122_record4\n",
      "got reward indices for mouse Y24 session 092122_record4\n",
      "No trials skipped; only dark trials omitted from reward data\n",
      "Mouse Y24 with n_misses: 11\n",
      "got lick indices for mouse Y24 session 092222_record5\n",
      "got reward indices for mouse Y24 session 092222_record5\n",
      "No trials skipped; only dark trials omitted from reward data\n",
      "Mouse Y24 with n_misses: 2\n",
      "got lick indices for mouse Y24 session 092322_record6\n",
      "got reward indices for mouse Y24 session 092322_record6\n",
      "No trials skipped; only dark trials omitted from reward data\n",
      "Mouse Y25 with n_misses: 69\n",
      "got lick indices for mouse Y25 session 021623_record1\n",
      "got reward indices for mouse Y25 session 021623_record1\n",
      "No trials skipped; only dark trials omitted from reward data\n",
      "Mouse Y25 with n_misses: 93\n",
      "got lick indices for mouse Y25 session 021723_record2\n",
      "got reward indices for mouse Y25 session 021723_record2\n",
      "No trials skipped; only dark trials omitted from reward data\n",
      "Mouse Y25 with n_misses: 24\n",
      "got lick indices for mouse Y25 session 021823_record3\n",
      "got reward indices for mouse Y25 session 021823_record3\n",
      "No trials skipped; only dark trials omitted from reward data\n",
      "Mouse Y25 with n_misses: 46\n",
      "got lick indices for mouse Y25 session 021923_record4\n",
      "got reward indices for mouse Y25 session 021923_record4\n",
      "No trials skipped; only dark trials omitted from reward data\n",
      "Mouse Y25 with n_misses: 10\n",
      "got lick indices for mouse Y25 session 022023_record5\n",
      "got reward indices for mouse Y25 session 022023_record5\n",
      "No trials skipped; only dark trials omitted from reward data\n",
      "Mouse Y25 with n_misses: 8\n",
      "got lick indices for mouse Y25 session 022123_record6\n",
      "got reward indices for mouse Y25 session 022123_record6\n",
      "No trials skipped; only dark trials omitted from reward data\n",
      "Mouse Y26 with n_misses: 63\n",
      "got lick indices for mouse Y26 session 021623_record1\n",
      "got reward indices for mouse Y26 session 021623_record1\n",
      "No trials skipped; only dark trials omitted from reward data\n",
      "Mouse Y26 with n_misses: 54\n",
      "got lick indices for mouse Y26 session 021723_record2\n",
      "got reward indices for mouse Y26 session 021723_record2\n",
      "No trials skipped; only dark trials omitted from reward data\n",
      "Mouse Y26 with n_misses: 46\n",
      "got lick indices for mouse Y26 session 021823_record3\n",
      "got reward indices for mouse Y26 session 021823_record3\n",
      "No trials skipped; only dark trials omitted from reward data\n",
      "Mouse Y26 with n_misses: 12\n",
      "got lick indices for mouse Y26 session 021923_record4\n",
      "got reward indices for mouse Y26 session 021923_record4\n",
      "No trials skipped; only dark trials omitted from reward data\n",
      "Mouse Y26 with n_misses: 5\n",
      "got lick indices for mouse Y26 session 022023_record5\n",
      "got reward indices for mouse Y26 session 022023_record5\n",
      "No trials skipped; only dark trials omitted from reward data\n",
      "Mouse Y26 with n_misses: 6\n",
      "got lick indices for mouse Y26 session 022123_record6\n",
      "got reward indices for mouse Y26 session 022123_record6\n",
      "No trials skipped; only dark trials omitted from reward data\n",
      "Mouse Y27 with n_misses: 121\n",
      "got lick indices for mouse Y27 session 021623_record1\n",
      "got reward indices for mouse Y27 session 021623_record1\n",
      "No trials skipped; only dark trials omitted from reward data\n",
      "Mouse Y27 with n_misses: 34\n",
      "got lick indices for mouse Y27 session 021723_record2\n",
      "got reward indices for mouse Y27 session 021723_record2\n",
      "No trials skipped; only dark trials omitted from reward data\n",
      "Mouse Y27 with n_misses: 20\n",
      "got lick indices for mouse Y27 session 021823_record3\n",
      "got reward indices for mouse Y27 session 021823_record3\n",
      "No trials skipped; only dark trials omitted from reward data\n",
      "Mouse Y27 with n_misses: 3\n",
      "got lick indices for mouse Y27 session 021923_record4\n",
      "got reward indices for mouse Y27 session 021923_record4\n",
      "No trials skipped; only dark trials omitted from reward data\n",
      "Mouse Y27 with n_misses: 0\n",
      "got lick indices for mouse Y27 session 022023_record5rep\n",
      "got reward indices for mouse Y27 session 022023_record5rep\n",
      "No trials skipped; only dark trials omitted from reward data\n",
      "Mouse Y27 with n_misses: 0\n",
      "got lick indices for mouse Y27 session 022123_record6\n",
      "got reward indices for mouse Y27 session 022123_record6\n",
      "No trials skipped; only dark trials omitted from reward data\n",
      "Mouse Y28 with n_misses: 120\n",
      "got lick indices for mouse Y28 session 022623_record1\n",
      "got reward indices for mouse Y28 session 022623_record1\n",
      "No trials skipped; only dark trials omitted from reward data\n",
      "Mouse Y28 with n_misses: 104\n",
      "got lick indices for mouse Y28 session 022723_record2\n",
      "got reward indices for mouse Y28 session 022723_record2\n",
      "No trials skipped; only dark trials omitted from reward data\n",
      "Mouse Y28 with n_misses: 74\n",
      "got lick indices for mouse Y28 session 022823_record3\n",
      "got reward indices for mouse Y28 session 022823_record3\n",
      "No trials skipped; only dark trials omitted from reward data\n",
      "Mouse Y28 with n_misses: 76\n",
      "got lick indices for mouse Y28 session 030123_record4\n",
      "got reward indices for mouse Y28 session 030123_record4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No trials skipped; only dark trials omitted from reward data\n",
      "Mouse Y28 with n_misses: 42\n",
      "got lick indices for mouse Y28 session 030223_record5\n",
      "got reward indices for mouse Y28 session 030223_record5\n",
      "No trials skipped; only dark trials omitted from reward data\n",
      "Mouse Y28 with n_misses: 36\n",
      "got lick indices for mouse Y28 session 030323_record6\n",
      "got reward indices for mouse Y28 session 030323_record6\n"
     ]
    }
   ],
   "source": [
    "''' Generate behavioral data for alternation'''\n",
    "\n",
    "#get lick & reward data\n",
    "rewarda_centers = []\n",
    "rewardb_centers = []\n",
    "\n",
    "for m, session in zip(mice, sessions):\n",
    "    for s in session:\n",
    "        d = data[m][s]\n",
    " \n",
    "        #load data\n",
    "        rawdata_file = 'RAW_' + m + '_' + s + '.npy'\n",
    "        spikes_file = 'SPIKES_' + m + '_' + s +'.npy'\n",
    "        behavior_file = 'BEHAVIOR_' + m + '_' + s + '.npy'\n",
    "        \n",
    "        raw = np.load(load_folder + rawdata_file, allow_pickle=True)\n",
    "        Y = np.load(load_folder + spikes_file, allow_pickle=False) #pre-filtered for speeds >2cm/s, position-corrected spikes, 20 ms timebins\n",
    "        behaviorfil = np.load(load_folder + behavior_file, allow_pickle=False)\n",
    "        \n",
    "        d['reward_data'] = {}\n",
    "        \n",
    "        # get behavioral params\n",
    "        posx = raw.item().get('posx')\n",
    "        post = raw.item().get('post')\n",
    "        dt = np.unique(np.round(np.diff(post),4))\n",
    "        lickt = raw.item().get('lickt')\n",
    "        trials_dark = np.sum(raw.item().get('trialinfo')['dark'])\n",
    "        reward = raw.item().get('reward')\n",
    "        reward['trials'] = np.arange(0,len(reward['trials']),1) # fixes occassional Unity error numbering of rewards \n",
    "        \n",
    "        if len(dt) > 1: # discard duplicate frame entries if they occurred\n",
    "            dt = dt[dt != 0]\n",
    "        speed = raw.item().get('speed')\n",
    "        \n",
    "         # get reward params & remove reward data pertaining to dark trials & skipped trials\n",
    "        try:\n",
    "            _ = raw.item().get('correctedtrial').shape\n",
    "            trial = raw.item().get('correctedtrial')\n",
    "            \n",
    "            if (len(np.unique(trial)) < 220): \n",
    "                alltrial = np.arange(0,np.max(np.unique(trial)) + 1 , 1)\n",
    "            else:    \n",
    "                alltrial = np.arange(0,220,1)\n",
    "                \n",
    "            skippedtrials = np.setdiff1d(alltrial,np.unique(trial))\n",
    "            nonskipped = np.setdiff1d(reward['trials'],skippedtrials)   \n",
    "            k_idx = np.intersect1d(np.where(reward['trials'] > trials_dark), nonskipped)\n",
    "            keep_idx = np.intersect1d(np.where(reward['trials'] <= np.max(alltrial)), k_idx)\n",
    "            print('Skipped & dark trials omitted from reward data, n skipped = ' + str(len(skippedtrials)))\n",
    "            \n",
    "        except AttributeError:\n",
    "            trial = raw.item().get('trial')\n",
    "            keep_idx = (np.where(reward['trials'] > trials_dark))\n",
    "            skippedtrials = []\n",
    "            print('No trials skipped; only dark trials omitted from reward data')\n",
    "        \n",
    "        reward_centers = np.array(reward['centers'][keep_idx])\n",
    "        rewardt = reward['times'][keep_idx]\n",
    "        reward_trials = reward['trials'][keep_idx]\n",
    "        misses = reward['missed'][keep_idx].astype(bool)\n",
    "        auto_reward = np.array(reward['auto'][keep_idx])\n",
    "        print('Mouse ' + m + ' with n_misses: ' + str(np.sum(misses)))   \n",
    "\n",
    "        # get lick and reward indices\n",
    "        lick_ct = get.spiketrain(post, dt, lickt, index=False)\n",
    "        d['reward_data']['lick_ct'] = lick_ct\n",
    "        print('got lick indices for mouse ' + m + ' session ' + s)\n",
    "        \n",
    "        reward_idx = get.rewardtrain(post, dt, rewardt, index=True) #gets reward ct for each time binned position range as index\n",
    "        d['reward_data']['reward_idx'] = reward_idx\n",
    "        print('got reward indices for mouse ' + m + ' session ' + s)\n",
    "    \n",
    "    # saves list of reward locations per mouse\n",
    "    if reward['centers'][0] == 270:\n",
    "        rewarda_centers = np.append(rewarda_centers,270)\n",
    "        rewardb_centers = np.append(rewardb_centers,370)\n",
    "    else:\n",
    "        rewarda_centers = np.append(rewarda_centers,370)\n",
    "        rewardb_centers = np.append(rewardb_centers,270)            \n",
    "        \n",
    "#Find & Save Number of Missed Rewards per Session & Animal\n",
    "#block array\n",
    "blocksatiety = []\n",
    "blockreq = []\n",
    "blocktrialn = []\n",
    "\n",
    "#session arrays\n",
    "req_rates = []\n",
    "reqa_rates = []\n",
    "reqb_rates = []\n",
    "reqblock_rates = []\n",
    "reqalt_rates = []\n",
    "reqalta_rates = []\n",
    "reqaltb_rates = []\n",
    "req_trials = []\n",
    "reqblock_trials = []\n",
    "reqalt_trials = []\n",
    "\n",
    "#animals arrays\n",
    "mreq_rates = []\n",
    "mreqa_rates = []\n",
    "mreqb_rates = []\n",
    "mreqblock_rates = []\n",
    "mreqalt_rates = []\n",
    "mreqalta_rates = []\n",
    "mreqaltb_rates = []\n",
    "\n",
    "for m, session in zip(mice, sessions):\n",
    "    rt = []\n",
    "    ca = []\n",
    "    cb = []\n",
    "    blocks = []\n",
    "    alt = []\n",
    "    alta = []\n",
    "    altb = []\n",
    "    \n",
    "    req = []\n",
    "    reqa = []\n",
    "    reqb = []\n",
    "    reqblocks = []\n",
    "    reqalt = []\n",
    "    reqalta = []\n",
    "    reqaltb = []\n",
    "    \n",
    "    for s in session:\n",
    "        # get behavior data\n",
    "        d = data[m][s]\n",
    "        \n",
    "        #load data\n",
    "        rawdata_file = 'RAW_' + m + '_' + s + '.npy'\n",
    "        spikes_file = 'SPIKES_' + m + '_' + s +'.npy'\n",
    "        behavior_file = 'BEHAVIOR_' + m + '_' + s + '.npy'\n",
    "        \n",
    "        raw = np.load(load_folder + rawdata_file, allow_pickle=True)\n",
    "        Y = np.load(load_folder + spikes_file, allow_pickle=False) #pre-filtered for speeds >2cm/s, position-corrected spikes, 20 ms timebins\n",
    "        behaviorfil = np.load(load_folder + behavior_file, allow_pickle=False)\n",
    "        \n",
    "        posx = raw.item().get('posx')\n",
    "        post = raw.item().get('post')\n",
    "        dt = np.unique(np.round(np.diff(post),4))\n",
    "        if len(dt) > 1: # discard duplicate frame entries if they occurred\n",
    "            dt = dt[dt != 0]\n",
    "        speed = raw.item().get('speed')\n",
    "        \n",
    "        # get reward params & remove reward data pertaining to dark trials & skipped trials\n",
    "        lickt = raw.item().get('lickt')\n",
    "        trials_dark = np.sum(raw.item().get('trialinfo')['dark'])\n",
    "        reward = raw.item().get('reward')\n",
    "        reward['trials'] = np.arange(0,len(reward['trials']),1)\n",
    "        \n",
    "        try:\n",
    "            _ = raw.item().get('correctedtrial').shape\n",
    "            trial = raw.item().get('correctedtrial')\n",
    "            \n",
    "            if (len(np.unique(trial)) < 220): \n",
    "                alltrial = np.arange(0,np.max(np.unique(trial)) + 1 , 1)\n",
    "            else:    \n",
    "                alltrial = np.arange(0,220,1)\n",
    "                \n",
    "            skippedtrials = np.setdiff1d(alltrial,np.unique(trial))\n",
    "            nonskipped = np.setdiff1d(reward['trials'],skippedtrials)   \n",
    "            k_idx = np.intersect1d(np.where(reward['trials'] > trials_dark), nonskipped)\n",
    "            keep_idx = np.intersect1d(np.where(reward['trials'] <= np.max(alltrial)), k_idx)\n",
    "            # print('Skipped & dark trials omitted from reward data, n skipped = ' + str(len(skippedtrials)))\n",
    "            \n",
    "        except AttributeError:\n",
    "            trial = raw.item().get('trial')\n",
    "            keep_idx = (np.where(reward['trials'] > trials_dark))\n",
    "            skippedtrials = []\n",
    "            # print('No trials skipped; only dark trials omitted from reward data')\n",
    "        \n",
    "        reward_centers = np.array(reward['centers'][keep_idx])\n",
    "        rewarda = reward_centers[0]\n",
    "        rewardb = reward_centers[60]\n",
    "        rewardt = reward['times'][keep_idx]\n",
    "        reward_trials = reward['trials'][keep_idx]\n",
    "        misses = reward['missed'][keep_idx].astype(bool)\n",
    "        requests = ~misses\n",
    "        \n",
    "        # find rate of requests for a given session\n",
    "        req_rates.append(np.sum(requests)/len(reward_trials)) #total\n",
    "        \n",
    "        rewarda_idx = np.where(reward_trials < 81)[0]\n",
    "        reqa_rates.append(np.sum(requests[rewarda_idx])/len(rewarda_idx)) #context a\n",
    "        \n",
    "        rewardb_idx = np.intersect1d((np.where(reward_trials >= 81)), (np.where(reward_trials <= 140)))\n",
    "        reqb_rates.append(np.sum(requests[rewardb_idx])/len(rewardb_idx)) #context b\n",
    "        \n",
    "        block_idx = np.where(reward_trials < 140)[0]\n",
    "        reqblock_rates.append(np.sum(requests[block_idx])/len(block_idx)) #block\n",
    "        \n",
    "        alt_idx = np.where(reward_trials >= 140)[0]\n",
    "        reqalt_rates.append(np.sum(requests[alt_idx])/len(alt_idx)) #alt\n",
    "        \n",
    "        alta_idx = np.where((reward_trials >= 140) & (reward_centers == rewarda))[0] \n",
    "        reqalta_rates.append(np.mean(requests[alta_idx]))\n",
    "        \n",
    "        altb_idx = np.where((reward_trials >= 140) & (reward_centers == rewardb))[0]\n",
    "        reqaltb_rates.append(np.mean(requests[altb_idx]))\n",
    "        \n",
    "        rt = np.append(rt,len(reward_trials))\n",
    "        ca = np.append(ca,len(rewarda_idx))\n",
    "        cb = np.append(cb,len(rewardb_idx))\n",
    "        blocks = np.append(blocks,len(block_idx))\n",
    "        alt = np.append(alt,len(alt_idx))\n",
    "        alta = np.append(alta, len(alta_idx))\n",
    "        altb = np.append(altb, len(altb_idx))\n",
    "        \n",
    "        req_trials = np.append(req_trials, len(reward_trials))\n",
    "        reqblock_trials = np.append(reqblock_trials, len(block_idx))\n",
    "        reqalt_trials = np.append(reqalt_trials, len(alt_idx))\n",
    "        \n",
    "        d['altreqbytrial'] = requests[alt_idx]\n",
    "        \n",
    "        req = np.append(req,np.sum(requests))\n",
    "        reqa = np.append(reqa,np.sum(requests[rewarda_idx]))\n",
    "        reqb = np.append(reqb,np.sum(requests[rewardb_idx]))\n",
    "        reqblocks = np.append(reqblocks,np.sum(requests[block_idx]))\n",
    "        reqalt = np.append(reqalt,np.sum(requests[alt_idx]))\n",
    "        reqalta = np.append(reqalta,requests[alta_idx])\n",
    "        reqaltb = np.append(reqaltb,requests[altb_idx])\n",
    "        \n",
    "        # append req rates from blocks into block req array len(4 x total sessions)\n",
    "        blockreq = np.append(blockreq, np.mean(requests[rewarda_idx])) # block 1\n",
    "        blockreq = np.append(blockreq, np.mean(requests[rewardb_idx])) # block 2\n",
    "        blockreq = np.append(blockreq, np.mean(requests[alta_idx])) # block 3\n",
    "        blockreq = np.append(blockreq, np.mean(requests[altb_idx])) # block 4   \n",
    "        \n",
    "        blocktrialn = np.append(blocktrialn, len(requests[rewarda_idx]))\n",
    "        blocktrialn = np.append(blocktrialn, len(requests[rewardb_idx]))\n",
    "        blocktrialn = np.append(blocktrialn, len(requests[alta_idx]))\n",
    "        blocktrialn = np.append(blocktrialn, len(requests[altb_idx]))\n",
    "        \n",
    "        # append reward counts from previous task block into block satiety array len(4 x total sessions)\n",
    "        blocksatiety = np.append(blocksatiety, 0) #no rewards before block a for every animal\n",
    "        blocksatiety = np.append(blocksatiety, np.sum(requests[rewarda_idx])) # count of rewards consumed before block b\n",
    "        blocksatiety = np.append(blocksatiety, (np.sum(requests[rewarda_idx]) + np.sum(requests[rewardb_idx]))) # before alta\n",
    "        blocksatiety = np.append(blocksatiety, (np.sum(requests[rewarda_idx]) + np.sum(requests[rewardb_idx]) + np.sum(requests[alta_idx]))) # beforealtb             \n",
    "                          \n",
    "    # get mouse request rate collapsing days\n",
    "    mreqrate = np.sum(req)/ np.sum(rt)\n",
    "    mreq_rates = np.append(mreq_rates,mreqrate)\n",
    "    \n",
    "    mreqarate = np.sum(reqa) / np.sum(ca)\n",
    "    mreqa_rates = np.append(mreqa_rates, mreqarate)\n",
    "    \n",
    "    mreqbrate = np.sum(reqb) / np.sum(cb)\n",
    "    mreqb_rates = np.append(mreqb_rates, mreqbrate)\n",
    "    \n",
    "    mreqblockrate = np.sum(reqblocks) / np.sum(blocks)\n",
    "    mreqblock_rates = np.append(mreqblock_rates, mreqblockrate)\n",
    "    \n",
    "    mreqaltrate = np.sum(reqalt) / np.sum(alt)\n",
    "    mreqalt_rates = np.append(mreqalt_rates, mreqaltrate)\n",
    "    \n",
    "    mreqalta_rates = np.append(mreqalta_rates, np.mean(reqalta))\n",
    "    mreqaltb_rates = np.append(mreqaltb_rates, np.mean(reqaltb))\n",
    "    \n",
    "# save as arrays to be safe\n",
    "req_rates = np.asarray(req_rates)\n",
    "reqa_rates = np.asarray(reqa_rates)\n",
    "reqb_rates = np.asarray(reqb_rates)\n",
    "reqblock_rates = np.asarray(reqblock_rates)\n",
    "reqalt_rates = np.asarray(reqalt_rates)\n",
    "reqalta_rates = np.asarray(reqalta_rates)\n",
    "reqaltb_rates = np.asarray(reqaltb_rates)\n",
    "\n",
    "mreq_rates = np.asarray(mreq_rates)\n",
    "mreqa_rates = np.asarray(mreqa_rates)\n",
    "mreqb_rates = np.asarray(mreqb_rates)\n",
    "mreqblock_rates = np.asarray(mreqblock_rates)\n",
    "mreqalt_rates = np.asarray(mreqalt_rates)\n",
    "mreqalta_rates = np.asarray(reqalta_rates)\n",
    "mreqaltb_rates = np.asarray(reqaltb_rates)\n",
    "\n",
    "blocksatiety = np.asarray(blocksatiety)\n",
    "blockreq = np.asarray(blockreq)\n",
    "blocktrialn = np.asarray(blocktrialn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "be5d0dc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0c4efb19574431f972965b22362da9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7d23851ed9a4fef884972fd9783ba96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63768fc02570423092f0555809e12119",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19c97164d6e14242b7eb25de52cf6bd2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da75a33c99254b229e4c659f91b53da9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8de98255f0364591b293879b335700c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70bc3c5cdef94a7c872b3bb424e10418",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4b79587290c487ea1de77615d2e8dc1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81d63724664c46c3b4677338271367cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "426dacdcf136495aa71e37dbd989b361",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbd03c5e7cbe4c2cbb0a0814fc60cece",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a0b724807ac45309079939609d56092",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8518923b615444d9ab7a68517176887",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f754e40826a34f6ba1bd80efae23df26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec1dcba5f2a844ef9e9180f892c8fb0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d26f0d08d2354b65b71cb00a9b990064",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d298f972fbd54f96ac16b4c6b8e4fe9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d1a2b232b254a9882ec2623c7686d2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2879d158145d4f31863d56a079a73c9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f55e93f58ead4e45a9a3c78accb93c80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bee266dcde9c4263836bb0b461777e8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be72701c902a45a781f074d8e9bf3106",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e9f78e176234be7a028747f063025d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3609883277c41abb957fbca6a0b39fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9520c32235c4d8db0cc3979e5e09407",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "798244712767433f8314cccb34bfbe54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b7dc870f2bf4fcab25be8dc82fef377",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d5f3351a6e54350a85e15b1361a8e22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ef805f881f346cf9f1a2ee34dc13eb2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "''' Load spatial cell (Figure 2/S3) and intn (Shuffle Procedure) booleans generated by previous notebooks. '''\n",
    "\n",
    "#adjujst paths\n",
    "save_folder = 'C:/Users/Python/Desktop/LocalData/spatialcellssm/'\n",
    "shuffle_folder = 'C:/Users/Python/Desktop/LocalData/intnspeedcells/'\n",
    "\n",
    "for m, session in zip(mice, sessions):\n",
    "    for s in tdqm(session):\n",
    "        d = data[m][s]\n",
    "        \n",
    "        #get file names\n",
    "        spatialcell99_file = 'spatialcell99_' + m + '_' + s + '.npy'\n",
    "        intn_file = 'intn_' + m + '_' + s + '.npy'\n",
    "\n",
    "        #load stuff\n",
    "        d['spatialcell99'] = np.load(save_folder + spatialcell99_file, allow_pickle = True)\n",
    "        d['intn'] = np.load(shuffle_folder + intn_file, allow_pickle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3851ec3f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "576ca4919d72431b98fda9377c6817eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7168cab46384b5d98933a4f43841394",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27318ed15df04401bed8db198e107619",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a17c2e8e41e4d1c9bc15ffe5326f35d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "207f82ce134641e6b70ecbad561867b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8bda02c0db114a2ba1f3cced8924c0ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67dcc3eaab9b4965b411eb08eea1851e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f42cb004a224bba8cc73016e044846b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "209f0955fbcc4c22a17cb4644a27076c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6caf1af7c9ac45359414c15a8f8af663",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26bb6367124c48a89b389584a309a3cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21f6d740ea2b48608c97961023d2bebd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19eca48a6d6f41e484cb81319d5a6d42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01b538dea5bc4baba1152fccf74b7c75",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3b29dae4c6840a799bf92043890e2e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f8c61e8b94e4cc0a5be9ac24541d420",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de015e4773b648ef88e8d71aad66803f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ddec73e45137444490196afb8ca65793",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26612a6739054936b2106f92b1d2cf2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bae1fe9d8a974740a358405b54615dbf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a39410e3310744198d226493678dfa29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "458cac2652174af586020a001ef0e780",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be231c01aed74e54aa24f0f30951e3b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d5fc955597e4a53aac60e0f649bfedf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fdb0842adfe7409199ca7a91ffab93af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83ab743758f2416a8da47f26217cbaa1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dcadf9a17daa40d6b34d98114b4f4c82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56fe2e30392c460183d6fd5551cd132f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a946187923641babbc4a986ed1d34bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "''' Apply FR thresholds to spatial cells\n",
    "\n",
    "Run time < 1 min / session (167 sessions)\n",
    "\n",
    "'''\n",
    "\n",
    "track_length = 400 #cm\n",
    "b = 2 # cm / spatial bin\n",
    "dt = 0.02\n",
    "n_dark = 20 #trials\n",
    "lags = np.arange(0,801,1)\n",
    "\n",
    "#adjust paths\n",
    "load_folder = 'C:/Users/Python/Desktop/LocalData/filtered/'\n",
    "save_folder = 'C:/Users/Python/Desktop/LocalData/shuffscores/'\n",
    "shuffload_folder3 = 'C:/Users/Python/Desktop/Dryad/shuffle_scores/peakheights/'\n",
    "\n",
    "perngs = []\n",
    "pergrid = []\n",
    "for m, session in zip(mice,sessions):\n",
    "    \n",
    "    for s in tdqm(session):\n",
    "        \n",
    "        d = data[m][s]\n",
    "        \n",
    "        #load in data\n",
    "        rawdata_file = 'RAW_' + m + '_' + s + '.npy'\n",
    "        behavior_file = 'BEHAVIOR_' + m + '_' + s + '.npy'\n",
    "        spikes_file = 'SPIKES_' + m + '_' + s +'.npy'\n",
    "        \n",
    "        raw = np.load(load_folder + rawdata_file, allow_pickle=True)\n",
    "        cell_IDs = raw.item().get('cellsfil')\n",
    "        behaviorfil = np.load(load_folder + behavior_file, allow_pickle=False)\n",
    "        Y = np.load(load_folder + spikes_file, allow_pickle=False) #pre-filtered for speeds >2cm/s, position-corrected spikes, 20 ms timebins\n",
    "        \n",
    "        posxfil = behaviorfil[:,0]\n",
    "        trial = behaviorfil[:,2]\n",
    "        trials = np.unique(trial)\n",
    "        postfil = behaviorfil[:,3]\n",
    "        rawtrialfil = raw.item().get('trialfil')\n",
    "        \n",
    "        Aidx = d['Aidx']\n",
    "        Bidx = d['Bidx']\n",
    "        \n",
    "        #load in spatial cells & interneurons classified elsewhere\n",
    "        spatialcell99 = d['spatialcell99']\n",
    "        spatialcells = cell_IDs[spatialcell99]\n",
    "        intn = d['intn']\n",
    "        \n",
    "        #define low FR cell group (mean FR <0.05 in the dark; 0.3 Hz overall); to be removed from grid cell group\n",
    "        stop_idx = np.where(trial <= 19)[0][-1].astype(int)\n",
    "        darkFR, _ , _ = ps.tuning_curve_bytrial(posxfil[:stop_idx], trial[:stop_idx], Y[:stop_idx,:], dt, b = 2, smooth=True, normalize=False, occupancy=True)\n",
    "        FR, _, _ = ps.tuning_curve(posxfil, Y, dt, b, smooth=True, l=2, SEM=False, occupancy=False)\n",
    "        lowfrcells = []\n",
    "        lowdarkfrcells = []\n",
    "        for i, c in enumerate(cell_IDs):\n",
    "            if np.mean(np.mean(darkFR[:,:,i], axis = 1)) <= 0.05:\n",
    "                lowdarkfrcells = np.append(lowdarkfrcells, c)\n",
    "            elif np.mean(FR[:,i]) < 0.3:\n",
    "                lowfrcells = np.append(lowfrcells, c)      \n",
    "                \n",
    "        #define indices excluding reward zone starts\n",
    "        reward = raw.item().get('reward')\n",
    "        centers = reward['centers']\n",
    "        centera = centers[0]\n",
    "        if centera == 270:\n",
    "            centerb = 370\n",
    "        else:\n",
    "            centerb = 270\n",
    "        \n",
    "        # generate aligned position tuning curve\n",
    "        aFR, abinned_pos, aFR_sem, occ = ps.tuning_curve(posxfil[Aidx], Y[Aidx,:], dt, b=2, smooth = True, l=5, SEM=True)\n",
    "        bFR, bbinned_pos, bFR_sem, occ = ps.tuning_curve(posxfil[Bidx], Y[Bidx,:], dt, b=2, smooth = True, l=5, SEM=True)\n",
    "        \n",
    "        #find indices of bins not including 50cm pre-post reward centers (220 to 255 and 320 to 355)\n",
    "        aidx = np.where((abinned_pos > (centera - 50)) & (abinned_pos <= (centera - 15)))\n",
    "        maska = np.ones(len(abinned_pos), bool)\n",
    "        maska[aidx] = 0\n",
    "        bidx = np.where((bbinned_pos > (centerb - 50)) & (bbinned_pos <= (centerb - 15)))\n",
    "        maskb = np.ones(len(bbinned_pos), bool)\n",
    "        maskb[bidx] = 0\n",
    "        \n",
    "        noisycells = []\n",
    "        for i, c in enumerate(cell_IDs):\n",
    "            if (np.mean(aFR_sem[maska,i]) > np.mean(aFR[maska,i])*.45) and (np.mean(bFR_sem[maskb,i]) > np.mean(bFR[maskb,i])*.45):\n",
    "                noisycells = np.append(noisycells, c)\n",
    "                \n",
    "        # filter out noisy cells from both grid and ngs cells and low firing grid cells    \n",
    "        for i, c in enumerate(cell_IDs):\n",
    "            #also require that dark FR > 0.05 Hz and mean FR > 0.3 Hz\n",
    "            if (c in lowfrcells) or (c in lowdarkfrcells):\n",
    "                spatialcell99[i] = 0\n",
    "                \n",
    "            if (c in noisycells):\n",
    "                spatialcell99[i] = 0\n",
    "                spatialcell99[i] = 0\n",
    "                \n",
    "        #Save booleans\n",
    "        spatialcell99 = spatialcell99.astype(bool)\n",
    "        d['spatialcell99'] = spatialcell99"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0d6bd77c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16d4f3310bb446c38683acbbef12dc26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A14, 083022_record1 n spatial cells: 67\n",
      "A14, 083122_record2 n spatial cells: 4\n",
      "A14, 090122_record3 n spatial cells: 24\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aca6b34f320f445799367c1d86e4971f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A15, 083022_record1 n spatial cells: 10\n",
      "A15, 083122_record2 n spatial cells: 116\n",
      "A15, 090122_record3 n spatial cells: 128\n",
      "A15, 090222_record4 n spatial cells: 182\n",
      "A15, 090322_record5 n spatial cells: 74\n",
      "A15, 090422_record6 n spatial cells: 40\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59967b9edc114072b8253aa274d724b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A16, 083022_record1 n spatial cells: 44\n",
      "A16, 083122_record2 n spatial cells: 93\n",
      "A16, 090122_record3 n spatial cells: 4\n",
      "A16, 090222_record4 n spatial cells: 52\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0b9ea937f984a5f8e1fcd0f56e6dd0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A17, 082322_record1 n spatial cells: 3\n",
      "A17, 082422_record2 n spatial cells: 6\n",
      "A17, 082522_record3 n spatial cells: 71\n",
      "A17, 082622_record4 n spatial cells: 58\n",
      "A17, 082722_record5 n spatial cells: 40\n",
      "A17, 082822_record6 n spatial cells: 72\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc795198025c43daa10a897a23cd7cbe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A18, 082322_record1real n spatial cells: 30\n",
      "A18, 082422_record2 n spatial cells: 229\n",
      "A18, 082522_record3 n spatial cells: 198\n",
      "A18, 082622_record4 n spatial cells: 113\n",
      "A18, 082722_record5 n spatial cells: 59\n",
      "A18, 082822_record6 n spatial cells: 5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7367f0ee140e41a5aab46994e343603a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A19, 012723_record2 n spatial cells: 1\n",
      "A19, 012823_record3 n spatial cells: 106\n",
      "A19, 012923_record4 n spatial cells: 116\n",
      "A19, 013023_record5 n spatial cells: 91\n",
      "A19, 013123_record6 n spatial cells: 65\n",
      "A19, 020123_record7 n spatial cells: 81\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4bf6dd9775004cc5b60233cb9259ebdd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A20, 012623_record1 n spatial cells: 25\n",
      "A20, 012723_record2 n spatial cells: 72\n",
      "A20, 012823_record3 n spatial cells: 117\n",
      "A20, 012923_record4 n spatial cells: 59\n",
      "A20, 013023_record5 n spatial cells: 75\n",
      "A20, 013123_record6 n spatial cells: 41\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29c9ac60f7d2435c80bcf484a6178b69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A22, 012923_record2 n spatial cells: 95\n",
      "A22, 013023_record3 n spatial cells: 192\n",
      "A22, 013123_record4 n spatial cells: 96\n",
      "A22, 020123_record5 n spatial cells: 20\n",
      "A22, 020223_record6 n spatial cells: 68\n",
      "A22, 020323_record7 n spatial cells: 17\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90e28dcf073946e8ade225e642f79b4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A23, 020923_record1 n spatial cells: 13\n",
      "A23, 021023_record2 n spatial cells: 85\n",
      "A23, 021123_record3 n spatial cells: 89\n",
      "A23, 021223_record4 n spatial cells: 10\n",
      "A23, 021323_record5 n spatial cells: 64\n",
      "A23, 021423_record6 n spatial cells: 103\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d4f85d02ba146fd95783445d2abbb1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A24, 022623_record1 n spatial cells: 91\n",
      "A24, 022723_record2 n spatial cells: 189\n",
      "A24, 022823_record3 n spatial cells: 122\n",
      "A24, 030123_record4 n spatial cells: 100\n",
      "A24, 030223_record5 n spatial cells: 81\n",
      "A24, 030323_record6 n spatial cells: 37\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72be8ab9ded649e1b361f1a5114c8b05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MA10F, 111322_record1 n spatial cells: 142\n",
      "MA10F, 111422_record2 n spatial cells: 93\n",
      "MA10F, 111522_record3 n spatial cells: 59\n",
      "MA10F, 111622_record4 n spatial cells: 41\n",
      "MA10F, 111722_record5 n spatial cells: 38\n",
      "MA10F, 111822_record6 n spatial cells: 85\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "299d11ce3c094d5194607f9eaada5131",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MA1F, 102322_record1 n spatial cells: 54\n",
      "MA1F, 102422_record2 n spatial cells: 79\n",
      "MA1F, 102522_record3 n spatial cells: 75\n",
      "MA1F, 102622_record4 n spatial cells: 19\n",
      "MA1F, 102722_record5 n spatial cells: 117\n",
      "MA1F, 102822_record6 n spatial cells: 100\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0929f9376eab40fb9df04e461cea03a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MA2F, 102322_record1 n spatial cells: 112\n",
      "MA2F, 102422_record2 n spatial cells: 128\n",
      "MA2F, 102522_record3 n spatial cells: 146\n",
      "MA2F, 102622_record4 n spatial cells: 102\n",
      "MA2F, 102722_record5 n spatial cells: 73\n",
      "MA2F, 102822_record6 n spatial cells: 85\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89f94f9697974f32b1efe36adf27542e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MA3M, 102322_record1 n spatial cells: 25\n",
      "MA3M, 102422_record2 n spatial cells: 96\n",
      "MA3M, 102522_record3 n spatial cells: 64\n",
      "MA3M, 102622_record4 n spatial cells: 68\n",
      "MA3M, 102722_record5 n spatial cells: 40\n",
      "MA3M, 102822_record6 n spatial cells: 67\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e19815ddc8f4ae68a775d1dbf5f226d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MA4M, 103122_record2 n spatial cells: 91\n",
      "MA4M, 110122_record3 n spatial cells: 54\n",
      "MA4M, 110222_record4 n spatial cells: 19\n",
      "MA4M, 110322_record5rep n spatial cells: 43\n",
      "MA4M, 110422_record6 n spatial cells: 51\n",
      "MA4M, 110522_record7 n spatial cells: 17\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "518b9a5cc3ff45b5b7e15edb155b8caf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MA5M, 110622_record1 n spatial cells: 78\n",
      "MA5M, 110722_record2 n spatial cells: 138\n",
      "MA5M, 110822_record3 n spatial cells: 124\n",
      "MA5M, 110922_record4 n spatial cells: 21\n",
      "MA5M, 111022_record5 n spatial cells: 44\n",
      "MA5M, 111122_record6 n spatial cells: 42\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5319163ee224e6d82d24c3901e663c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MA6M, 103022_record1 n spatial cells: 94\n",
      "MA6M, 103122_record2 n spatial cells: 68\n",
      "MA6M, 110122_record3 n spatial cells: 124\n",
      "MA6M, 110222_record4 n spatial cells: 26\n",
      "MA6M, 110322_record5 n spatial cells: 21\n",
      "MA6M, 110422_record6 n spatial cells: 68\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1dbde8a07f648b88e9cef518aab04b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MA7M, 103022_record1 n spatial cells: 61\n",
      "MA7M, 103122_record2 n spatial cells: 86\n",
      "MA7M, 110122_record3 n spatial cells: 57\n",
      "MA7M, 110222_record4 n spatial cells: 11\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd095cad58c345b5a13a5692e8e25ed1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MA8F, 111322_record1 n spatial cells: 27\n",
      "MA8F, 111422_record2 n spatial cells: 118\n",
      "MA8F, 111522_record3 n spatial cells: 111\n",
      "MA8F, 111622_record4 n spatial cells: 61\n",
      "MA8F, 111722_record5 n spatial cells: 41\n",
      "MA8F, 111822_record6 n spatial cells: 29\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0da37dbec0a4966b4e8d2c71bbefa1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MA9F, 111322_record1 n spatial cells: 74\n",
      "MA9F, 111422_record2 n spatial cells: 220\n",
      "MA9F, 111522_record3 n spatial cells: 164\n",
      "MA9F, 111622_record4 n spatial cells: 1\n",
      "MA9F, 111722_record5 n spatial cells: 49\n",
      "MA9F, 111822_record6 n spatial cells: 38\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc08840824cb4e0f9427ba9858841eb6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y20, 092522_record1 n spatial cells: 15\n",
      "Y20, 092622_record2 n spatial cells: 68\n",
      "Y20, 092722_record3 n spatial cells: 21\n",
      "Y20, 092822_record4 n spatial cells: 82\n",
      "Y20, 092922_record5 n spatial cells: 33\n",
      "Y20, 093022_record6 n spatial cells: 160\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96a5322f3e8e45b9b8b8717de43dda47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y21, 091822_record1 n spatial cells: 163\n",
      "Y21, 091922_record2 n spatial cells: 169\n",
      "Y21, 092022_record3 n spatial cells: 62\n",
      "Y21, 092122_record4 n spatial cells: 111\n",
      "Y21, 092222_record5 n spatial cells: 75\n",
      "Y21, 092322_record6 n spatial cells: 26\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e81e908047244946a7882af77f9d5b60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y22, 092522_record1 n spatial cells: 136\n",
      "Y22, 092622_record2 n spatial cells: 200\n",
      "Y22, 092722_record3 n spatial cells: 156\n",
      "Y22, 092822_record4 n spatial cells: 44\n",
      "Y22, 092922_record5 n spatial cells: 47\n",
      "Y22, 093022_record6 n spatial cells: 91\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5142a60c82894ef1b67aed61f6f85595",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y23, 092522_record1 n spatial cells: 51\n",
      "Y23, 092622_record2 n spatial cells: 38\n",
      "Y23, 092722_record3 n spatial cells: 64\n",
      "Y23, 092822_record4 n spatial cells: 59\n",
      "Y23, 092922_record5 n spatial cells: 91\n",
      "Y23, 093022_record6 n spatial cells: 132\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9282efb7ddea4cca98b1ce0274073839",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y24, 091822_record1 n spatial cells: 150\n",
      "Y24, 091922_record2 n spatial cells: 86\n",
      "Y24, 092022_record3 n spatial cells: 137\n",
      "Y24, 092122_record4 n spatial cells: 149\n",
      "Y24, 092222_record5 n spatial cells: 125\n",
      "Y24, 092322_record6 n spatial cells: 123\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6fe7a30b249047df9dbfc1f056dc0a12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y25, 021623_record1 n spatial cells: 1\n",
      "Y25, 021723_record2 n spatial cells: 117\n",
      "Y25, 021823_record3 n spatial cells: 89\n",
      "Y25, 021923_record4 n spatial cells: 78\n",
      "Y25, 022023_record5 n spatial cells: 83\n",
      "Y25, 022123_record6 n spatial cells: 25\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9dfa9eddbe234d52ae41b64af3d6e3d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y26, 021623_record1 n spatial cells: 79\n",
      "Y26, 021723_record2 n spatial cells: 83\n",
      "Y26, 021823_record3 n spatial cells: 51\n",
      "Y26, 021923_record4 n spatial cells: 3\n",
      "Y26, 022023_record5 n spatial cells: 35\n",
      "Y26, 022123_record6 n spatial cells: 6\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "606d8a1076624e7eb6e25051892e0998",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y27, 021623_record1 n spatial cells: 94\n",
      "Y27, 021723_record2 n spatial cells: 57\n",
      "Y27, 021823_record3 n spatial cells: 53\n",
      "Y27, 021923_record4 n spatial cells: 35\n",
      "Y27, 022023_record5rep n spatial cells: 71\n",
      "Y27, 022123_record6 n spatial cells: 94\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c52b9f54fba40579acf28f4df3e97ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y28, 022623_record1 n spatial cells: 35\n",
      "Y28, 022723_record2 n spatial cells: 85\n",
      "Y28, 022823_record3 n spatial cells: 73\n",
      "Y28, 030123_record4 n spatial cells: 49\n",
      "Y28, 030223_record5 n spatial cells: 114\n",
      "Y28, 030323_record6 n spatial cells: 89\n"
     ]
    }
   ],
   "source": [
    "''' Load saved spatial cell booleans & glance at overall density '''\n",
    "\n",
    "save_folder = 'C:/Users/Python/Desktop/LocalData/shuffscores/'\n",
    "\n",
    "perspatial = []\n",
    "sperspatial = []\n",
    "mperspatial = []\n",
    "\n",
    "for m, session in zip(mice,sessions):\n",
    "    \n",
    "    m_perspatial = []\n",
    "    m_cells = []\n",
    "    \n",
    "    for s in tdqm(session):\n",
    "        d = data[m][s]\n",
    "        \n",
    "        #load in data\n",
    "        rawdata_file = 'RAW_' + m + '_' + s + '.npy'\n",
    "        raw = np.load(load_folder + rawdata_file, allow_pickle=True)\n",
    "        cell_IDs = raw.item().get('cellsfil')\n",
    "        \n",
    "        spatialcell = d['spatialcell99'].astype(bool)\n",
    "        \n",
    "        print(m + ', ' + s + ' n spatial cells: '+ str(np.sum(spatialcell)))\n",
    "        perspatial = np.append(perspatial, 100*np.sum(spatialcell)/len(cell_IDs))        \n",
    "        sperspatial = np.append(sperspatial, 100*np.sum(spatialcell)/len(cell_IDs))\n",
    "        m_perspatial = np.append(m_perspatial, np.sum(spatialcell))\n",
    "        m_cells = np.append(m_cells, len(cell_IDs))\n",
    "    \n",
    "    mperspatial = np.append(mperspatial, np.sum(m_perspatial)/np.sum(m_cells)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c9b2820f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean, SEM Spatial Cell %\n",
      "29.15809617608128 0.9674108723859292\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 230x250 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "''' Examine spatial cell densities quickly as a sanity check'''\n",
    "\n",
    "# Assess distribution of spatial/ngs cell densities\n",
    "print('Mean, SEM Spatial Cell %')\n",
    "print(np.mean(perspatial), stats.sem(perspatial))\n",
    "\n",
    "#plot spatial cell % distributions\n",
    "fig, ax = plt.subplots(1,1,figsize = (2.3,2.5), sharey = True)\n",
    "ax.hist(perspatial, bins = np.arange(0,80,2), edgecolor = 'black',alpha = 0.5, color = 'C0')\n",
    "ax.set_title('Sessions vs. Spatial Cell %')\n",
    "ax.set_ylabel('Number of Sessions')\n",
    "ax.set_xlabel('Spatial Cell %')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7228c589",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Y20' 'Y21' 'Y22' 'Y23' 'Y24' 'Y25' 'Y26' 'Y27' 'Y28'] ['MA10F' 'MA1F' 'MA2F' 'MA3M' 'MA4M' 'MA5M' 'MA6M' 'MA7M' 'MA8F' 'MA9F'] ['A14' 'A15' 'A16' 'A17' 'A18' 'A19' 'A20' 'A22' 'A23' 'A24']\n",
      "9 10 10\n",
      "54 58 55\n"
     ]
    }
   ],
   "source": [
    "'''Get Indices of Stored Session, Animal Data Mice by Age Group'''\n",
    "save_folder = 'C:/Users/Python/Desktop/LocalData/spatialcellssm/'\n",
    "\n",
    "age_ind = []\n",
    "ma_ind = []\n",
    "y_ind = []\n",
    "age_sind = []\n",
    "ma_sind = []\n",
    "y_sind = []\n",
    "\n",
    "s_count = 0\n",
    "for m, s in zip(mice, sessions):\n",
    "    start = s_count\n",
    "    end = len(s) + s_count\n",
    "\n",
    "    if m in all_aged_mice:\n",
    "        age_ind = np.append(age_ind, (np.where(mice == m)[0]))\n",
    "        age_sind = np.append(age_sind, np.arange(start, end, 1))\n",
    "    elif m in all_MA_mice:\n",
    "        ma_ind = np.append(ma_ind, (np.where(mice == m)[0]))\n",
    "        ma_sind = np.append(ma_sind, np.arange(start, end, 1))\n",
    "    else:\n",
    "        y_ind = np.append(y_ind, (np.where(mice == m)[0]))\n",
    "        y_sind = np.append(y_sind, np.arange(start, end, 1))\n",
    "                            \n",
    "    s_count += len(s)\n",
    "    \n",
    "age_ind = age_ind.astype(int)\n",
    "ma_ind = ma_ind.astype(int)\n",
    "y_ind = y_ind.astype(int)\n",
    "age_sind = age_sind.astype(int)\n",
    "ma_sind = ma_sind.astype(int)\n",
    "y_sind = y_sind.astype(int)\n",
    "\n",
    "print(mice[y_ind], mice[ma_ind], mice[age_ind])\n",
    "print(len(mice[y_ind]), len(mice[ma_ind]), len(mice[age_ind]))\n",
    "print(len(y_sind), len(ma_sind), len(age_sind))\n",
    "Nold = len(mice[age_ind])\n",
    "Nma = len(mice[ma_ind])\n",
    "Nyoung = len(mice[y_ind])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "049232f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Define ColorMaps for Session & Animal Boxplots '''\n",
    "import matplotlib.pylab as pl\n",
    "import matplotlib.lines as mlines\n",
    "\n",
    "col_animal_old = pl.cm.Oranges([np.linspace(0.2,0.9,10)])\n",
    "col_animal_MA = pl.cm.Greens([np.linspace(0.2,0.9,10)])\n",
    "col_animal_young = pl.cm.Blues([np.linspace(0.2,0.9,9)])\n",
    "col_animal = [col_animal_young, col_animal_MA, col_animal_old]\n",
    "\n",
    "col_session_young = []\n",
    "col_session_MA = []\n",
    "col_session_old = []\n",
    "\n",
    "for m, session in zip(mice, sessions):\n",
    "    for s in range(0,len(session)):\n",
    "        \n",
    "        if m in SM_aged_mice:\n",
    "            idx = np.where(mice == m)[0][0] \n",
    "            col_session_old.append(col_animal[2][0][idx])           \n",
    "        elif m in SM_MA_mice:\n",
    "            idx = np.where(mice == m)[0][0] - Nold\n",
    "            col_session_MA.append(col_animal[1][0][idx])\n",
    "        else:\n",
    "            idx = np.where(mice == m)[0][0] - (Nold + Nma)\n",
    "            col_session_young.append(col_animal[0][0][idx])\n",
    "\n",
    "col_session = [col_session_young, col_session_MA, col_session_old]\n",
    "label_mice = ['Y20', 'Y21', 'Y22', 'Y23', 'Y24', 'Y25', 'Y26', 'Y27', 'Y28', \"\",\n",
    "              'MA10F', 'MA1F', 'MA2F', 'MA3M', 'MA4M', 'MA5M', 'MA6M', 'MA7M', 'MA8F', 'MA9F',\n",
    "              'A14', 'A15', 'A16', 'A17', 'A18', 'A19', 'A20', 'A22', 'A23', 'A24']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed38356c",
   "metadata": {},
   "source": [
    "# Compute or Load Spatial Cell FR Tensor (choose either cell below) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70b28d02",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b501c24dbfa4b61b1844bea24810557",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "too few spatial cells in session: A14, 083122_record2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13090849eda5411d8bebedd173c10664",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "too few spatial cells in session: A15, 083022_record1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94c48227b7ae43dc93bbe9cb53352d97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "too few spatial cells in session: A16, 090122_record3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2efa1aebe13e420e9679f9eae10cb426",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "too few spatial cells in session: A17, 082322_record1\n",
      "too few spatial cells in session: A17, 082422_record2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ecfb74a92f4438a85dd15e17b9a18fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "too few spatial cells in session: A18, 082822_record6\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e55156d4f0c14b2bbe04b2cfe9651881",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "too few spatial cells in session: A19, 012723_record2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e29878e3b264b2d89cad05e40ca57c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35c8e96d970b4e8eb99fb32f7ed48ea6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e067218224c540f0af859ccd32c61866",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "too few spatial cells in session: A23, 021223_record4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e018124b821c4b65a7edc176a5c7653d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43afc67b6eba41b7a296582c6f1ce554",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e4d1b4ac564499bb3ff38cd867e51ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32ff85164f5042d2a62bae26c9eb7143",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "''' Compute & Save Sorted Normalized FR Tensor for Grid Network in Back of Track, excluding Gain Change Period \n",
    "\n",
    "Run time 20 - 90 seconds / session x 167 sessions.\n",
    "\n",
    "'''\n",
    "\n",
    "from scipy.spatial.distance import pdist\n",
    "from scipy.spatial.distance import squareform\n",
    "\n",
    "dt = 0.02\n",
    "save_folder = 'C:/Users/Python/Desktop/LocalData/spatialcellssm/simmatrices/'\n",
    "\n",
    "for m, session in zip(mice, sessions):\n",
    "    for s in tdqm(session):\n",
    "        d = data[m][s]\n",
    "        \n",
    "        #get some data & cell IDs\n",
    "        rawdata_file = 'RAW_' + m + '_' + s + '.npy'\n",
    "        spikes_file = 'SPIKES_' + m + '_' + s +'.npy'\n",
    "        behavior_file = 'BEHAVIOR_' + m + '_' + s + '.npy'\n",
    "        \n",
    "        raw = np.load(load_folder + rawdata_file, allow_pickle=True)\n",
    "        Y = np.load(load_folder + spikes_file, allow_pickle=False) #pre-filtered for speeds >2cm/s, position-corrected spikes, 20 ms timebins\n",
    "        behaviorfil = np.load(load_folder + behavior_file, allow_pickle=False)\n",
    "        \n",
    "        cell_IDs = raw.item().get('cellsfil')\n",
    "        spatialcell99 = d['spatialcell99']\n",
    "        spatialcells = cell_IDs[spatialcell99] \n",
    "        \n",
    "        posx = behaviorfil[:,0]\n",
    "        trial = behaviorfil[:,2]\n",
    "        rawtrialfil = raw.item().get('trialfil')\n",
    "        \n",
    "        #Find any skipped trials\n",
    "        try:\n",
    "            _ = raw.item().get('correctedtrial').shape\n",
    "            if (len(np.unique(trial)) < 220): \n",
    "                alltrial = np.arange(0, np.max(np.unique(trial)) + 1 , 1)\n",
    "            else:    \n",
    "                alltrial = np.arange(0,220,1)\n",
    "            skippedtrials = np.setdiff1d(alltrial, np.unique(trial)).astype(int)\n",
    "            #print('Skipped trials, n skipped = ' + str(len(skippedtrials)) + str(skippedtrials))\n",
    "        except: \n",
    "            skippedtrials = []\n",
    "            alltrial = np.arange(0, 220, 1)\n",
    "        \n",
    "        if np.max(np.unique(trial)) < 160: #handles truncated, shorter sessions \n",
    "            alltrial = np.arange(0, np.max(np.unique(trial)) + 2, 1)\n",
    "            #print(m, s)\n",
    "        else:\n",
    "            alltrial = np.arange(0,220,1)\n",
    "\n",
    "        # Load in left vs. right info\n",
    "        trials = np.unique(trial)\n",
    "        trialinfo = raw.item().get('trialinfo')\n",
    "        left = trialinfo['left']\n",
    "        \n",
    "        #sort trial labels to correspond\n",
    "        posxcopy = posx.copy()\n",
    "        leftsort = left.copy()\n",
    "        alt_idx = 140\n",
    "        lefttail = left[alt_idx:]\n",
    "        lefttail = 1 - lefttail\n",
    "        leftsort[alt_idx:] = lefttail[np.argsort(lefttail, kind = 'stable')]\n",
    "\n",
    "        #revise skippedtrials locations\n",
    "        allcopy = alltrial.copy()\n",
    "        alltail = alltrial[alt_idx:]\n",
    "        allcopy[alt_idx:] = alltail[np.argsort(lefttail, kind = 'stable')]\n",
    "        newskippedtrials = []\n",
    "        for z in skippedtrials:\n",
    "            newskippedtrials = np.append(newskippedtrials, np.where(allcopy == z)[0][0])\n",
    "\n",
    "        ndarkskipped = 0\n",
    "        for z in newskippedtrials:\n",
    "            if z < 20: \n",
    "                ndarkskipped += 1\n",
    "                \n",
    "        #sort position & spike train, all copy is in the sorted order\n",
    "        posxcopy = []\n",
    "        allcopy = np.append(allcopy, 220)\n",
    "        for t in allcopy:\n",
    "            obs_idx = np.where(trial == t)[0]\n",
    "            posxcopy = np.append(posxcopy, posx[obs_idx])\n",
    "\n",
    "            if t == 0:\n",
    "                Z = Y[obs_idx,:]\n",
    "            else: \n",
    "                Z = np.append(Z, Y[obs_idx,:], axis = 0)\n",
    "\n",
    "        #adjust trialfil so that sorted trials are skipped instead\n",
    "        count = 0\n",
    "        if len(skippedtrials) > 0 :\n",
    "            skippedrawtrialfil = rawtrialfil.copy()\n",
    "            consec = count_consec(list(np.sort(newskippedtrials).astype(int)))\n",
    "\n",
    "            for i, k in enumerate(consec):\n",
    "                t = np.sort(newskippedtrials)[count] \n",
    "                #print(i,t,k)\n",
    "\n",
    "                if i == 0: \n",
    "                    skippedrawtrialfil[rawtrialfil >= t] = skippedrawtrialfil[rawtrialfil >= t] + k\n",
    "                else: \n",
    "                    skippedrawtrialfil[skippedrawtrialfil >= t] = skippedrawtrialfil[skippedrawtrialfil >= t] + k\n",
    "\n",
    "                count += k\n",
    "        else:\n",
    "            skippedrawtrialfil = trial.copy()\n",
    "            \n",
    "        #remove dark & trial 220 dataframes     \n",
    "        start_idx = (np.where(skippedrawtrialfil >= 20)[0][0]).astype(int)\n",
    "        if np.max(skippedrawtrialfil) > 200:\n",
    "            end_idx = (np.where(skippedrawtrialfil >= 200)[0][0])\n",
    "        else:\n",
    "            end_idx = len(skippedrawtrialfil) + 1\n",
    "\n",
    "        #divide observations into front and back halves\n",
    "        frontidx = np.where(posxcopy < 200)[0].astype(int)\n",
    "        backidx = np.where(posxcopy >= 200)[0].astype(int)\n",
    "        VRidx = np.arange(start_idx, end_idx, 1)\n",
    "        VRfrontidx = np.intersect1d(VRidx, frontidx)\n",
    "        VRbackidx = np.intersect1d(VRidx, backidx)\n",
    "        \n",
    "        d['VRbackidx'] = VRbackidx\n",
    "        #VRbackidx_file = 'VRbackidx_' + m + '_' + s + '.npy'\n",
    "        #np.save(save_folder + VRbackidx_file, VRbackidx)\n",
    "        \n",
    "        d['skippedrawtrialfil'] = skippedrawtrialfil\n",
    "        #skippedrawtrialfil_file = 'skippedrawtrialfil_' + m + '_' + s + '.npy'\n",
    "        #np.save(save_folder + skippedrawtrialfil_file, skippedrawtrialfil)\n",
    "        \n",
    "        #get smoothed by trial FR matrix excluding dark period sorted by context using front half of track\n",
    "        normFR, _, _ = tuning_curve_bytrial(posxcopy[VRbackidx], skippedrawtrialfil[VRbackidx], Z[VRbackidx,:], dt, sigma = 5, b=2, smooth=True, normalize=True, occupancy=True)\n",
    "        \n",
    "        #get & plot similarity matrix for all spatial cells\n",
    "        sdx = []\n",
    "        for i, c in enumerate(spatialcells):\n",
    "            sd = (np.where(cell_IDs == c)[0][0]).astype(int)\n",
    "            sdx.append(sd)\n",
    "            \n",
    "        normspatialFR = normFR[:,:,sdx] \n",
    "        \n",
    "        if len(spatialcells) > 10:\n",
    "            #save spatial cell network FR tensor \n",
    "            d['spatialFRtensorbacksorted'] = normspatialFR\n",
    "            FRtensor_file = 'SM_spatialFRtensorbacksorted_' + m + '_' + s + '.npy'\n",
    "            np.save(save_folder + FRtensor_file, d['spatialFRtensorbacksorted'])\n",
    "            \n",
    "            #save spatial cell network trial by trial sim matrix \n",
    "            normspatialFR_unwrapped = np.reshape(normspatialFR, (normspatialFR.shape[0], -1))\n",
    "            sim_vec = np.abs(pdist(normspatialFR_unwrapped, 'correlation')-1)\n",
    "            sim = squareform(sim_vec)  \n",
    "            d['spatialsimilaritybacksorted'] = sim\n",
    "        else:\n",
    "            print('too few spatial cells in session: ' + str(m) + ', ' + str(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e848de50",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee22994680cb4410873f2672e7812ced",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "too few grid cells in session: A14, 083022_record1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "111fc1be48354abab025c8fd88fc2fec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "too few grid cells in session: A15, 083022_record1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "197b8df608e744ed82a89be496d40a49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "too few grid cells in session: A16, 090122_record3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac36d69b5c7947ea9cac9e6eb72c38bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "too few grid cells in session: A17, 082322_record1\n",
      "too few grid cells in session: A17, 082422_record2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18c7ff4fbef94550ace515419c9ce7e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "too few grid cells in session: A18, 082822_record6\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9181c8481e394f4c908b271c28e66f41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec0f240bfb284ebea379a6cab2f39080",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "too few grid cells in session: A20, 012623_record1\n",
      "too few grid cells in session: A20, 013123_record6\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57b2c04d331d4607b8deeeb5f9c146b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bda41f9365b74959b64416a2ea30ba4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "too few grid cells in session: A23, 020923_record1\n",
      "too few grid cells in session: A23, 021223_record4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ff5f9c638a44cd9a4f86431a5779d08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed237e7ecff64b11af0501d2abd1993a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2be62c40863549078433e1703d62bdc4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "too few grid cells in session: MA1F, 102622_record4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d38f09d3c5e5479683b4cceb0e5b564a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "248edc4feb5b450d859fe43249737496",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "too few grid cells in session: MA3M, 102322_record1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5455e24554d34f57aabb17ce2f94ddf7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "too few grid cells in session: MA4M, 110222_record4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "129dbfcb679140948b61ab91ed74a8b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "too few grid cells in session: MA5M, 110922_record4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "449865ad3ba44c0ea4e6667a46089ba0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "too few grid cells in session: MA6M, 110222_record4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abc2fbd13bfb4b0b90b66f8c984200f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "too few grid cells in session: MA7M, 110222_record4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7b1b3a6f0674f63a4ebda768b30dc87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ff097f4c4e442628f6109c151d4ebb8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "too few grid cells in session: MA9F, 111622_record4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eef5de2cb61b41daaa85138835c7c484",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "too few grid cells in session: Y20, 092522_record1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "581c73a28f384a86a5e2431399532e3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "too few grid cells in session: Y21, 092322_record6\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "381949ef890949d7a0edd2e108e74b20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89679224f2214add9311bf2ccfb4c3a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82ae68d87ab54bc697adedd11ce5b297",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98eece6e76814ddcbc85c86b2a7f1071",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "too few grid cells in session: Y25, 021623_record1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6bfe4e45e12d42cfb1d676136b8c9020",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "too few grid cells in session: Y26, 021923_record4\n",
      "too few grid cells in session: Y26, 022123_record6\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "acee5e385c014175aedae52f3b8380db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d833255085024d0c9196ccc9eecd5181",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "too few grid cells in session: Y28, 022623_record1\n"
     ]
    }
   ],
   "source": [
    "''' Load Sorted Normalized FR Tensor for Spatial Network in Back of Track, excluding Gain Change Period '''\n",
    "\n",
    "from scipy.spatial.distance import pdist\n",
    "from scipy.spatial.distance import squareform\n",
    "\n",
    "dt = 0.02\n",
    "save_folder = 'C:/Users/Python/Desktop/LocalData/spatialcellssm/simmatrices/'\n",
    "\n",
    "for m, session in zip(mice, sessions):\n",
    "    for s in tdqm(session):\n",
    "        d = data[m][s]\n",
    "         \n",
    "        VRbackidx_file = 'VRbackidx_' + m + '_' + s + '.npy'\n",
    "        VRbackidx = np.load(save_folder + VRbackidx_file)\n",
    "        d['VRbackidx'] = VRbackidx\n",
    "        \n",
    "        skippedrawtrialfil_file = 'skippedrawtrialfil_' + m + '_' + s + '.npy'\n",
    "        skippedrawtrialfil = np.load(save_folder + skippedrawtrialfil_file)\n",
    "        d['skippedrawtrialfil'] = skippedrawtrialfil\n",
    "        \n",
    "        #get some data & cell IDs\n",
    "        rawdata_file = 'RAW_' + m + '_' + s + '.npy'\n",
    "        raw = np.load(load_folder + rawdata_file, allow_pickle=True)\n",
    "        \n",
    "        cell_IDs = raw.item().get('cellsfil')\n",
    "        spatialcell = d['spatialcell99'].astype(bool)\n",
    "        spatialcells = cell_IDs[spatialcell]     \n",
    "        \n",
    "        if len(spatialcells) > 10:\n",
    "            #load grid network FR tensor \n",
    "            FRtensor_file = 'SM_spatialFRtensorbacksorted_' + m + '_' + s + '.npy'\n",
    "            normspatialFR = np.load(save_folder + FRtensor_file)\n",
    "            d['spatialFRtensorbacksorted'] = normspatialFR \n",
    "            \n",
    "            #get grid network trial by trial sim matrix \n",
    "            normspatialFR_unwrapped = np.reshape(normspatialFR, (normspatialFR.shape[0], -1))\n",
    "            sim_vec = np.abs(pdist(normspatialFR_unwrapped, 'correlation')-1)\n",
    "            sim = squareform(sim_vec)  \n",
    "            d['spatialsimilaritybacksorted'] = sim\n",
    "        else:\n",
    "            print('too few spatial cells in session: ' + str(m) + ', ' + str(s))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6ec4432",
   "metadata": {},
   "source": [
    "# Optimize K-Means k parameter for each session (k = 1 - 4) or load results of k optimization code if run previously. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d727ed0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Load in KMeans '''\n",
    "\n",
    "from lvl.factor_models import KMeans as lvl_kmeans\n",
    "from lvl.factor_models import NMF as lvl_soft_kmeans\n",
    "from lvl.resamplers import RotationResampler\n",
    "from lvl.crossval import speckled_cv_scores \n",
    "from scipy.spatial.distance import cdist \n",
    "from scipy.special import logsumexp\n",
    "from sklearn.metrics import silhouette_samples, silhouette_score\n",
    "\n",
    "def softmax(M):\n",
    "    return np.exp(M - logsumexp(M, axis=-1, keepdims=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74636390",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' K Hyperparameter Selection (k = 1-4); plot Figure S4A & S4C along the way\n",
    "\n",
    "Y_unwrapped: matrix of shape m, n; m = n_trials & n = (nposbins * ncells)\n",
    "W: first factor matrix. Has shape (m, rank) or n_trials, n_clusters (i.e. [0, 1] if map 1 and [1, 0] if map 0)\n",
    "H: second factor matrix. Has shape (rank, n) or n_clusters, n_obs\n",
    "\n",
    "Run time is about 5 - 15 minutes per session.\n",
    "\n",
    "'''\n",
    "possible_k = np.arange(2, 5, 1)\n",
    "extended_k = np.arange(1,5,1)\n",
    "colors = ['xkcd:pink','xkcd:blue','xkcd:orchid','xkcd:azure']\n",
    "n_reps = 10 \n",
    "alpha = 0.05\n",
    "\n",
    "save_folder = 'C:/Users/Python/Desktop/LocalData/spatialcellssm/kmeans/spatial/' # adjust path\n",
    "\n",
    "# if you want to visualize the quality of k selection for all sessions vs. just the examples in Figure S4A & C:\n",
    "example_mice = mice\n",
    "example_sessions = sessions\n",
    "\n",
    "# if you want to visualize the quality of k selection for only the example sessions in Figure S4A & C\n",
    "#example_mice = ['Y23', 'Y20', 'Y22', 'A16']\n",
    "#example_sessions = ['092722_record3','090222_record4']\n",
    "\n",
    "for m, session in zip(mice, sessions):\n",
    "    for s in tdqm(session):\n",
    "        d = data[m][s]\n",
    "                \n",
    "        rawdata_file = 'RAW_' + m + '_' + s + '.npy'\n",
    "        raw = np.load(load_folder + rawdata_file, allow_pickle=True)\n",
    "        cell_IDs = raw.item().get('cellsfil')\n",
    "        spatialcell = d['spatialcell99'].astype(bool)\n",
    "        spatialcells = cell_IDs[spatialcell]     \n",
    "        \n",
    "        if len(spatialcells) > 10: \n",
    "            \n",
    "            Y = d['spatialFRtensorbacksorted'].copy()\n",
    "            Y = Y.transpose(0, 2, 1)\n",
    "            Y_unwrapped = np.reshape(Y, (Y.shape[0], -1))\n",
    "            \n",
    "            #Run k-means ten times and choose the k that most frequently most often maximizes the average silhouette score \n",
    "            silhouette_avgs = np.zeros((n_reps, len(possible_k)))\n",
    "            for p in range(n_reps):\n",
    "                sil_avgs = []\n",
    "                for n in possible_k:     \n",
    "                    # fit model and get params\n",
    "                    model_kmeans = lvl_kmeans(n_components = n, n_restarts = 100)\n",
    "                    model_kmeans.fit(Y_unwrapped)\n",
    "                    W, _ = model_kmeans.factors\n",
    "                    labels = []\n",
    "                    for t in range(W.shape[0]):\n",
    "                        mapid = np.where(W[t,:] == 1)[0]\n",
    "                        labels = np.append(labels, mapid)\n",
    "                    sil_avgs = np.append(sil_avgs, silhouette_score(Y_unwrapped, labels))\n",
    "                silhouette_avgs[p,:] = sil_avgs\n",
    "            \n",
    "            #compare test R^2 vs. shuffle for k = 1-4\n",
    "            # Run cross-validated k-means with speckled holdout pattern.\n",
    "            km_train_scores = np.ones((4, n_reps))\n",
    "            km_test_scores = np.ones((4, n_reps))\n",
    "\n",
    "            for i, rank in enumerate(tdqm(extended_k)):\n",
    "                model = lvl_kmeans(n_components=rank, n_restarts=100, maxiter=1000)\n",
    "                km_train_scores[i], km_test_scores[i] = \\\n",
    "                    speckled_cv_scores(model, Y_unwrapped, n_repeats=n_reps)\n",
    "\n",
    "            # Run cross-validated k-means on shuffled/resampled dataset.\n",
    "            shuff_km_train_scores = np.ones((4, n_reps))\n",
    "            shuff_km_test_scores = np.ones((4, n_reps))\n",
    "\n",
    "            for i, rank in enumerate(tdqm(extended_k)):\n",
    "                model = lvl_kmeans(n_components=rank, n_restarts=100, maxiter=1000)\n",
    "                shuff_km_train_scores[i], shuff_km_test_scores[i] = \\\n",
    "                    speckled_cv_scores(model, Y_unwrapped, n_repeats=n_reps, resampler=RotationResampler())\n",
    "            \n",
    "            #Select optimal k, run KMeans with that k & store results, & plot to confirm quality of results\n",
    "            if m in SM_aged_mice:\n",
    "                col = 'C1'\n",
    "            elif m in SM_MA_mice:\n",
    "                col = 'C2'\n",
    "            else:\n",
    "                col = 'C0'\n",
    "                \n",
    "            SilN = possible_k[np.argmax(np.mean(silhouette_avgs, axis = 0))]\n",
    "            print(stats.sem(silhouette_avgs, axis = 0))\n",
    "            model_kmeans = lvl_kmeans(n_components = SilN, n_restarts = 100)\n",
    "            model_kmeans.fit(Y_unwrapped)\n",
    "            W, H = model_kmeans.factors\n",
    "            Y_hat = model_kmeans.predict()\n",
    "            score = model_kmeans.score(Y_unwrapped)\n",
    "            d['kmeans'] = {}\n",
    "            d['kmeans']['SilN'] = SilN\n",
    "            d['kmeans']['W'] = W\n",
    "            d['kmeans']['H'] = H\n",
    "            d['kmeans']['Y_hat'] = Y_hat \n",
    "            d['kmeans']['Y_hat'] = Y_hat \n",
    "            d['kmeans']['score'] = score\n",
    "            \n",
    "            #save selected SilN (optimal k value)\n",
    "            SilN_file = 'SilN_' + m + '_' + s + '.npy'\n",
    "            np.save(save_folder + SilN_file, SilN)\n",
    "            \n",
    "            #check & save whether if sig difference in the distribution of test R^2 real vs. shuffle data at optimal k:\n",
    "            chosenkidx = np.where(extended_k == SilN)[0]\n",
    "            res = stats.wilcoxon(km_test_scores[chosenkidx,:][0], shuff_km_test_scores[chosenkidx,:][0], alternative = 'greater')\n",
    "            onemap = []\n",
    "            if res.pvalue <= alpha:\n",
    "                print('outperforms shuffle at optimal k = ' + str(SilN))\n",
    "                print('stat = ' + str(np.round(res.statistic,2)) + ', p= ' + str(np.round(res.pvalue, 4)))\n",
    "                onemap = np.append(onemap, [False, res.statistic, res.pvalue])\n",
    "            else:\n",
    "                print('does not outperform shuffle, probable one map session')\n",
    "                print('stat = ' + str(np.round(res.statistic,2)) + ', p= ' + str(np.round(res.pvalue, 4)))\n",
    "                onemap = np.append(onemap, [True, res.statistic, res.pvalue])\n",
    "\n",
    "            #save boolean of whether the session was fit well by k > 1 (onemap = False)\n",
    "            d['kmeans']['onemap'] = onemap\n",
    "            onemapfile = 'onemap' + m + '_' + s + '.npy'\n",
    "            np.save(save_folder + onemapfile, onemap)\n",
    "            \n",
    "            #get map labels & silhouette scores for samples & on average\n",
    "            labels = []\n",
    "            for t in range(W.shape[0]):\n",
    "                mapid = np.where(W[t,:] == 1)[0]\n",
    "                labels = np.append(labels, mapid)\n",
    "            silhouette_avg = silhouette_score(Y_unwrapped, labels)\n",
    "            samp_sil = silhouette_samples(Y_unwrapped, labels)\n",
    "\n",
    "            ##SHOW GOODNESS OF CHOSEN as in Figures S4A & C\n",
    "            #Plot silhouette averages + SEM over ten reps. \n",
    "            \n",
    "            if (m in example_mice) and (s in example_sessions):\n",
    "\n",
    "                fig, ax = plt.subplots(2, 2, figsize = (2,2), sharey = False)\n",
    "                plt.subplots_adjust(hspace = 0.5, wspace = 0.5)\n",
    "                fig.suptitle(str(m) + '_' + str(s[-1]) + ', One Map = ' + str(onemap[0].astype(bool)) + ', Optimal k = ' + str(SilN), color = col, fontsize = 10)\n",
    "\n",
    "                #plot sparsely labeled sim matrix \n",
    "                sim = d['spatialsimilaritybacksorted']\n",
    "                im = ax[0,0].imshow(sim, clim=[0, 1.0], aspect='auto', cmap='Greys', interpolation='none')\n",
    "                ax[0,0].tick_params(which='major', labelsize=8)\n",
    "                ax[0,0].set_ylabel('Trial Number', fontsize=9, labelpad=1)\n",
    "                ax[0,0].set_xlabel('Trial Number', fontsize=9, labelpad=1)\n",
    "                ax[0,0].set_yticks([])\n",
    "                ax[0,0].set_xticks([0, 90, 180])\n",
    "                ax[0,0].tick_params(labelsize = 8)\n",
    "\n",
    "                #plot test R^2 vs. shuffle\n",
    "                rax = np.tile(extended_k, (n_reps, 1)).T.ravel()\n",
    "                ax[0,1].plot(rax-.1, km_test_scores.ravel(), '.', color = col, label = 'Data');\n",
    "                ax[0,1].plot(rax+.1, shuff_km_test_scores.ravel(), '.k', label = 'Shuffle');\n",
    "                ax[0,1].set_xticks(extended_k, labels = None)\n",
    "                ax[0,1].set_ylabel(\"R**2\", fontsize = 9)\n",
    "                ax[0,1].set_xlabel('K', fontsize=9)\n",
    "                ax[0,1].set_yticks([])\n",
    "                #ax[0,1].legend(fontsize = 8)\n",
    "                ax[0,1].tick_params(labelsize = 8)\n",
    "\n",
    "                #plot of k selection criteria over n reps\n",
    "                ax[1,0].plot(possible_k, np.mean(silhouette_avgs, axis = 0), color = col)\n",
    "                ax[1,0].fill_between(possible_k, np.mean(silhouette_avgs, axis = 0) - stats.sem(silhouette_avgs, axis = 0),\n",
    "                                   np.mean(silhouette_avgs, axis = 0) + stats.sem(silhouette_avgs, axis = 0), facecolor = col, alpha = 0.2)\n",
    "                ax[1,0].scatter(SilN, np.max(np.mean(silhouette_avgs, axis = 0)), color = 'k', marker = 'x')\n",
    "                ax[1,0].set_xlim([2,4])\n",
    "                ax[1,0].set_xticks(possible_k, labels = None)\n",
    "                ax[1,0].set_yticks([])\n",
    "                ax[1,0].set_ylabel('Avg. Sil Score', fontsize=9)\n",
    "                ax[1,0].set_xlabel('K', fontsize=9)\n",
    "                ax[1,0].tick_params(labelsize = 8)\n",
    "\n",
    "                #plot of k selection criteria over n reps\n",
    "                ax[1,1].set_xlim([-0.2, 1.0])\n",
    "                ax[1,1].set_ylim([0, len(Y_unwrapped) + (SilN + 1) * 10])\n",
    "                y_lower = 10\n",
    "                for i in range(SilN):\n",
    "                    ith_cluster_silhouette_values = samp_sil[labels == i]\n",
    "                    ith_cluster_silhouette_values.sort()\n",
    "                    size_cluster_i = ith_cluster_silhouette_values.shape[0]\n",
    "                    y_upper = y_lower + size_cluster_i\n",
    "                    color = colors[i]\n",
    "                    ax[1,1].fill_betweenx(np.arange(y_lower, y_upper),0,\n",
    "                        ith_cluster_silhouette_values,facecolor=color,edgecolor=color,alpha=0.7)\n",
    "                    #ax[1,1].text(-0.05, y_lower + 0.5 * size_cluster_i, str(i))\n",
    "                    y_lower = y_upper + 10  # 10 for the 0 samples\n",
    "                ax[1,1].set_xlabel(\"Silhouette Score\", fontsize = 9)\n",
    "                ax[1,1].set_ylabel(\"Cluster\", fontsize = 9)\n",
    "                ax[1,1].axvline(x=silhouette_avg, color = \"k\", linestyle=\"--\")\n",
    "                ax[1,1].set_yticks([]) \n",
    "                ax[1,1].set_xticks([-0.2, 0.2, 0.6, 1.0])\n",
    "                ax[1,1].tick_params(labelsize = 8)\n",
    "\n",
    "                #plt.tight_layout()\n",
    "                plt.savefig(save_folder + m + '_' + s + '_chosenk.png', dpi=400, bbox_inches='tight')\n",
    "                plt.savefig(save_folder + m + '_' + s + '_chosenk.svg', dpi=400, bbox_inches='tight')\n",
    "                plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bf6ae72",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "''' After k optimization, load in results & perform K-means '''\n",
    "\n",
    "kmeans_folder = 'C:/Users/Python/Desktop/LocalData/spatialcellssm/kmeans/spatial/' #adjust path to output above this \n",
    "\n",
    "from scipy.spatial.distance import pdist\n",
    "from scipy.spatial.distance import squareform\n",
    "\n",
    "for m, session in zip(mice, sessions):\n",
    "    for s in tdqm(session):\n",
    "        d = data[m][s]\n",
    "                \n",
    "        rawdata_file = 'RAW_' + m + '_' + s + '.npy'\n",
    "        raw = np.load(load_folder + rawdata_file, allow_pickle=True)\n",
    "        cell_IDs = raw.item().get('cellsfil')\n",
    "        spatialcell = d['spatialcell99'].astype(bool)\n",
    "        spatialcells = cell_IDs[spatialcell]     \n",
    "        \n",
    "        if len(spatialcells) > 10: \n",
    "            \n",
    "            #Load stuff I have saved previously\n",
    "            SilN_file = 'SilN_' + m + '_' + s + '.npy'\n",
    "            SilN = np.load(kmeans_folder + SilN_file)\n",
    "            \n",
    "            #fit K-means\n",
    "            Y = d['spatialFRtensorbacksorted'].copy()\n",
    "            Y = Y.transpose(0, 2, 1)\n",
    "            Y_unwrapped = np.reshape(Y, (Y.shape[0], -1))\n",
    "            \n",
    "            model_kmeans = lvl_kmeans(n_components = SilN, n_restarts = 100)\n",
    "            model_kmeans.fit(Y_unwrapped)\n",
    "            W, H = model_kmeans.factors\n",
    "            Y_hat = model_kmeans.predict()\n",
    "            score = model_kmeans.score(Y_unwrapped)\n",
    "            d['kmeans'] = {}\n",
    "            d['kmeans']['SilN'] = SilN\n",
    "            d['kmeans']['W'] = W\n",
    "            d['kmeans']['H'] = H\n",
    "            d['kmeans']['Y_hat'] = Y_hat \n",
    "            d['kmeans']['Y_hat'] = Y_hat \n",
    "            d['kmeans']['score'] = score\n",
    "            \n",
    "            #load boolean to determine if I should keep k-means map in dataset (better than shuffle at chosen k)\n",
    "            onemapfile = 'onemap' + m + '_' + s + '.npy'\n",
    "            onemap = np.load(kmeans_folder + onemapfile)\n",
    "            d['kmeans']['onemap'] = onemap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85c61720",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Plot Figure S4E (Right): Histogram of Optimal K for Split Maze Sessions'''\n",
    "allks = []\n",
    "optimalks = []\n",
    "yk = []\n",
    "mak = []\n",
    "ak =[]\n",
    "for m, session in zip(mice, sessions):\n",
    "    for s in session:\n",
    "        d = data[m][s]\n",
    "        \n",
    "        #get some data & cell IDs\n",
    "        rawdata_file = 'RAW_' + m + '_' + s + '.npy'\n",
    "        spikes_file = 'SPIKES_' + m + '_' + s +'.npy'\n",
    "        behavior_file = 'BEHAVIOR_' + m + '_' + s + '.npy'\n",
    "        \n",
    "        raw = np.load(load_folder + rawdata_file, allow_pickle=True)\n",
    "        Y = np.load(load_folder + spikes_file, allow_pickle=False) #pre-filtered for speeds >2cm/s, position-corrected spikes, 20 ms timebins\n",
    "        behaviorfil = np.load(load_folder + behavior_file, allow_pickle=False)\n",
    "        \n",
    "        cell_IDs = raw.item().get('cellsfil')\n",
    "        spatialcell = d['spatialcell99'].astype(bool)\n",
    "        spatialcells = cell_IDs[spatialcell]   \n",
    "        \n",
    "        if len(spatialcells) > 10:\n",
    "            SilN = d['kmeans']['SilN']\n",
    "            onemap = d['kmeans']['onemap'] # vector [one map boolean, WSR Stat, WSR P-Value]\n",
    "            \n",
    "            if onemap[0].astype(bool) == True:\n",
    "                optimalks = np.append(optimalks, 1)\n",
    "                allks = np.append(allks, 1)\n",
    "                \n",
    "                if m in SM_aged_mice:\n",
    "                    ak = np.append(ak, 1)\n",
    "                elif m in SM_MA_mice:\n",
    "                    mak = np.append(mak, 1)\n",
    "                else:\n",
    "                    yk = np.append(yk, 1)\n",
    "                \n",
    "            else:\n",
    "                optimalks = np.append(optimalks, SilN)\n",
    "                allks = np.append(allks, SilN)\n",
    "                \n",
    "                if m in SM_aged_mice:\n",
    "                    ak = np.append(ak, SilN)\n",
    "                elif m in SM_MA_mice:\n",
    "                    mak = np.append(mak, SilN)\n",
    "                else:\n",
    "                    yk = np.append(yk, SilN)\n",
    "        else:\n",
    "            allks = np.append(allks, np.nan)\n",
    "\n",
    "#Plot half of Figure S4E\n",
    "kbins = np.arange(1,5,1)\n",
    "fig, ax = plt.subplots(figsize = (1.4,1))\n",
    "\n",
    "allk, bin_edges = np.histogram(optimalks, bins = [1,2,3,4,5])\n",
    "pdf = allk / sum(allk)\n",
    "ax.plot(kbins, pdf, '-', linewidth = 0.75, alpha = 1, color = 'k', label = 'All')\n",
    "\n",
    "y, bin_edges = np.histogram(yk, bins = [1,2,3,4,5])\n",
    "pdf = y / sum(y)\n",
    "ax.plot(kbins, pdf, '-', linewidth = 0.75, alpha = 1, color = 'C0', label = 'Young')\n",
    "\n",
    "ma, bin_edges = np.histogram(mak, bins = [1,2,3,4,5])\n",
    "pdf = ma / sum(ma)\n",
    "ax.plot(kbins, pdf, '-', linewidth = 0.75, alpha = 1, color = 'C2', label = 'MA')\n",
    "\n",
    "a, bin_edges = np.histogram(ak, bins = [1,2,3,4,5])\n",
    "pdf = a / sum(a)\n",
    "ax.plot(kbins, pdf, '-', linewidth = 0.75, alpha = 1, color = 'C1', label = 'Aged')\n",
    "ax.tick_params(labelsize = 8)\n",
    "\n",
    "plt.title('Split Maze', fontsize = 10)\n",
    "plt.ylabel('Density', fontsize = 9)\n",
    "plt.xlabel('Optimal K', fontsize = 9)\n",
    "plt.xlim([1,4])\n",
    "plt.xticks([1,2,3,4])\n",
    "plt.yticks([0,0.2,0.4,0.6,0.8,1.0])\n",
    "plt.ylim([0,1])\n",
    "\n",
    "ax.legend(bbox_to_anchor = (1,1), fontsize = 8)\n",
    "#plt.savefig(save_folder + 'allsmoptimalkpdf.png', dpi=400, bbox_inches='tight')\n",
    "#plt.savefig(save_folder + 'allsmoptimalkpdf.svg', dpi=400, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "#run KS on optimal k distributions\n",
    "print('\\nOptimal K KS:')\n",
    "res = stats.ks_2samp(ak,yk, alternative = 'two-sided')\n",
    "stat = res.statistic; p_value = res.pvalue; loc = res.statistic_location; sign = res.statistic_sign\n",
    "print('A vs. Y CDF: Stat ' + str(stat) + ', p=' + str(p_value) + ', sign=' + str(sign) + ', loc=' + str(loc))\n",
    "\n",
    "res = stats.ks_2samp(mak,yk, alternative = 'two-sided')\n",
    "stat = res.statistic; p_value = res.pvalue; loc = res.statistic_location; sign = res.statistic_sign\n",
    "print('MA vs. Y CDF: Stat ' + str(stat) + ', p=' + str(p_value) + ', sign=' + str(sign) + ', loc=' + str(loc))\n",
    "\n",
    "res = stats.ks_2samp(ak,mak, alternative = 'two-sided')\n",
    "stat = res.statistic; p_value = res.pvalue; loc = res.statistic_location; sign = res.statistic_sign\n",
    "print('A vs. MA CDF: Stat ' + str(stat) + ', p=' + str(p_value) + ', sign=' + str(sign) + ', loc=' + str(loc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01169b0f",
   "metadata": {},
   "source": [
    "# Compare remapping frequency across age groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b17ec475",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Get remapping frequency by task phase across age groups'''\n",
    "\n",
    "#get remap indices not requiring minimum map size\n",
    "for m, session in zip(mice, sessions):\n",
    "    for s in session:\n",
    "        d = data[m][s]\n",
    "        \n",
    "        rawdata_file = 'RAW_' + m + '_' + s + '.npy'\n",
    "        raw = np.load(load_folder + rawdata_file, allow_pickle=True)\n",
    "        cell_IDs = raw.item().get('cellsfil')\n",
    "        spatialcell = d['spatialcell99'].astype(bool)\n",
    "        spatialcells = cell_IDs[spatialcell]\n",
    "        \n",
    "        if len(spatialcells) > 10: \n",
    "            \n",
    "            W = d['kmeans']['W']\n",
    "            trials = np.arange(0, W.shape[0]-1)\n",
    "            \n",
    "            # define remaps\n",
    "            remap_idx = np.asarray([])\n",
    "            for w in range(W.shape[1]):\n",
    "                remaps = np.where(np.abs(np.diff(W[:, w])))[0]\n",
    "                remap_idx = np.append(remap_idx, remaps)\n",
    "            remap_idx = np.unique(remap_idx)\n",
    "            stable_idx = np.setdiff1d(trials,remap_idx)\n",
    "            \n",
    "            # save remap vs. stable indices\n",
    "            d['remap_idx'] = [stable_idx.astype(int), remap_idx.astype(int)]\n",
    "\n",
    "# get remapping frequency            \n",
    "sblockremaps = []\n",
    "saltremaps = []\n",
    "spatialmultimapsesh = []\n",
    "\n",
    "for m, session in zip(mice, sessions):\n",
    "    for s in session:\n",
    "        d = data[m][s]\n",
    "        rawdata_file = 'RAW_' + m + '_' + s + '.npy'\n",
    "        raw = np.load(load_folder + rawdata_file, allow_pickle=True)\n",
    "        cell_IDs = raw.item().get('cellsfil')\n",
    "        spatialcell = d['spatialcell99'].astype(bool)\n",
    "        spatialcells = cell_IDs[spatialcell]\n",
    "        \n",
    "        if len(spatialcells) > 10: \n",
    "            onemap = d['kmeans']['onemap']\n",
    "            \n",
    "            if onemap[0].astype(bool) == True:\n",
    "                spatialmultimapsesh = np.append(spatialmultimapsesh, False)\n",
    "                print('skipping remapping assessment for one-map sesh ' + str(m) + ', ' + str(s))\n",
    "                \n",
    "                sblockremaps = np.append(sblockremaps, np.nan)\n",
    "                saltremaps = np.append(saltremaps, np.nan)\n",
    "                \n",
    "            else:\n",
    "                W = d['kmeans']['W']\n",
    "                trials = np.arange(0, W.shape[0]-1)\n",
    "                remap_idx = d['remap_idx'][1]\n",
    "                spatialmultimapsesh = np.append(spatialmultimapsesh, True)\n",
    "\n",
    "                # Load in left vs. right info\n",
    "                trialinfo = raw.item().get('trialinfo')\n",
    "                left = trialinfo['left']\n",
    "\n",
    "                skippedrawtrialfil = d['skippedrawtrialfil'].astype(int)\n",
    "                VRbackidx = d['VRbackidx'].astype(int)\n",
    "\n",
    "                #binary context vector, excluding skipped trials, dark, & gain periods, 1 = Map A\n",
    "                leftsort = left.copy()\n",
    "                alt_idx = 140\n",
    "                lefttail = left[alt_idx:]\n",
    "                leftsort[alt_idx:] = lefttail[np.argsort(-1*lefttail, kind = 'stable')]\n",
    "\n",
    "                context = []\n",
    "                for i, t in enumerate(np.unique(skippedrawtrialfil[VRbackidx])):\n",
    "                    context = np.append(context, leftsort[t.astype(int)])\n",
    "                altcontextidx = np.where(np.diff(context) == 1.)[0][0] + 1 #index where alternation begins in context vectors\n",
    "\n",
    "                #get n_switches & remap_idx for block only\n",
    "                blockremap_idx = remap_idx[remap_idx < altcontextidx]\n",
    "                sblockremaps = np.append(sblockremaps, blockremap_idx.shape[0]/len(trials[:altcontextidx]))\n",
    "                   \n",
    "                altremap_idx = remap_idx[remap_idx >= altcontextidx]\n",
    "                saltremaps = np.append(saltremaps, altremap_idx.shape[0]/len(trials[altcontextidx:]))\n",
    "        else:\n",
    "            spatialmultimapsesh = np.append(spatialmultimapsesh, False)\n",
    "            sblockremaps = np.append(sblockremaps, np.nan)\n",
    "            saltremaps = np.append(saltremaps, np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "936211ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Find where nan and ignore for plotting '''\n",
    "nan_idx10spatial = np.where((spatialmultimapsesh.astype(bool) == 0))[0]\n",
    "\n",
    "# Adjust y_sind, ma_sind, age_sind for subsequent plots\n",
    "y_sind10spatial = np.setdiff1d(y_sind, nan_idx10spatial)\n",
    "ma_sind10spatial = np.setdiff1d(ma_sind, nan_idx10spatial)\n",
    "age_sind10spatial = np.setdiff1d(age_sind, nan_idx10spatial)\n",
    "\n",
    "# Adjust colormaps for plots\n",
    "yidx = []\n",
    "maidx = []\n",
    "aidx = []\n",
    "for i in nan_idx10spatial:\n",
    "    yidx = np.append(yidx, np.where(y_sind == i)[0].astype(int))\n",
    "    maidx = np.append(maidx, np.where(ma_sind == i)[0].astype(int))\n",
    "    aidx = np.append(aidx, np.where(age_sind == i)[0].astype(int)) \n",
    "\n",
    "col_session_young10spatial = np.delete(col_session_young, list(yidx.astype(int)), axis = 0)\n",
    "col_session_ma10spatial = np.delete(col_session_MA, list(maidx.astype(int)), axis = 0)\n",
    "col_session_old10spatial = np.delete(col_session_old, list(aidx.astype(int)), axis = 0)\n",
    "col_session10spatial = [col_session_young10spatial, col_session_ma10spatial, col_session_old10spatial] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7818796d",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Plot Figure 3B, comparing remapping frequency across groups in the Split Maze'''\n",
    "\n",
    "fig, ax = plt.subplots(1,2, figsize = (4,2.25), sharey = True)\n",
    "fig.suptitle('Remapping Frequency by Task Phase', fontsize = 10, y = 0.9)\n",
    "\n",
    "sblockremaps_tog = [sblockremaps[y_sind10spatial], sblockremaps[ma_sind10spatial],sblockremaps[age_sind10spatial]]\n",
    "labels = ['Young','MA','Aged']\n",
    "w = 0.5\n",
    "ax[0].boxplot(sblockremaps_tog, widths = w, labels = labels, medianprops = dict(color = 'black'))\n",
    "ax[0].set_xlabel('Age', fontsize=9, labelpad=1)\n",
    "ax[0].set_xticklabels(labels = labels, fontsize = 9)\n",
    "ax[0].tick_params(labelsize = 8)\n",
    "ax[0].set_ylabel('Remaps / Trial', fontsize=9, labelpad=1)\n",
    "ax[0].set_yticks([0,0.1,0.2,0.3,0.4,0.5])\n",
    "ax[0].set_ylim([-0.05,0.55])\n",
    "ax[0].set_title('Blocks', fontsize = 10, pad = 3)\n",
    "\n",
    "for i in range(len(sblockremaps_tog)):\n",
    "    y = sblockremaps_tog[i]\n",
    "    x = np.random.normal(i + 1, 0.04, len(y))\n",
    "    ax[0].scatter(x, y, color = col_session10spatial[i][:len(y)], edgecolors = col_session10spatial[i][:len(y)], alpha = 1, s = 10)\n",
    "    \n",
    "saltremaps_tog = [saltremaps[y_sind10spatial], saltremaps[ma_sind10spatial],saltremaps[age_sind10spatial]]\n",
    "labels = ['Young','MA','Aged']\n",
    "w = 0.5\n",
    "ax[1].boxplot(saltremaps_tog, widths = w, labels = labels, medianprops = dict(color = 'black'))\n",
    "ax[1].set_xlabel('Age', fontsize=9, labelpad=1)\n",
    "#ax[1].set_ylabel('Remaps / Trial', fontsize=9, labelpad=1)\n",
    "ax[1].set_xticklabels(labels = labels, fontsize = 8)\n",
    "ax[1].tick_params(labelsize = 8)\n",
    "ax[1].set_yticks([0,0.1,0.2,0.3,0.4,0.5])\n",
    "ax[1].set_title('Alternation', fontsize = 10, pad = 3)\n",
    "\n",
    "for i in range(len(saltremaps_tog)):\n",
    "    y = saltremaps_tog[i]\n",
    "    x = np.random.normal(i + 1, 0.04, len(y))\n",
    "    ax[1].scatter(x, y, color = col_session10spatial[i][:len(y)], edgecolors = col_session10spatial[i][:len(y)], alpha = 1, s = 10)\n",
    "    \n",
    "#ax[1].legend(handles = handles, labels = label_mice, ncol = 2, bbox_to_anchor=(1.2, 1))\n",
    "plt.tight_layout()\n",
    "#plt.savefig(save_folder + 'remappingfreq.png', dpi=400, bbox_inches='tight')\n",
    "#plt.savefig(save_folder + 'remappingfreq.svg', dpi=400, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ba29d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Perform Kruskal Wallis Test on Remapping Frequency in each Task Phase w/ Multiple Comparisons Correcition'''\n",
    "\n",
    "print('n young, MA, aged sessions: ')\n",
    "print(len(y_sind10spatial), len(ma_sind10spatial), len(age_sind10spatial))\n",
    "\n",
    "import statsmodels.api as sm\n",
    "import scikit_posthocs as ph\n",
    "\n",
    "H, p = stats.kruskal(sblockremaps[y_sind10spatial],sblockremaps[ma_sind10spatial],sblockremaps[age_sind10spatial])\n",
    "print('block remapping freq KW test H, p = ')\n",
    "print(H, p)\n",
    "\n",
    "print('\\nmean ± SEM young block remap freq:')\n",
    "print(str(np.mean(sblockremaps[y_sind10spatial])) + ' ± '+ str(stats.sem(sblockremaps[y_sind10spatial]))) \n",
    "\n",
    "print('mean ± SEM MA block remap freq:')\n",
    "print(str(np.mean(sblockremaps[ma_sind10spatial])) + ' ± '+ str(stats.sem(sblockremaps[ma_sind10spatial]))) \n",
    "\n",
    "print('mean ± SEM age block remap freq:')\n",
    "print(str(np.mean(sblockremaps[age_sind10spatial])) + ' ± '+ str(stats.sem(sblockremaps[age_sind10spatial]))) \n",
    "\n",
    "#make into dataframe\n",
    "sex = list(animalmeta.Sex[mice_ind])\n",
    "sexes = []\n",
    "seshmice = []\n",
    "seshcount = []\n",
    "seshage = []\n",
    "for m, session in zip(mice, sessions):\n",
    "    msex = sex[np.where(mice == m)[0][0]]\n",
    "    age =  np.array(animalmeta.loc[(animalmeta.Animal_ID == m),'Age_Group'])\n",
    "    totalsesh = len(session)\n",
    "    \n",
    "    for i, s in enumerate(session):\n",
    "        sexes = np.append(sexes, msex)\n",
    "        seshmice = np.append(seshmice, m)\n",
    "        seshcount = np.append(seshcount, (i + 1))\n",
    "        seshage = np.append(seshage, age)\n",
    "\n",
    "# Collect all relevant data into pandas dataframe\n",
    "allidx = np.concatenate((y_sind10spatial,ma_sind10spatial,age_sind10spatial))\n",
    "Animal_ID = list(seshmice[allidx])\n",
    "Session = list(seshcount[allidx])\n",
    "Sex = list(sexes[allidx])\n",
    "Age_Group = list(seshage[allidx])\n",
    "BlockFreq = list(sblockremaps[allidx])\n",
    "AltFreq = list(saltremaps[allidx])\n",
    "\n",
    "tuples = list(zip(Animal_ID, Session, Sex, Age_Group, BlockFreq, AltFreq))\n",
    "tuples\n",
    "\n",
    "df = pd.DataFrame(tuples, columns = ['AnimalID', 'Session', 'Sex', 'AgeGroup','BlockFreq','AltFreq'])\n",
    "df = df.dropna(axis = 0)\n",
    "\n",
    "#Run Post Hoc Tests on Block Remapping Frequency\n",
    "ph.posthoc_conover(df, val_col = 'BlockFreq', group_col = 'AgeGroup', p_adjust = 'holm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49f07d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run Post Hoc Tests on Alt Remapping Frequency\n",
    "H, p = stats.kruskal(saltremaps[y_sind10grid],saltremaps[ma_sind10grid],saltremaps[age_sind10grid])\n",
    "print('alt remapping freq KW test H, p = ')\n",
    "print(H, p)\n",
    "\n",
    "print('\\nmean ± SEM young alt remap freq:')\n",
    "print(str(np.mean(saltremaps[y_sind10grid])) + ' ± '+ str(stats.sem(saltremaps[y_sind10grid]))) \n",
    "\n",
    "print('mean ± SEM MA alt remap freq:')\n",
    "print(str(np.mean(saltremaps[ma_sind10grid])) + ' ± '+ str(stats.sem(saltremaps[ma_sind10grid]))) \n",
    "\n",
    "print('mean ± SEM age alt remap freq:')\n",
    "print(str(np.mean(saltremaps[age_sind10grid])) + ' ± '+ str(stats.sem(saltremaps[age_sind10grid]))) \n",
    "\n",
    "ph.posthoc_conover(df, val_col = 'AltFreq', group_col = 'AgeGroup', p_adjust = 'holm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50972557",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Plot relationship between alternation behavior and remapping frequency or optimal k (Figure S4I [left & right]) '''\n",
    "\n",
    "### ALT Remaps/Trial vs. REQ RATES\n",
    "#Linear regression\n",
    "res = stats.linregress(saltremaps[y_sind10spatial],reqalt_rates[y_sind10spatial])\n",
    "yslope1 = res.slope; yint1 = res.intercept; yr1 = res.rvalue; yp1 = res.pvalue\n",
    "\n",
    "res = stats.linregress(saltremaps[ma_sind10spatial],reqalt_rates[ma_sind10spatial])\n",
    "maslope1 = res.slope; maint1 = res.intercept; mar1 = res.rvalue ; map1 = res.pvalue\n",
    "\n",
    "res = stats.linregress(saltremaps[age_sind10spatial],reqalt_rates[age_sind10spatial])\n",
    "aslope1 = res.slope; aint1 = res.intercept; ar1 = res.rvalue ; ap1 = res.pvalue\n",
    "\n",
    "allidx = np.concatenate((y_sind10spatial,ma_sind10spatial,age_sind10spatial))\n",
    "res = stats.linregress(saltremaps[allidx],reqalt_rates[allidx])\n",
    "allslope1 = res.slope; allint1 = res.intercept; allr1 = res.rvalue; allp1 = res.pvalue\n",
    "\n",
    "print('Association btwn Young, MA, Aged, & All Performance & Variable of Interest:')\n",
    "print('R [Young, MA, Aged, All]: ')\n",
    "print(yr1, mar1, ar1, allr1)\n",
    "print('P [Young, MA, Aged, All]: ')\n",
    "print(yp1, map1, ap1, allp1)\n",
    "        \n",
    "fig, ax = plt.subplots(figsize = (3.00,1.25))\n",
    "fig.suptitle('All Sessions (k ≥ 2)', fontsize = 10)\n",
    "ax.scatter(saltremaps[y_sind10spatial],reqalt_rates[y_sind10spatial], color = 'C0', s = 10)\n",
    "ax.scatter(saltremaps[ma_sind10spatial],reqalt_rates[ma_sind10spatial], color = 'C2', s = 10)\n",
    "ax.scatter(saltremaps[age_sind10spatial],reqalt_rates[age_sind10spatial], color = 'C1', s = 10)\n",
    "ax.set_xlabel('Alternation Remaps/Trial', fontsize = 9)\n",
    "ax.set_ylabel('Alt. Frac. Rewards Requested', fontsize = 9)\n",
    "ax.set_ylim([-0.1,1.1])\n",
    "ax.set_xlim([-0.05,0.5])\n",
    "ax.tick_params(labelsize = 8)\n",
    "X_plot = np.linspace(ax.get_xlim()[0],ax.get_xlim()[1],100)\n",
    "ax.plot(X_plot, aslope1*X_plot + aint1, '--', linewidth = 0.75, color = 'C1', label = 'Aged')\n",
    "ax.plot(X_plot, allslope1*X_plot + allint1, '-', linewidth = 0.75, color = 'k', label = 'All Ages')\n",
    "#plt.savefig(save_folder + 'alldays_remapfreq_correlation_all.png', dpi = 400, bbox_inches = 'tight')\n",
    "#plt.savefig(save_folder + 'alldays_remapfreqcorrelation_all.svg', dpi = 400, bbox_inches = 'tight')\n",
    "plt.show()\n",
    "\n",
    "### ALT Remaps/Trial vs. REQ RATES\n",
    "#Linear regression\n",
    "res = stats.linregress(allks[y_sind10spatial],reqalt_rates[y_sind10spatial])\n",
    "yslope1 = res.slope; yint1 = res.intercept; yr1 = res.rvalue; yp1 = res.pvalue\n",
    "\n",
    "res = stats.linregress(allks[ma_sind10spatial],reqalt_rates[ma_sind10spatial])\n",
    "maslope1 = res.slope; maint1 = res.intercept; mar1 = res.rvalue ; map1 = res.pvalue\n",
    "\n",
    "res = stats.linregress(allks[age_sind10spatial],reqalt_rates[age_sind10spatial])\n",
    "aslope1 = res.slope; aint1 = res.intercept; ar1 = res.rvalue ; ap1 = res.pvalue\n",
    "\n",
    "allidx = np.concatenate((y_sind10spatial,ma_sind10spatial,age_sind10spatial))\n",
    "res = stats.linregress(allks[allidx],reqalt_rates[allidx])\n",
    "allslope1 = res.slope; allint1 = res.intercept; allr1 = res.rvalue; allp1 = res.pvalue\n",
    "\n",
    "print('Association btwn Young, MA, Aged, & All Performance & Variable of Interest:')\n",
    "print('R [Young, MA, Aged, All]: ')\n",
    "print(yr1, mar1, ar1, allr1)\n",
    "print('P [Young, MA, Aged, All]: ')\n",
    "print(yp1, map1, ap1, allp1)\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (3.00,1.25))\n",
    "fig.suptitle('All Sessions (k ≥ 2)', fontsize = 10)\n",
    "ax.scatter(allks[y_sind10spatial] - 0.1,reqalt_rates[y_sind10spatial], color = 'C0', s = 10)\n",
    "ax.scatter(allks[ma_sind10spatial],reqalt_rates[ma_sind10spatial], color = 'C2', s = 10)\n",
    "ax.scatter(allks[age_sind10spatial] + 0.1,reqalt_rates[age_sind10spatial], color = 'C1', s = 10)\n",
    "ax.set_xlabel('Optimal K', fontsize = 9)\n",
    "ax.set_ylabel('Alt. Frac. Rewards Requested', fontsize = 9)\n",
    "ax.set_ylim([-0.1,1.1])\n",
    "ax.set_xlim([1.5, 4.5])\n",
    "ax.set_xticks([2,3,4])\n",
    "ax.tick_params(labelsize = 8)\n",
    "X_plot = np.linspace(ax.get_xlim()[0],ax.get_xlim()[1],100)\n",
    "ax.plot(X_plot, aslope1*X_plot + aint1, '--', linewidth = 0.75, color = 'C1', label = 'Aged')\n",
    "ax.plot(X_plot, allslope1*X_plot + allint1, '-', linewidth = 0.75, color = 'k', label = 'All Ages')\n",
    "#plt.savefig(save_folder + 'alldays_kcorrelation_all.png', dpi = 400, bbox_inches = 'tight')\n",
    "#plt.savefig(save_folder + 'alldays_kcorrelation_all.svg', dpi = 400, bbox_inches = 'tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c9c0ac6",
   "metadata": {},
   "source": [
    "# Re-label K-Means maps non-arbitrarily, assign map identities, & examine alignment of map identity & VR context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24788e45",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "''' Re-label spatial maps based on occupancy of Context A & B\n",
    "\n",
    " - If k = 2, map 0 is the map with the greatest relative number of trials in Block A (map 1 is the other)\n",
    " - If k = 3, map 0 & map 1 are the maps with greatest relative number of trials in Blocks A & B (map 2 is the other map)\n",
    " - If k = 4, map 0 & map 1 are the maps with greatest relative number of trials in Blocks A & B; between the remaining maps,\n",
    " whichever occupies more of blocks + A' is map 2. \n",
    " \n",
    "'''\n",
    "\n",
    "for m, session in zip(mice, sessions):\n",
    "    for s in tdqm(session):\n",
    "        d = data[m][s]\n",
    "        \n",
    "        #get some data & cell IDs\n",
    "        rawdata_file = 'RAW_' + m + '_' + s + '.npy'\n",
    "        spikes_file = 'SPIKES_' + m + '_' + s +'.npy'\n",
    "        behavior_file = 'BEHAVIOR_' + m + '_' + s + '.npy'\n",
    "        \n",
    "        raw = np.load(load_folder + rawdata_file, allow_pickle=True)\n",
    "        Y = np.load(load_folder + spikes_file, allow_pickle=False) #pre-filtered for speeds >2cm/s, position-corrected spikes, 20 ms timebins\n",
    "        behaviorfil = np.load(load_folder + behavior_file, allow_pickle=False)\n",
    "        \n",
    "        cell_IDs = raw.item().get('cellsfil')\n",
    "        spatialcell = d['spatialcell99'].astype(bool)\n",
    "        spatialcells = cell_IDs[spatialcell]     \n",
    "        \n",
    "        if len(spatialcells) > 10: \n",
    "            W = d['kmeans']['W']\n",
    "            skippedrawtrialfil = d['skippedrawtrialfil'].astype(int)\n",
    "            VRbackidx = d['VRbackidx'].astype(int)\n",
    "            trials = skippedrawtrialfil[VRbackidx]\n",
    "\n",
    "            #assign map 0 to be the one dominating A, map 1 is the other map\n",
    "            if (d['kmeans']['SilN'] == 2) and (d['kmeans']['onemap'][0] == False):\n",
    "                # get map indices\n",
    "                map_idx = W[:, 0].astype(bool)\n",
    "                map0_idx = np.zeros_like(trials)\n",
    "                map1_idx = np.zeros_like(trials)\n",
    "                for i, t in enumerate(np.unique(trials)):\n",
    "                    if map_idx[i]:\n",
    "                        map0_idx[trials == t] = 1\n",
    "                    else:\n",
    "                        map1_idx[trials == t] = 1\n",
    "                map0_idx = map0_idx.astype(bool)\n",
    "                map1_idx = map1_idx.astype(bool)\n",
    "\n",
    "                # get assign map 0 to be the one with the greate number of trials in Context A\n",
    "                trials_0inA = np.sum(np.unique(trials[map0_idx]) < 80)\n",
    "                trials_1inA = np.sum(np.unique(trials[map1_idx]) < 80) \n",
    "\n",
    "                if trials_0inA < trials_1inA: # swap labels\n",
    "                    d['map0_idx'] = 1\n",
    "                else:\n",
    "                    d['map0_idx'] = 0\n",
    "            \n",
    "            #ditto, assign map 1 to be the one dominating B, map 2 is the other map\n",
    "            elif (d['kmeans']['SilN'] == 3) and (d['kmeans']['onemap'][0] == False):\n",
    "                map0_idx = np.zeros_like(trials)\n",
    "                map1_idx = np.zeros_like(trials)\n",
    "                map2_idx = np.zeros_like(trials)\n",
    "                for i, t in enumerate(np.unique(trials)):\n",
    "                    map_idx = np.where(W[i,:] == 1)[0][0]\n",
    "                    if map_idx == 0:\n",
    "                        map0_idx[trials == t] = 1\n",
    "                    elif map_idx == 1:\n",
    "                        map1_idx[trials == t] = 1\n",
    "                    else:\n",
    "                        map2_idx[trials == t] = 1\n",
    "                map0_idx = map0_idx.astype(bool)\n",
    "                map1_idx = map1_idx.astype(bool)\n",
    "                map2_idx = map2_idx.astype(bool)\n",
    "                \n",
    "                # get assign map 0 to be the one with the greate number of trials in Context A\n",
    "                map0trials = np.unique(trials[map0_idx])\n",
    "                map1trials = np.unique(trials[map1_idx])\n",
    "                map2trials = np.unique(trials[map2_idx])\n",
    "                                       \n",
    "                trials_0inA = np.sum(map0trials < 80)\n",
    "                trials_1inA = np.sum(map1trials < 80) \n",
    "                trials_2inA = np.sum(map2trials < 80) \n",
    "                \n",
    "                d['map0_idx'] = np.argmax([trials_0inA, trials_1inA, trials_2inA])\n",
    "                \n",
    "                # get assign map 1 to be the one with the greate number of trials in Context B\n",
    "                trials_0inB = len(map0trials[(map0trials >= 80) & (map0trials < 140)])\n",
    "                trials_1inB = len(map1trials[(map1trials >= 80) & (map1trials < 140)])\n",
    "                trials_2inB = len(map2trials[(map2trials >= 80) & (map2trials < 140)])\n",
    "\n",
    "                d['map1_idx'] = np.argmax([trials_0inB, trials_1inB, trials_2inB])\n",
    "                d['map2_idx'] = np.setdiff1d([0,1,2], [d['map0_idx'], d['map1_idx']])[0]\n",
    " \n",
    "            #ditto but map 2 is the map occupying most of A' map 3 is the other map        \n",
    "            elif (d['kmeans']['SilN'] == 4) and (d['kmeans']['onemap'][0] == False):\n",
    "                map0_idx = np.zeros_like(trials)\n",
    "                map1_idx = np.zeros_like(trials)\n",
    "                map2_idx = np.zeros_like(trials)\n",
    "                map3_idx = np.zeros_like(trials)\n",
    "                for i, t in enumerate(np.unique(trials)):\n",
    "                    map_idx = np.where(W[i,:] == 1)[0][0]\n",
    "                    if map_idx == 0:\n",
    "                        map0_idx[trials == t] = 1\n",
    "                    elif map_idx == 1:\n",
    "                        map1_idx[trials == t] = 1\n",
    "                    elif map_idx == 2:\n",
    "                        map2_idx[trials == t] = 1\n",
    "                    else:\n",
    "                        map3_idx[trials == t] = 1\n",
    "                map0_idx = map0_idx.astype(bool)\n",
    "                map1_idx = map1_idx.astype(bool)\n",
    "                map2_idx = map2_idx.astype(bool)\n",
    "                map3_idx = map3_idx.astype(bool)\n",
    "                \n",
    "                # get assign map 0 to be the one with the greate number of trials in Context A\n",
    "                map0trials = np.unique(trials[map0_idx])\n",
    "                map1trials = np.unique(trials[map1_idx])\n",
    "                map2trials = np.unique(trials[map2_idx])\n",
    "                map3trials = np.unique(trials[map3_idx])\n",
    "                \n",
    "                maptrials = [map0trials, map1trials, map2trials, map3trials]\n",
    "                                       \n",
    "                trials_0inA = np.sum(map0trials < 80)\n",
    "                trials_1inA = np.sum(map1trials < 80) \n",
    "                trials_2inA = np.sum(map2trials < 80)\n",
    "                trials_3inA = np.sum(map3trials < 80)\n",
    "                \n",
    "                d['map0_idx'] = np.argmax([trials_0inA, trials_1inA, trials_2inA, trials_3inA])\n",
    "                \n",
    "                # get assign map 1 to be the one with the greate number of trials in Context B\n",
    "                trials_0inB = len(map0trials[(map0trials >= 80) & (map0trials < 140)])\n",
    "                trials_1inB = len(map1trials[(map1trials >= 80) & (map1trials < 140)])\n",
    "                trials_2inB = len(map2trials[(map2trials >= 80) & (map2trials < 140)])\n",
    "                trials_3inB = len(map3trials[(map3trials >= 80) & (map3trials < 140)])\n",
    "                   \n",
    "                d['map1_idx'] = np.argmax([trials_0inB, trials_1inB, trials_2inB, trials_3inB])    \n",
    "                \n",
    "                #decide which map has more trials before half way point in alternation, that is map 2\n",
    "                possibleidxs = np.setdiff1d([0,1,2,3], [d['map0_idx'], d['map1_idx']])\n",
    "                lengths = []\n",
    "                for n in possibleidxs:\n",
    "                    althalf = np.max(np.unique(trials)//4) + 140\n",
    "                    lengths = np.append(lengths, len(maptrials[n][maptrials[n] < althalf]))\n",
    "                                        \n",
    "                if lengths[0] > lengths[1]:           \n",
    "                    d['map2_idx'] = possibleidxs[0]\n",
    "                    d['map3_idx'] = possibleidxs[1]\n",
    "                else:\n",
    "                    d['map2_idx'] = possibleidxs[1]\n",
    "                    d['map3_idx'] = possibleidxs[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4c0bae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Check out how well map labels capture structure in the spatial cell similarity network matrices (Plot Panels of Figure S4G)\n",
    "\n",
    "Notes:\n",
    "1. In the figure panel, we retained the left y-axis label and tick labels and the right y-axis label only on the first panel. \n",
    "2. In the figure panel, we retained the colorbar only on the last matrix.\n",
    "3. In the first panel, the right y-axis label was moved closer to the matrix in Illustrator after removing the colorbar. \n",
    "4. Plotting is done this way to ensure that all matrices are equally sized.\n",
    "5. For clarity in the manuscript, A19_2 and _7 were relabeled A19_1 and _6 because session 2 was the first real recording \n",
    "session from this mouse. \n",
    "6. Middle aged animals were named with their sex (F/M) in the recording files and metadata. For clarity, this flag was removed \n",
    "from MA animal names in the manuscript. \n",
    "\n",
    "'''\n",
    "\n",
    "all_colors = ['xkcd:pink','xkcd:blue','xkcd:orchid','xkcd:azure']\n",
    "CLU_W = 3\n",
    "\n",
    "# if you want to assess map labeling for all sessions and plot all grid network firing similarity as in Figure S4G:\n",
    "#example_mice = mice\n",
    "#example_sessions = sessions\n",
    "#ex_sesh_only = False\n",
    "\n",
    "# if you want to assess map labeling for & plot only the example sessions in Figure S4G:\n",
    "example_mice = ['Y24', 'MA3M', 'A19', 'Y23','MA1F', 'A24','Y27','MA8F','A17']\n",
    "example_sessions = ['092322_record6','102822_record6','020123_record7','093022_record6','102822_record6','030323_record6','022123_record6','111822_record6','082822_record6']\n",
    "ex_sesh_only = True\n",
    "\n",
    "for m, session in zip(mice, sessions):\n",
    "    \n",
    "    for s in session:\n",
    "        d = data[m][s]\n",
    "\n",
    "        #get some data & cell IDs\n",
    "        rawdata_file = 'RAW_' + m + '_' + s + '.npy'\n",
    "        spikes_file = 'SPIKES_' + m + '_' + s +'.npy'\n",
    "        behavior_file = 'BEHAVIOR_' + m + '_' + s + '.npy'\n",
    "        \n",
    "        raw = np.load(load_folder + rawdata_file, allow_pickle=True)\n",
    "        Y = np.load(load_folder + spikes_file, allow_pickle=False) #pre-filtered for speeds >2cm/s, position-corrected spikes, 20 ms timebins\n",
    "        behaviorfil = np.load(load_folder + behavior_file, allow_pickle=False)\n",
    "        \n",
    "        cell_IDs = raw.item().get('cellsfil')\n",
    "        spatialcell = d['spatialcell99'].astype(bool)\n",
    "        spatialcells = cell_IDs[spatialcell]     \n",
    "        \n",
    "        posx = behaviorfil[:,0]\n",
    "        trial = behaviorfil[:,2]\n",
    "        rawtrialfil = raw.item().get('trialfil')   \n",
    "        \n",
    "        if m in SM_aged_mice:\n",
    "            col = 'C1'\n",
    "        elif m in SM_MA_mice:\n",
    "            col = 'C2'\n",
    "        else:\n",
    "            col = 'C0'\n",
    "\n",
    "        if len(spatialcells) > 10:\n",
    "            W = d['kmeans']['W']\n",
    "            skippedrawtrialfil = d['skippedrawtrialfil'].astype(int)\n",
    "            VRbackidx = d['VRbackidx'].astype(int)\n",
    "\n",
    "            # Load in left vs. right info\n",
    "            trialinfo = raw.item().get('trialinfo')\n",
    "            left = trialinfo['left']\n",
    "\n",
    "            #binary context vector, excluding skipped trials, dark, & gain periods, 1 = Map A\n",
    "            leftsort = left.copy()\n",
    "            alt_idx = 140\n",
    "            lefttail = left[alt_idx:]\n",
    "            leftsort[alt_idx:] = lefttail[np.argsort(-1*lefttail, kind = 'stable')]\n",
    "\n",
    "            context = []\n",
    "            for i, t in enumerate(np.unique(skippedrawtrialfil[VRbackidx])):\n",
    "                context = np.append(context, leftsort[t.astype(int)])\n",
    "            altcontextidx = np.where(np.diff(context) == 1.)[0][0] + 1 #index where alternation begins in context vectors\n",
    "    \n",
    "            if (d['kmeans']['onemap'][0] == False) and (m in example_mice) and (s in example_sessions) and (ex_sesh_only == True):\n",
    "                SilN = d['kmeans']['SilN']\n",
    "\n",
    "                print('mouse ' + m + '\\nsession ' + s[-1] + ', k = ' + str(SilN))\n",
    "                fig = plt.figure(figsize = (1.0,0.83))\n",
    "                fig.suptitle(m + '_' + s[-1] + ', ' + str(len(spatialcells)), y = 1.25, fontsize=10, color = col)\n",
    "                gs = gridspec.GridSpec(21, 21, figure=fig)\n",
    "\n",
    "                # plot Euclidean similarity score\n",
    "                ax1 = fig.add_subplot(gs[1:, :-1])\n",
    "                sim = d['gridsimilaritybacksorted']\n",
    "                im = ax1.imshow(sim, aspect='auto', cmap='Greys')\n",
    "                ax1.tick_params(labelleft=True)\n",
    "                ax1.tick_params(labelbottom=True)\n",
    "                ax1.set_xticks(ticks = [0,60,120,sim.shape[0]])\n",
    "                ax1.set_yticks(ticks = [0,60,120,sim.shape[0]])\n",
    "                ax1.set_xticklabels(labels = [0,60,120,180])\n",
    "                ax1.set_yticklabels(labels = [0,60,120,180])\n",
    "                ax1.set_ylabel('Trial Number', labelpad = 1, fontsize = 9)\n",
    "                ax1.set_xlabel('Trial Number', labelpad = 1, fontsize = 9)\n",
    "                ax1.set_title('VR Context', fontsize = 9, pad = 5)\n",
    "                ax1.tick_params('both',which='both', labelsize=8, pad=0.5)\n",
    "                ax1.text(260,170,'Map Label', rotation = 270, fontsize = 9)\n",
    "\n",
    "                # add k-means map labels\n",
    "                ax2 = fig.add_subplot(gs[1:, 16]) #clu label\n",
    "                                # k-means cluster labels\n",
    "                W = d['kmeans']['W'].copy()\n",
    "                \n",
    "                #add colorbar\n",
    "                cbar = fig.colorbar(im, shrink=0.8, ticks=np.arange(0.1, 0.8, 0.2), ax = ax1)\n",
    "                cbar.ax.tick_params(labelsize=8, pad=1)\n",
    "                \n",
    "                if SilN == 2:\n",
    "                    map_0 = W[:, d['map0_idx']].astype(bool)\n",
    "\n",
    "                    for i, t in enumerate(map_0):\n",
    "                        if t == True:\n",
    "                            ax2.vlines(1, i, i + 1, colors='xkcd:pink', lw= CLU_W, linestyles= 'solid', alpha = 1)\n",
    "                        else:\n",
    "                            ax2.vlines(1, i, i + 1, colors='xkcd:blue', lw= CLU_W, linestyles='solid', alpha = 1)\n",
    "                elif SilN == 3:\n",
    "                    map_0 = W[:, d['map0_idx']].astype(bool)\n",
    "                    map_1 = W[:, d['map1_idx']].astype(bool)\n",
    "                    map_2 = W[:, d['map2_idx']].astype(bool)\n",
    "\n",
    "                    for i, t in enumerate(map_0):\n",
    "                        if t == True:\n",
    "                            ax2.vlines(1, i, i + 1, colors='xkcd:pink', lw= CLU_W, linestyles= 'solid', alpha = 1)\n",
    "                            \n",
    "                    for i, t in enumerate(map_1):\n",
    "                        if t == True:\n",
    "                            ax2.vlines(1, i, i + 1, colors='xkcd:blue', lw= CLU_W, linestyles= 'solid', alpha = 1)\n",
    "                            \n",
    "                    for i, t in enumerate(map_2):\n",
    "                        if t == True:\n",
    "                            ax2.vlines(1, i, i + 1, colors='xkcd:green', lw= CLU_W, linestyles= 'solid', alpha = 1)\n",
    "                            \n",
    "                else:\n",
    "                    map_0 = W[:, d['map0_idx']].astype(bool)\n",
    "                    map_1 = W[:, d['map1_idx']].astype(bool)\n",
    "                    map_2 = W[:, d['map2_idx']].astype(bool)\n",
    "                    map_3 = W[:, d['map3_idx']].astype(bool)\n",
    "\n",
    "                    for i, t in enumerate(map_0):\n",
    "                        if t == True:\n",
    "                            ax2.vlines(1, i, i + 1, colors='xkcd:pink', lw= CLU_W, linestyles= 'solid', alpha = 1)\n",
    "                            \n",
    "                    for i, t in enumerate(map_1):\n",
    "                        if t == True:\n",
    "                            ax2.vlines(1, i, i + 1, colors='xkcd:blue', lw= CLU_W, linestyles= 'solid', alpha = 1)\n",
    "                            \n",
    "                    for i, t in enumerate(map_2):\n",
    "                        if t == True:\n",
    "                            ax2.vlines(1, i, i + 1, colors='xkcd:green', lw= CLU_W, linestyles= 'solid', alpha = 1)\n",
    "                                       \n",
    "                    for i, t in enumerate(map_3):\n",
    "                        if t == True:\n",
    "                            ax2.vlines(1, i, i + 1, colors='xkcd:black', lw = CLU_W, linestyles= 'solid', alpha = 1)\n",
    "                            \n",
    "                \n",
    "                ax2.set_xlim([0.5, 1.5])\n",
    "                ax2.set_ylim([W.shape[0], 0])\n",
    "                plt.axis('off')    \n",
    "                #ax2.set_ylabel('k cluster label', fontsize = 9)\n",
    "                \n",
    "                # add VR context labels\n",
    "                ax3 = fig.add_subplot(gs[0, 0:16])\n",
    "                for i, t in enumerate(context.astype(bool)):\n",
    "                    if t == True:\n",
    "                        ax3.hlines(1, i, i + 1, colors='xkcd:pink', lw = CLU_W, linestyles= 'solid', alpha = 1)\n",
    "                    else:\n",
    "                        ax3.hlines(1, i, i + 1, colors='xkcd:blue', lw = CLU_W, linestyles='solid', alpha = 1)\n",
    "                \n",
    "                ax3.set_ylim([0.5, 1.5])\n",
    "                ax3.set_xlim([0, W.shape[0]])\n",
    "                plt.axis('off')\n",
    "                \n",
    "                #fig.savefig(save_folder + m + '_' + s + '_klabelvcontext.png', dpi=400, bbox_inches='tight')\n",
    "                #fig.savefig(save_folder + m + '_' + s + '_klabelvcontext.svg', dpi=400, bbox_inches='tight')\n",
    "                plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "025c5313",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Assign identities to each now non-arbitrarily labeled spatial map as follows:\n",
    "\n",
    "Map 0 is the map dominating A trials and is therefore assumed to represent Context A. Therefore, map0context = A by default.\n",
    "Map 1 is the map dominating B trials and is therefore assumed to represent Context B. Therefore, map1context = B by default.\n",
    "\n",
    "For k > 2 sessions, to align context, map 2/3 represents either Context A or B based on its relative Block A or B similarity.\n",
    "\n",
    "This means that for k = 4 sessions there could be up to three maps associated with a particular context. \n",
    "\n",
    "'''\n",
    "\n",
    "for m, session in zip(mice, sessions):\n",
    "    for s in session:\n",
    "        d = data[m][s]\n",
    "        \n",
    "        rawdata_file = 'RAW_' + m + '_' + s + '.npy'\n",
    "        raw = np.load(load_folder + rawdata_file, allow_pickle=True)\n",
    "        cell_IDs = raw.item().get('cellsfil')\n",
    "        spatialcell = d['spatialcell99'].astype(bool)\n",
    "        spatialcells = cell_IDs[spatialcell]\n",
    "        \n",
    "        if len(spatialcells) > 10: \n",
    "            sim = d['spatialsimilaritybacksorted']\n",
    "            W = d['kmeans']['W']\n",
    "            skippedrawtrialfil = d['skippedrawtrialfil'].astype(int)\n",
    "            VRbackidx = d['VRbackidx'].astype(int)\n",
    "            trials = np.unique(skippedrawtrialfil[VRbackidx])\n",
    "            Aidx = np.where(trials < 80)[0]\n",
    "            Bidx = np.where((trials >= 80) & (trials < 140))[0]\n",
    "        \n",
    "            if (d['kmeans']['SilN'] == 3) and (d['kmeans']['onemap'][0] == False):\n",
    "                print('\\nfor mouse ' + str(m) + ', session ' + str(s[-1]) + ', k = ' + str(d['kmeans']['SilN']) + '... ')\n",
    "            \n",
    "                # get matrices comparing across each possible pair\n",
    "                map2_idx = d['map2_idx']\n",
    "                map_2 = W[:, d['map2_idx']].astype(bool)\n",
    "                 \n",
    "                sim_across1 = sim[Aidx, :]\n",
    "                sim_across1 = sim_across1[:, map_2]\n",
    "                simA = np.mean(sim_across1[np.triu_indices(n=sim_across1.shape[0], k=1, m=sim_across1.shape[1])])\n",
    "                sim_across2 = sim[Bidx, :]\n",
    "                sim_across2 = sim_across2[:, map_2]\n",
    "                simB = np.mean(sim_across2[np.triu_indices(n=sim_across2.shape[0], k=1, m=sim_across2.shape[1])])\n",
    "                \n",
    "                if simB > simA:\n",
    "                    d['map2context'] = 1 #1 = B\n",
    "                    print('map 2 context = B')\n",
    "                else: \n",
    "                    d['map2context'] = 0 #0 = A\n",
    "                    print('map 2 context = A')\n",
    "                    \n",
    "            elif (d['kmeans']['SilN'] == 4) and (d['kmeans']['onemap'][0] == False):\n",
    "                print('\\nfor mouse ' + str(m) + ', session ' + str(s[-1]) + ' k = ' + str(d['kmeans']['SilN']) + '...')\n",
    "                 \n",
    "                # get matrices comparing across each possible pair\n",
    "                map2_idx = d['map2_idx']\n",
    "                map3_idx = d['map3_idx']\n",
    "                map_2 = W[:, d['map2_idx']].astype(bool)\n",
    "                map_3 = W[:, d['map3_idx']].astype(bool)\n",
    "                 \n",
    "                sim_across1 = sim[Aidx, :]\n",
    "                sim_across1 = sim_across1[:, map_2]\n",
    "                sim2A = np.mean(sim_across1[np.triu_indices(n=sim_across1.shape[0], k=1, m=sim_across1.shape[1])])\n",
    "                sim_across2 = sim[Bidx, :]\n",
    "                sim_across2 = sim_across2[:, map_2]\n",
    "                sim2B = np.mean(sim_across2[np.triu_indices(n=sim_across2.shape[0], k=1, m=sim_across2.shape[1])])\n",
    "                \n",
    "                sim_across3 = sim[Aidx, :]\n",
    "                sim_across3 = sim_across3[:, map_3]\n",
    "                sim3A = np.mean(sim_across3[np.triu_indices(n=sim_across3.shape[0], k=1, m=sim_across3.shape[1])])\n",
    "                sim_across4 = sim[Bidx, :]\n",
    "                sim_across4 = sim_across4[:, map_3]\n",
    "                sim3B = np.mean(sim_across4[np.triu_indices(n=sim_across4.shape[0], k=1, m=sim_across4.shape[1])])\n",
    "               \n",
    "                if sim2B > sim2A:\n",
    "                    d['map2context'] = 1 #1 = B\n",
    "                    print('map 2 context = B')\n",
    "                else: \n",
    "                    d['map2context'] = 0 #0 = A\n",
    "                    print('map 2 context = A')\n",
    "                \n",
    "                if sim3B > sim3A:\n",
    "                    d['map3context'] = 1 #1 = B\n",
    "                    print('map 3 context = B')\n",
    "                else: \n",
    "                    d['map3context'] = 0 #0 = A\n",
    "                    print('map 3 context = A')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "028479f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Plot examples of map identity vs. context aligned to grid network similarity matrices (Figure 3A panels) \n",
    "\n",
    "Notes:\n",
    "1. In the figure panel, we retained the left y-axis label and tick labels and the right y-axis label only on the first panel. \n",
    "2. In the figure panel, we retained the colorbar only on the last matrix.\n",
    "3. In the first panel, the right y-axis label was moved closer to the matrix in Illustrator after removing the colorbar. \n",
    "4. Plotting is done this way to ensure that all matrices are equally sized.\n",
    "5. For clarity in the manuscript, A19_2 and _7 were relabeled A19_1 and _6 because session 2 was the first real recording \n",
    "session from this mouse. \n",
    "6. Arrows were added in Illustrator to indicate the location of expected map identity transitions given VR context changes \n",
    "on the right y-axis.\n",
    "7. Middle aged animals were named with their sex (F/M) in the recording files and metadata. For clarity, this flag was removed \n",
    "from MA animal names in the manuscript. \n",
    "\n",
    "'''\n",
    "\n",
    "all_colors = ['xkcd:pink','xkcd:blue','xkcd:orchid','xkcd:azure']\n",
    "CLU_W = 3\n",
    "\n",
    "# if you want to assess map labeling for all sessions and plot all grid network firing similarity as in Figure S4G:\n",
    "#example_mice = mice\n",
    "#example_sessions = sessions\n",
    "#ex_sesh_only = False\n",
    "\n",
    "# if you want to assess map labeling for & plot only the example sessions in Figure S4G:\n",
    "example_mice = ['Y27','MA1F','A19']\n",
    "example_sessions = ['021623_record1','022123_record6','102322_record1','102822_record6','012723_record2','020123_record7']\n",
    "ex_sesh_only = True\n",
    "\n",
    "for m, session in zip(mice, sessions):\n",
    "    \n",
    "    for s in session:\n",
    "        d = data[m][s]\n",
    "\n",
    "        #get some data & cell IDs\n",
    "        rawdata_file = 'RAW_' + m + '_' + s + '.npy'\n",
    "        spikes_file = 'SPIKES_' + m + '_' + s +'.npy'\n",
    "        behavior_file = 'BEHAVIOR_' + m + '_' + s + '.npy'\n",
    "        \n",
    "        raw = np.load(load_folder + rawdata_file, allow_pickle=True)\n",
    "        Y = np.load(load_folder + spikes_file, allow_pickle=False) #pre-filtered for speeds >2cm/s, position-corrected spikes, 20 ms timebins\n",
    "        behaviorfil = np.load(load_folder + behavior_file, allow_pickle=False)\n",
    "        \n",
    "        cell_IDs = raw.item().get('cellsfil')\n",
    "        spatialcell = d['spatialcell99'].astype(bool)\n",
    "        spatialcells = cell_IDs[spatialcell]     \n",
    "        \n",
    "        posx = behaviorfil[:,0]\n",
    "        trial = behaviorfil[:,2]\n",
    "        rawtrialfil = raw.item().get('trialfil')   \n",
    "\n",
    "        if (m in example_mice) and (s in example_sessions) and (ex_sesh_only == True):\n",
    "            W = d['kmeans']['W']\n",
    "            skippedrawtrialfil = d['skippedrawtrialfil'].astype(int)\n",
    "            VRbackidx = d['VRbackidx'].astype(int)\n",
    "\n",
    "            # Load in left vs. right info\n",
    "            trialinfo = raw.item().get('trialinfo')\n",
    "            left = trialinfo['left']\n",
    "\n",
    "            #binary context vector, excluding skipped trials, dark, & gain periods, 1 = Map A\n",
    "            leftsort = left.copy()\n",
    "            alt_idx = 140\n",
    "            lefttail = left[alt_idx:]\n",
    "            leftsort[alt_idx:] = lefttail[np.argsort(-1*lefttail, kind = 'stable')]\n",
    "\n",
    "            context = []\n",
    "            for i, t in enumerate(np.unique(skippedrawtrialfil[VRbackidx])):\n",
    "                context = np.append(context, leftsort[t.astype(int)])\n",
    "            altcontextidx = np.where(np.diff(context) == 1.)[0][0] + 1 #index where alternation begins in context vectors\n",
    "            \n",
    "            if m in SM_aged_mice:\n",
    "                col = 'C1'\n",
    "            elif m in SM_MA_mice:\n",
    "                col = 'C2'\n",
    "            else:\n",
    "                col = 'C0'\n",
    "    \n",
    "            SilN = d['kmeans']['SilN']\n",
    "\n",
    "            print('mouse ' + m + '\\nsession ' + s[-1] + ', k = ' + str(SilN))\n",
    "            fig = plt.figure(figsize = (1.5,1.25))\n",
    "            fig.suptitle(m + '_' + s[-1] + ', ' + str(len(spatialcells)) + ' cells', y = 1.15, fontsize=10, color = col)\n",
    "            gs = gridspec.GridSpec(21, 21, figure=fig)\n",
    "\n",
    "            # plot Euclidean similarity score\n",
    "            ax1 = fig.add_subplot(gs[1:, :-1])\n",
    "            sim = d['spatialsimilaritybacksorted']\n",
    "            im = ax1.imshow(sim, aspect='auto', cmap='Greys')\n",
    "            ax1.tick_params(labelleft=True)\n",
    "            ax1.tick_params(labelbottom=True)\n",
    "            ax1.set_xticks(ticks = [0,60,120,180])\n",
    "            ax1.set_yticks(ticks = [0,60,120,180])\n",
    "            ax1.set_xticks(ticks = [0,60,120,sim.shape[0]])\n",
    "            ax1.set_yticks(ticks = [0,60,120,sim.shape[0]])\n",
    "            ax1.set_xticklabels(labels = [0,60,120,180])\n",
    "            ax1.set_yticklabels(labels = [0,60,120,180])\n",
    "            ax1.set_ylabel('Trial Number', labelpad = 1, fontsize = 9)\n",
    "            ax1.set_xlabel('Trial Number', labelpad = 1, fontsize = 9)\n",
    "            ax1.set_title('VR Context', fontsize = 9, pad = 5)\n",
    "            ax1.tick_params('both',which='both', labelsize=8, pad=0.5)\n",
    "            ax1.text(250,150,'Map Identity', rotation = 270, fontsize = 9)\n",
    "            ax1.tick_params('both', which='both', labelsize=8, pad=2)\n",
    "\n",
    "            #colorbar\n",
    "            cbar = fig.colorbar(im, shrink=1.0, ticks=np.arange(0.1, 0.8, 0.2))\n",
    "            cbar.ax.tick_params(labelsize=8, pad=1)\n",
    "\n",
    "            # k-means map identities\n",
    "            ax2 = fig.add_subplot(gs[1:, 16])\n",
    "            W = d['kmeans']['W'].copy()\n",
    "\n",
    "            if SilN == 2:\n",
    "                map_0 = W[:, d['map0_idx']].astype(bool)\n",
    "\n",
    "                for i, t in enumerate(map_0):\n",
    "                    if t == True:\n",
    "                        ax2.vlines(1, i, i + 1, colors='xkcd:pink', lw= CLU_W, linestyles= 'solid', alpha = 1)\n",
    "                    else:\n",
    "                        ax2.vlines(1, i, i + 1, colors='xkcd:blue', lw= CLU_W, linestyles='solid', alpha = 1)\n",
    "            elif SilN == 3:\n",
    "                map_0 = W[:, d['map0_idx']].astype(bool)\n",
    "                map_1 = W[:, d['map1_idx']].astype(bool)\n",
    "                map_2 = W[:, d['map2_idx']].astype(bool)\n",
    "\n",
    "                if d['map2context'] == 0:\n",
    "                    map_A = map_0 + map_2\n",
    "                else:\n",
    "                    map_A = map_0\n",
    "\n",
    "                for i, t in enumerate(map_A):\n",
    "                    if t == True:\n",
    "                        ax2.vlines(1, i, i + 1, colors='xkcd:pink', lw= CLU_W, linestyles= 'solid', alpha = 1)\n",
    "                    else:\n",
    "                        ax2.vlines(1, i, i + 1, colors='xkcd:blue', lw= CLU_W, linestyles= 'solid', alpha = 1)        \n",
    "\n",
    "            else:\n",
    "                map_0 = W[:, d['map0_idx']].astype(bool)\n",
    "                map_1 = W[:, d['map1_idx']].astype(bool)\n",
    "                map_2 = W[:, d['map2_idx']].astype(bool)\n",
    "                map_3 = W[:, d['map3_idx']].astype(bool)\n",
    "\n",
    "                if d['map2context'] == 0 and d['map3context'] == 0:\n",
    "                    map_A = map_0 + map_2 + map_3\n",
    "                elif d['map2context'] == 1 and d['map3context'] == 0:\n",
    "                    map_A = map_0 + map_3\n",
    "                elif d['map2context'] == 0 and d['map3context'] == 1:\n",
    "                    map_A = map_0 + map_2\n",
    "                else:\n",
    "                    map_A = map_0\n",
    "\n",
    "                for i, t in enumerate(map_A):\n",
    "                    if t == True:\n",
    "                        ax2.vlines(1, i, i + 1, colors='xkcd:pink', lw= CLU_W, linestyles= 'solid', alpha = 1)\n",
    "                    else:\n",
    "                        ax2.vlines(1, i, i + 1, colors='xkcd:blue', lw= CLU_W, linestyles= 'solid', alpha = 1)  \n",
    "\n",
    "            ax2.set_xlim([0.5, 1.5])\n",
    "            ax2.set_ylim([W.shape[0], 0])\n",
    "            plt.axis('off')    \n",
    "\n",
    "            # VR context labels\n",
    "            ax3 = fig.add_subplot(gs[0, 0:16])\n",
    "            for i, t in enumerate(context.astype(bool)):\n",
    "                if t == True:\n",
    "                    ax3.hlines(1, i, i + 1, colors='xkcd:pink', lw = CLU_W, linestyles= 'solid', alpha = 1)\n",
    "                else:\n",
    "                    ax3.hlines(1, i, i + 1, colors='xkcd:blue', lw = CLU_W, linestyles='solid', alpha = 1)\n",
    "\n",
    "            ax3.set_ylim([0.5, 1.5])\n",
    "            ax3.set_xlim([0, W.shape[0]])\n",
    "            plt.axis('off')\n",
    "\n",
    "            #fig.savefig(save_folder + m + '_' + s + '_kidentityvcontext_simAB.png', dpi=400, bbox_inches='tight')\n",
    "            #fig.savefig(save_folder + m + '_' + s + '_kidentityvcontext_simAB.svg', dpi=400, bbox_inches='tight')\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c29e4d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Calculate fraction of trials during alternation with context-map alignment '''\n",
    "\n",
    "saltfrac = []\n",
    "maltfrac = []\n",
    "\n",
    "for m, session in zip(mice, sessions):\n",
    "    \n",
    "    m_contextalt = []\n",
    "    m_mapAalt = []\n",
    "    \n",
    "    for s in session:\n",
    "        d = data[m][s]\n",
    "\n",
    "        #get some data & cell IDs\n",
    "        rawdata_file = 'RAW_' + m + '_' + s + '.npy'\n",
    "        spikes_file = 'SPIKES_' + m + '_' + s +'.npy'\n",
    "        behavior_file = 'BEHAVIOR_' + m + '_' + s + '.npy'\n",
    "        \n",
    "        raw = np.load(load_folder + rawdata_file, allow_pickle=True)\n",
    "        Y = np.load(load_folder + spikes_file, allow_pickle=False) #pre-filtered for speeds >2cm/s, position-corrected spikes, 20 ms timebins\n",
    "        behaviorfil = np.load(load_folder + behavior_file, allow_pickle=False)\n",
    "        \n",
    "        cell_IDs = raw.item().get('cellsfil')\n",
    "        spatialcell = d['spatialcell99'].astype(bool)\n",
    "        spatialcells = cell_IDs[spatialcell]     \n",
    "        \n",
    "        posx = behaviorfil[:,0]\n",
    "        trial = behaviorfil[:,2]\n",
    "        rawtrialfil = raw.item().get('trialfil')   \n",
    "\n",
    "        if len(spatialcells) > 10:\n",
    "            W = d['kmeans']['W']\n",
    "            skippedrawtrialfil = d['skippedrawtrialfil'].astype(int)\n",
    "            VRbackidx = d['VRbackidx'].astype(int)\n",
    "\n",
    "            # Load in left vs. right info\n",
    "            trialinfo = raw.item().get('trialinfo')\n",
    "            left = trialinfo['left']\n",
    "\n",
    "            #binary context vector, excluding skipped trials, dark, & gain periods, 1 = Map A\n",
    "            leftsort = left.copy()\n",
    "            alt_idx = 140\n",
    "            lefttail = left[alt_idx:]\n",
    "            leftsort[alt_idx:] = lefttail[np.argsort(-1*lefttail, kind = 'stable')]\n",
    "\n",
    "            context = []\n",
    "            for i, t in enumerate(np.unique(skippedrawtrialfil[VRbackidx])):\n",
    "                context = np.append(context, leftsort[t.astype(int)])\n",
    "            altcontextidx = np.where(np.diff(context) == 1.)[0][0] #index where alternation begins in context vectors\n",
    "            \n",
    "            if (d['kmeans']['SilN'] == 2) and (d['kmeans']['onemap'][0] == False):\n",
    "                map_A = W[:, d['map0_idx']].astype(bool)\n",
    "                \n",
    "                #save out to be able to compute at animal level\n",
    "                m_mapAalt = np.append(m_mapAalt, map_A[altcontextidx:])\n",
    "                m_contextalt = np.append(m_contextalt, context[altcontextidx:])\n",
    "\n",
    "                #compute fraction trials in map = context\n",
    "                saltfrac = np.append(saltfrac, np.sum(map_A[altcontextidx:] == context[altcontextidx:])/len(context[:altcontextidx:]))\n",
    "           \n",
    "            elif (d['kmeans']['SilN'] == 3) and (d['kmeans']['onemap'][0] == False):\n",
    "                if d['map2context'] == 0: #if map 2 is closer to representing context A, combine map 0 and 2 trials into context A trials\n",
    "                    map_A = W[:, d['map0_idx']] + W[:, d['map2_idx']]\n",
    "                    map_A = map_A.astype(bool)\n",
    "                else:\n",
    "                    map_A = W[:, d['map0_idx']].astype(bool)\n",
    "                \n",
    "                #save out to be able to compute at animal level\n",
    "                m_mapAalt = np.append(m_mapAalt, map_A[altcontextidx:])\n",
    "                m_contextalt = np.append(m_contextalt, context[altcontextidx:])\n",
    "\n",
    "                #compute fraction trials in map = context\n",
    "                saltfrac = np.append(saltfrac, np.sum(map_A[altcontextidx:] == context[altcontextidx:])/len(context[:altcontextidx:]))\n",
    "            \n",
    "            elif (d['kmeans']['SilN'] == 4) and (d['kmeans']['onemap'][0] == False):\n",
    "                if (d['map2context'] == 0) and (d['map3context'] == 0): #if map 2 & 3 are closer to representing context A, combine them into context A trials\n",
    "                    map_A = W[:, d['map0_idx']] + W[:, d['map2_idx']] + W[:, d['map3_idx']]\n",
    "                    map_A = map_A.astype(bool)\n",
    "                elif (d['map2context'] == 0) and (d['map3context'] == 1):\n",
    "                    map_A = W[:, d['map0_idx']] +  W[:, d['map2_idx']]\n",
    "                    map_A = map_A.astype(bool)    \n",
    "                elif (d['map2context'] == 1) and (d['map3context'] == 0):\n",
    "                    map_A = W[:, d['map0_idx']] +  W[:, d['map3_idx']]\n",
    "                    map_A = map_A.astype(bool)\n",
    "                else: #only map 0 represents A\n",
    "                    map_A = W[:, d['map0_idx']].astype(bool)\n",
    "                    \n",
    "                #save out to be able to compute at animal level\n",
    "                m_mapAalt = np.append(m_mapAalt, map_A[altcontextidx:])\n",
    "                m_contextalt = np.append(m_contextalt, context[altcontextidx:])\n",
    "\n",
    "                #compute fraction trials in map = context\n",
    "                saltfrac = np.append(saltfrac, np.sum(map_A[altcontextidx:] == context[altcontextidx:])/len(context[:altcontextidx:]))     \n",
    "            \n",
    "            else:\n",
    "                saltfrac = np.append(saltfrac, np.nan)\n",
    "        \n",
    "        else:\n",
    "            saltfrac = np.append(saltfrac, np.nan)\n",
    "\n",
    "    #compute fraction trials in map = context\n",
    "    if len(m_contextalt) > 0:\n",
    "        maltfrac = np.append(maltfrac, np.sum(m_mapAalt == m_contextalt)/len(m_contextalt))\n",
    "    else:\n",
    "        maltfrac = np.append(maltfrac, np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a2999b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Find where nan and ignore for plotting '''\n",
    "nan_idx = np.where(np.isnan(saltfrac) == True)[0]\n",
    "\n",
    "# Adjust y_sind, ma_sind, age_sind for subsequent plots\n",
    "y_sind10spatial = np.setdiff1d(y_sind, nan_idx)\n",
    "ma_sind10spatial = np.setdiff1d(ma_sind, nan_idx)\n",
    "age_sind10spatial = np.setdiff1d(age_sind, nan_idx)\n",
    "\n",
    "# Adjust colormaps for spatial plots\n",
    "yidx = []\n",
    "maidx = []\n",
    "aidx = []\n",
    "for i in nan_idx:\n",
    "    yidx = np.append(yidx, np.where(y_sind == i)[0].astype(int))\n",
    "    maidx = np.append(maidx, np.where(ma_sind == i)[0].astype(int))\n",
    "    aidx = np.append(aidx, np.where(age_sind == i)[0].astype(int)) \n",
    "\n",
    "col_session_young10spatial = np.delete(col_session_young, list(yidx.astype(int)), axis = 0)\n",
    "col_session_ma10spatial = np.delete(col_session_MA, list(maidx.astype(int)), axis = 0)\n",
    "col_session_old10spatial = np.delete(col_session_old, list(aidx.astype(int)), axis = 0)\n",
    "col_session10spatial = [col_session_young10spatial, col_session_ma10spatial, col_session_old10spatial] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "187a2b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Plot relationship between alternation performance and trial alignment (Figure 3d) '''\n",
    "### ALT Fraction Aligned Trials vs. REQ RATES\n",
    "#Linear regression\n",
    "res = stats.linregress(saltfrac[y_sind10spatial],reqalt_rates[y_sind10spatial])\n",
    "yslope1 = res.slope; yint1 = res.intercept; yr1 = res.rvalue; yp1 = res.pvalue\n",
    "\n",
    "res = stats.linregress(saltfrac[ma_sind10spatial],reqalt_rates[ma_sind10spatial])\n",
    "maslope1 = res.slope; maint1 = res.intercept; mar1 = res.rvalue ; map1 = res.pvalue\n",
    "\n",
    "res = stats.linregress(saltfrac[age_sind10spatial],reqalt_rates[age_sind10spatial])\n",
    "aslope1 = res.slope; aint1 = res.intercept; ar1 = res.rvalue ; ap1 = res.pvalue\n",
    "\n",
    "allidx = np.concatenate((y_sind10spatial,ma_sind10spatial,age_sind10spatial))\n",
    "res = stats.linregress(saltfrac[allidx],reqalt_rates[allidx])\n",
    "allslope1 = res.slope; allint1 = res.intercept; allr1 = res.rvalue; allp1 = res.pvalue\n",
    "\n",
    "print('Association btwn Young, MA, Aged, & All Performance & Variable of Interest:')\n",
    "print('R [Young, MA, Aged, All]: ')\n",
    "print(yr1, mar1, ar1, allr1)\n",
    "print('P [Young, MA, Aged, All]: ')\n",
    "print(yp1, map1, ap1, allp1)\n",
    "        \n",
    "#Plot Figure 3d\n",
    "fig, ax = plt.subplots(figsize = (2.5,1.05))\n",
    "fig.suptitle('Young & MA Sessions', fontsize = 10)\n",
    "ax.scatter(saltfrac[y_sind10spatial],reqalt_rates[y_sind10spatial], color = 'C0', s = 10)\n",
    "ax.scatter(saltfrac[ma_sind10spatial],reqalt_rates[ma_sind10spatial], color = 'C2', s = 10)\n",
    "ax.set_xlabel('Alt. Frac. Trials Aligned', fontsize = 9)\n",
    "ax.set_ylabel('Alt. Frac. Rewards Requested', fontsize = 9)\n",
    "ax.set_ylim([-0.1,1.1])\n",
    "ax.set_xlim([0,0.6])\n",
    "ax.tick_params(labelsize = 8)\n",
    "X_plot = np.linspace(ax.get_xlim()[0],ax.get_xlim()[1],100)\n",
    "ax.plot(X_plot, yslope1*X_plot + yint1, '--', color = 'C0', linewidth = 0.75, label = 'Young Fit')\n",
    "ax.plot(X_plot, maslope1*X_plot + maint1, '--', color = 'C2', linewidth = 0.75, label = 'MA Fit')\n",
    "#plt.savefig(save_folder + 'alldays_alignment_correlation_YMA.png', dpi = 400, bbox_inches = 'tight')\n",
    "#plt.savefig(save_folder + 'alldays_alignment_correlation_YMA.svg', dpi = 400, bbox_inches = 'tight')\n",
    "plt.show()\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (2.5,1.05))\n",
    "ax.scatter(saltfrac[age_sind10spatial],reqalt_rates[age_sind10spatial], color = 'C1', s = 10)\n",
    "ax.set_xlabel('Alt. Frac. Trials Aligned', fontsize = 9)\n",
    "ax.set_ylabel('Alt. Frac. Rewards Requested', fontsize = 9)\n",
    "ax.set_ylim([-0.1,1.1])\n",
    "ax.set_xlim([0,0.6])\n",
    "ax.tick_params(labelsize = 8)\n",
    "X_plot = np.linspace(ax.get_xlim()[0],ax.get_xlim()[1],100)\n",
    "ax.plot(X_plot, aslope1*X_plot + aint1, '--', linewidth = 0.75, color = 'C1', label = 'Aged')\n",
    "#plt.savefig(save_folder + 'alldays_alignment_correlation_aged.png', dpi = 400, bbox_inches = 'tight')\n",
    "#plt.savefig(save_folder + 'alldays_alignment_correlation_aged.svg', dpi = 400, bbox_inches = 'tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87709576",
   "metadata": {},
   "source": [
    "# Use logistic regression models to explore predictors of map-context alignment and reward requests by trial across age groups. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb41bc16",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Assemble data frame with reward request, context-map alignment, mouse age/sex/cohort/ID, VR context, & num trials\n",
    "since a switch data for each alternation trial '''\n",
    "\n",
    "sex = list(animalmeta.Sex[mice_ind])\n",
    "total_trials = 0\n",
    "\n",
    "allreq = []\n",
    "allaligned = []\n",
    "allcontext = []\n",
    "alltswitch = []\n",
    "allswitch = []\n",
    "\n",
    "alltrialid = []\n",
    "allsesh = []\n",
    "allage = []\n",
    "allsex = []\n",
    "allcohort = []\n",
    "allmice = []\n",
    "allk = []\n",
    "\n",
    "for m, session in zip(mice, sessions):\n",
    "    \n",
    "    msex = sex[np.where(mice == m)[0][0]]\n",
    "    age =  np.array(animalmeta.loc[(animalmeta.Animal_ID == m),'Age_Group'])\n",
    "    cohort =  np.array(animalmeta.loc[(animalmeta.Animal_ID == m),'Cohort'])\n",
    "    totalsesh = len(session)\n",
    "    sesh_count = 0\n",
    "    \n",
    "    for s in tdqm(session):\n",
    "        d = data[m][s]\n",
    "        \n",
    "        #get some data & cell IDs\n",
    "        rawdata_file = 'RAW_' + m + '_' + s + '.npy'\n",
    "        spikes_file = 'SPIKES_' + m + '_' + s +'.npy'\n",
    "        behavior_file = 'BEHAVIOR_' + m + '_' + s + '.npy'\n",
    "        \n",
    "        raw = np.load(load_folder + rawdata_file, allow_pickle=True)\n",
    "        Y = np.load(load_folder + spikes_file, allow_pickle=False) #pre-filtered for speeds >2cm/s, position-corrected spikes, 20 ms timebins\n",
    "        behaviorfil = np.load(load_folder + behavior_file, allow_pickle=False)\n",
    "        \n",
    "        cell_IDs = raw.item().get('cellsfil')\n",
    "        spatialcell = d['spatialcell99'].astype(bool)\n",
    "        spatialcells = cell_IDs[spatialcell]     \n",
    "        \n",
    "        posx = behaviorfil[:,0]\n",
    "        trial = behaviorfil[:,2]\n",
    "        rawtrialfil = raw.item().get('trialfil')  \n",
    "        \n",
    "        if len(spatialcells) > 10:\n",
    "            W = d['kmeans']['W']\n",
    "            skippedrawtrialfil = d['skippedrawtrialfil'].astype(int)\n",
    "            VRbackidx = d['VRbackidx'].astype(int)\n",
    "\n",
    "            # Load in left vs. right info\n",
    "            trialinfo = raw.item().get('trialinfo')\n",
    "            left = trialinfo['left']\n",
    "            alt_idx = 140\n",
    "            leftsort = left.copy()\n",
    "            lefttail = left[alt_idx:]\n",
    "            trials = np.unique(skippedrawtrialfil[VRbackidx])\n",
    "            alttrials = trials[trials >= 139]\n",
    "            \n",
    "            #get distance in trials since a context switch for each alternation trial\n",
    "            distswitch = []\n",
    "            switch = []\n",
    "            countsinceswitch = 0 \n",
    "            \n",
    "            allswitchtrials = np.where(np.diff(left) != 0)[0] + 1\n",
    "            altswitchtrials = allswitchtrials[allswitchtrials >= 139]\n",
    "            for i, t in enumerate(alttrials):\n",
    "                if t in altswitchtrials:\n",
    "                    countsinceswitch = 0\n",
    "                    distswitch = np.append(distswitch, countsinceswitch)\n",
    "                    switch = np.append(switch, 1)\n",
    "                else:\n",
    "                    countsinceswitch += 1\n",
    "                    distswitch = np.append(distswitch, countsinceswitch)\n",
    "                    switch = np.append(switch, 0)\n",
    "                    \n",
    "            #reward requests as binary vector for alternation trials\n",
    "            reward = raw.item().get('reward')\n",
    "            reward['trials'] = np.arange(0,len(reward['trials']),1) # fixes occassional Unity error numbering of rewards \n",
    "            \n",
    "            altreq = []\n",
    "            for i, t in enumerate(alttrials):\n",
    "                altreq = np.append(altreq, ~reward['missed'][reward['trials'] == t].astype(bool))\n",
    "            \n",
    "            #sort alternation context to retrieve alignment     \n",
    "            leftsort[alt_idx:] = lefttail[np.argsort(-1*lefttail, kind = 'stable')]\n",
    "\n",
    "            context = []\n",
    "            unsortcontext = []\n",
    "            for i, t in enumerate(trials):\n",
    "                context = np.append(context, leftsort[t.astype(int)])\n",
    "                unsortcontext = np.append(unsortcontext, left[t.astype(int)])\n",
    "    \n",
    "            #altcontextidx = np.where(np.diff(context) == 1.)[0][0] #index where alternation begins in context vectors\n",
    "            altcontextunsort = unsortcontext[trials >= 139]\n",
    "            \n",
    "            leftsmall = left[alttrials]\n",
    "            sortindices = np.argsort(-1*leftsmall, kind = 'stable')\n",
    "\n",
    "            if (d['kmeans']['SilN'] == 2) and (d['kmeans']['onemap'][0] == False):\n",
    "                \n",
    "                map_A = W[:, d['map0_idx']].astype(bool)\n",
    "\n",
    "                #compute fraction trials in map = context\n",
    "                sortedaligned = map_A[trials >= 139] == context[trials >= 139]\n",
    "                aligned = np.empty(sortedaligned.shape)\n",
    "                aligned[sortindices] = sortedaligned\n",
    "                \n",
    "                #append info about trials & reward requests\n",
    "                allreq = np.append(allreq, altreq)\n",
    "                alltswitch = np.append(alltswitch, distswitch)\n",
    "                allswitch = np.append(allswitch, switch)\n",
    "                allaligned = np.append(allaligned, aligned)\n",
    "                allcontext = np.append(allcontext, altcontextunsort)\n",
    "                \n",
    "                #save out info for each trial \n",
    "                for j in range(0,len(altreq)):\n",
    "                    alltrialid = np.append(alltrialid, total_trials)\n",
    "                    allsex = np.append(allsex, msex)\n",
    "                    allmice = np.append(allmice, m)\n",
    "                    allsesh = np.append(allsesh, sesh_count)\n",
    "                    allage = np.append(allage, age)\n",
    "                    allcohort = np.append(allcohort, cohort)\n",
    "                    allk = np.append(allk, d['kmeans']['SilN'])\n",
    "\n",
    "                    total_trials += 1\n",
    "           \n",
    "            elif (d['kmeans']['SilN'] == 3) and (d['kmeans']['onemap'][0] == False):\n",
    "                \n",
    "                if d['map2context'] == 0: #if map 2 is closer to representing context A, combine map 0 and 2 trials into context A trials\n",
    "                    map_A = W[:, d['map0_idx']] + W[:, d['map2_idx']]\n",
    "                    map_A = map_A.astype(bool)\n",
    "                else:\n",
    "                    map_A = W[:, d['map0_idx']].astype(bool)\n",
    "                \n",
    "                sortedaligned = map_A[trials >= 139] == context[trials >= 139]\n",
    "                aligned = np.empty(sortedaligned.shape)\n",
    "                aligned[sortindices] = sortedaligned\n",
    "                \n",
    "                #append info about trials & reward requests\n",
    "                allreq = np.append(allreq, altreq)\n",
    "                alltswitch = np.append(alltswitch, distswitch)\n",
    "                allswitch = np.append(allswitch, switch)\n",
    "                allaligned = np.append(allaligned, aligned)\n",
    "                allcontext = np.append(allcontext, altcontextunsort)\n",
    "                \n",
    "                #save out info for each trial \n",
    "                for j in range(0,len(altreq)):\n",
    "                    alltrialid = np.append(alltrialid, total_trials)\n",
    "                    allsex = np.append(allsex, msex)\n",
    "                    allmice = np.append(allmice, m)\n",
    "                    allsesh = np.append(allsesh, sesh_count)\n",
    "                    allage = np.append(allage, age)\n",
    "                    allcohort = np.append(allcohort, cohort)\n",
    "                    allk = np.append(allk, d['kmeans']['SilN'])\n",
    "\n",
    "                    total_trials += 1\n",
    "\n",
    "            elif (d['kmeans']['SilN'] == 4) and (d['kmeans']['onemap'][0] == False):\n",
    "                \n",
    "                if (d['map2context'] == 0) and (d['map3context'] == 0): #if map 2 & 3 are closer to representing context A, combine them into context A trials\n",
    "                    map_A = W[:, d['map0_idx']] + W[:, d['map2_idx']] + W[:, d['map3_idx']]\n",
    "                    map_A = map_A.astype(bool)\n",
    "                elif (d['map2context'] == 0) and (d['map3context'] == 1):\n",
    "                    map_A = W[:, d['map0_idx']] +  W[:, d['map2_idx']]\n",
    "                    map_A = map_A.astype(bool)    \n",
    "                elif (d['map2context'] == 1) and (d['map3context'] == 0):\n",
    "                    map_A = W[:, d['map0_idx']] +  W[:, d['map3_idx']]\n",
    "                    map_A = map_A.astype(bool)\n",
    "                else: #only map 0 represents A\n",
    "                    map_A = W[:, d['map0_idx']].astype(bool)\n",
    "\n",
    "                sortedaligned = map_A[trials >= 139] == context[trials >= 139]\n",
    "                aligned = np.empty(sortedaligned.shape)\n",
    "                aligned[sortindices] = sortedaligned\n",
    "                \n",
    "                #append info about trials & reward requests\n",
    "                allreq = np.append(allreq, altreq)\n",
    "                alltswitch = np.append(alltswitch, distswitch)\n",
    "                allswitch = np.append(allswitch, switch)\n",
    "                allaligned = np.append(allaligned, aligned)\n",
    "                allcontext = np.append(allcontext, altcontextunsort)\n",
    "                \n",
    "                #save out info for each trial \n",
    "                for j in range(0,len(altreq)):\n",
    "                    alltrialid = np.append(alltrialid, total_trials)\n",
    "                    allsex = np.append(allsex, msex)\n",
    "                    allmice = np.append(allmice, m)\n",
    "                    allsesh = np.append(allsesh, sesh_count)\n",
    "                    allage = np.append(allage, age)\n",
    "                    allcohort = np.append(allcohort, cohort)\n",
    "                    allk = np.append(allk, d['kmeans']['SilN'])\n",
    "\n",
    "                    total_trials += 1\n",
    "\n",
    "        sesh_count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38588cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Model Probability of a Context:Aligned Trial'''\n",
    "\n",
    "import statsmodels.api as sm\n",
    "from patsy import dmatrices\n",
    "\n",
    "#gather fixed effects into lists & then into dataframe\n",
    "Animal_ID = list(allmice)\n",
    "Session = list(allsesh)\n",
    "Sex = list(allsex)\n",
    "Age_Group = list(allage)\n",
    "Trial_ID = list(alltrialid)\n",
    "Cohort = list(allcohort)\n",
    "K = list(allk)\n",
    "\n",
    "Req = list(allreq)\n",
    "Aligned = list(allaligned)\n",
    "Context = list(allcontext)\n",
    "Tswitch = list(alltswitch)\n",
    "Switch = list(allswitch)\n",
    "\n",
    "tuples = list(zip(Animal_ID, Session, Sex, Age_Group, Trial_ID, Cohort, K, Req, Aligned, Context, Tswitch, Switch))\n",
    "tuples\n",
    "\n",
    "df = pd.DataFrame(tuples, columns = ['Animal_ID', 'Session', 'Sex', 'Age_Group', 'Trial_ID', 'Cohort', 'K','Req', 'Aligned', 'Context', 'Tswitch', 'Switch'])\n",
    "df = df.dropna(axis = 0)\n",
    "\n",
    "# model probability of a correct response\n",
    "y,X = dmatrices('Aligned ~ 1 + C(Age_Group) + C(Sex):C(Age_Group) + Session:C(Age_Group) + C(Context):C(Age_Group) + Tswitch:C(Age_Group)', data = df, return_type = 'dataframe')\n",
    "#y,X = dmatrices('Aligned ~ 1 + C(Age_Group) + C(Sex):C(Age_Group) + C(Remap) + C(Remap):C(Age_Group) + Session:C(Age_Group) + C(Context):C(Age_Group) + Switch:C(Age_Group)', data = df, return_type = 'dataframe')\n",
    "maligned = sm.Logit(y,X).fit()\n",
    "print(maligned.summary())\n",
    "\n",
    "#plot fitted values\n",
    "pvalues = pd.concat([maligned.pvalues[1:].T.to_frame()], \n",
    "                   ignore_index=False)\n",
    "pvalues.index.name = 'Features'\n",
    "pvalues.reset_index()\n",
    "\n",
    "params = pd.concat([maligned.params[1:].T.to_frame()], \n",
    "                   ignore_index=False)\n",
    "params.index.name = 'Features'\n",
    "params.reset_index()\n",
    "\n",
    "results = pd.merge(params, pvalues, how = \"left\", on = \"Features\",suffixes=(\"params\",\"pvalues\")).fillna(0).reset_index()\n",
    "results = results.rename(columns={'0params': 'Params', \"0pvalues\":'Pvalues'})\n",
    "\n",
    "plt.figure(figsize=(2,10))\n",
    "pvalues.plot.barh()\n",
    "plt.axvline(x = 0.05)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(2,10))\n",
    "params.plot.barh()\n",
    "plt.show()\n",
    "\n",
    "final = results.loc[(results['Pvalues'] < 0.05)].reset_index(drop=True)\n",
    "final['Odds'] = np.exp(final['Params'])\n",
    "final['Percent'] = (final['Odds'] - 1)*100\n",
    "final.sort_values(by=['Odds'], ascending = False).reset_index(drop=True)\n",
    "\n",
    "#plot fitted values\n",
    "hue_order = [1.0, 3.0, 2.0]\n",
    "df['predicted'] = maligned.predict(X)\n",
    "new_palette =  sns.color_palette(n_colors = 3)\n",
    "new_palette[1], new_palette[2] = new_palette[2], new_palette[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee136f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Table of All Predictors '''\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7c949fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Table of only Significant Predictors with OR'''\n",
    "\n",
    "final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdfbcd53",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Plot Figure 3c (left)'''\n",
    "#GATHER RESULTS\n",
    "results = df.groupby(by = ['Animal_ID','Session'], as_index = False)['predicted'].aggregate('mean')\n",
    "seshanimal = np.asarray(results['Animal_ID'])\n",
    "seshcount = np.asarray(results['Session'])\n",
    "seshmean = np.asarray(results['predicted'])\n",
    "\n",
    "r = 6\n",
    "salignedprobfitted_seg_aged = [[] * r for i in range(r)]\n",
    "salignedprobfitted_seg_MA = [[] * r for i in range(r)]\n",
    "salignedprobfitted_seg_young = [[] * r for i in range(r)]\n",
    "\n",
    "sessioncount_fitted_aged = [[] * r for i in range(r)]\n",
    "sessioncount_fitted_MA = [[] * r for i in range(r)]\n",
    "sessioncount_fitted_young = [[] * r for i in range(r)]\n",
    "\n",
    "for m, session in zip(mice, sessions): \n",
    "    \n",
    "    if m in seshanimal: \n",
    "        animalidx = np.where(seshanimal == m)[0][0]\n",
    "        session_idx = np.where(seshanimal == m)[0]\n",
    "\n",
    "        if m in SM_aged_mice:\n",
    "            for i, c in enumerate(seshcount[session_idx]):\n",
    "                idx = c.astype(int)\n",
    "                salignedprobfitted_seg_aged[idx] = np.append(salignedprobfitted_seg_aged[idx], seshmean[session_idx][i])\n",
    "                sessioncount_fitted_aged[idx] = np.append(sessioncount_fitted_aged[idx], c)\n",
    "        elif m in SM_MA_mice:\n",
    "            for i, c in enumerate(seshcount[session_idx]):\n",
    "                idx = c.astype(int)\n",
    "                salignedprobfitted_seg_MA[idx] = np.append(salignedprobfitted_seg_MA[idx], seshmean[session_idx][i])\n",
    "                sessioncount_fitted_MA[idx] = np.append(sessioncount_fitted_MA[idx], c)\n",
    "        else:\n",
    "            for i, c in enumerate(seshcount[session_idx]):\n",
    "                idx = c.astype(int)\n",
    "                salignedprobfitted_seg_young[idx] = np.append(salignedprobfitted_seg_young[idx], seshmean[session_idx][i])\n",
    "                sessioncount_fitted_young[idx] = np.append(sessioncount_fitted_young[idx], c)\n",
    "    else:\n",
    "        #print(m, session)\n",
    "        pass   \n",
    "    \n",
    "## PLOT\n",
    "fig, ax = plt.subplots(figsize = (1.60,1.60))\n",
    "\n",
    "#scatter plot actual raw data:\n",
    "for i in range(0,len(salignedprobfitted_seg_aged)):\n",
    "    print('\\nn aged, MA, young mice on day ' + str(i + 1))\n",
    "    print(len(sessioncount_fitted_aged[i]),len(sessioncount_fitted_MA[i]), len(sessioncount_fitted_young[i]))\n",
    "    ax.scatter(sessioncount_fitted_aged[i] + 0.2, salignedprobfitted_seg_aged[i], s = 5, alpha = 0.4, c = 'C1', edgecolor = 'none')\n",
    "    ax.scatter(sessioncount_fitted_MA[i], salignedprobfitted_seg_MA[i], s = 5, alpha = 0.4, c = 'C2', edgecolor = 'none')\n",
    "    ax.scatter(sessioncount_fitted_young[i] - 0.2, salignedprobfitted_seg_young[i], s = 5, alpha = 0.4, c = 'C0', edgecolor = 'none')\n",
    "\n",
    "g =  sns.pointplot(x = df['Session'], y = maligned.predict(X), hue = df['Age_Group'], hue_order = hue_order, scale = 0.5)\n",
    "ax.set_ylabel('P(Context-Aligned Trial)', fontsize = 9)\n",
    "ax.set_xlabel('Session', fontsize = 9)\n",
    "ax.set_xticks([0,1,2,3,4,5])\n",
    "ax.set_xticklabels(labels = [1,2,3,4,5,6])\n",
    "ax.set_xlim([-0.5,5.5])\n",
    "ax.set_yticks([0.25,0.5,0.75])\n",
    "ax.set_ylim([0.25,0.75])\n",
    "ax.tick_params(labelsize = 8)\n",
    "ax.hlines(y = 0.5,xmin = -0.5, xmax = 5.5, linestyle = '--', lw = 0.75, color = 'k')\n",
    "#plt.legend(bbox_to_anchor = (1.02,1), fontsize = 9)\n",
    "g.legend_.remove()\n",
    "for l in g.lines:\n",
    "    plt.setp(l,linewidth = 0.75)\n",
    "#fig.savefig(save_folder + 'alignmentovertime.png', dpi = 400, bbox_inches='tight')\n",
    "#fig.savefig(save_folder + 'alignmentovertime.svg', dpi = 400, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04597bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''   Count number of trials per group to justify where to cut the x-axis early \n",
    "\n",
    "After TSwitch > 7, <2 MA animals are included in the dataset. As a result, \n",
    "we cut off the x-axis below at TSwitch = 7. \n",
    "\n",
    "'''\n",
    "\n",
    "# num trials per trials since switch group\n",
    "results = df.groupby(by = ['Tswitch'], as_index = False)['predicted'].aggregate('count')\n",
    "print(results)\n",
    "\n",
    "# which mice those trials come from \n",
    "results = df.groupby(by = ['Tswitch','Animal_ID'], as_index = False)['predicted'].aggregate('count')\n",
    "print(results.tail(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "262d7bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Plot Figure 3c (right)'''\n",
    "\n",
    "## COLLECT RESULTS\n",
    "results = df.groupby(by = ['Animal_ID','Tswitch'], as_index = False)['predicted'].aggregate('mean')\n",
    "seshanimal = np.asarray(results['Animal_ID'])\n",
    "seshcount = np.asarray(results['Tswitch'])\n",
    "seshmean = np.asarray(results['predicted'])\n",
    "\n",
    "r = 8\n",
    "salignedprobfitted_seg_aged = [[] * r for i in range(r)]\n",
    "salignedprobfitted_seg_MA = [[] * r for i in range(r)]\n",
    "salignedprobfitted_seg_young = [[] * r for i in range(r)]\n",
    "\n",
    "sessioncount_fitted_aged = [[] * r for i in range(r)]\n",
    "sessioncount_fitted_MA = [[] * r for i in range(r)]\n",
    "sessioncount_fitted_young = [[] * r for i in range(r)]\n",
    "\n",
    "for m, session in zip(mice, sessions): \n",
    "    \n",
    "    if m in seshanimal: \n",
    "        animalidx = np.where(seshanimal == m)[0][0]\n",
    "        max_tswitch = len(np.where(seshanimal == m)[0])\n",
    "        if max_tswitch <= 8:\n",
    "            session_idx = np.arange(animalidx, max_tswitch + animalidx)\n",
    "        else:\n",
    "            session_idx = np.arange(animalidx, 8 + animalidx)\n",
    "\n",
    "        if m in SM_aged_mice:\n",
    "            for i, c in enumerate(seshcount[session_idx]):\n",
    "                idx = c.astype(int)\n",
    "                salignedprobfitted_seg_aged[idx] = np.append(salignedprobfitted_seg_aged[idx], seshmean[session_idx][i])\n",
    "                sessioncount_fitted_aged[idx] = np.append(sessioncount_fitted_aged[idx], c)\n",
    "        elif m in SM_MA_mice:\n",
    "            for i, c in enumerate(seshcount[session_idx]):\n",
    "                idx = c.astype(int)\n",
    "                salignedprobfitted_seg_MA[idx] = np.append(salignedprobfitted_seg_MA[idx], seshmean[session_idx][i])\n",
    "                sessioncount_fitted_MA[idx] = np.append(sessioncount_fitted_MA[idx], c)\n",
    "        else:\n",
    "            for i, c in enumerate(seshcount[session_idx]):\n",
    "                idx = c.astype(int)\n",
    "                salignedprobfitted_seg_young[idx] = np.append(salignedprobfitted_seg_young[idx], seshmean[session_idx][i])\n",
    "                sessioncount_fitted_young[idx] = np.append(sessioncount_fitted_young[idx], c)\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "## PLOT\n",
    "fig, ax = plt.subplots(figsize = (1.60,1.60))\n",
    "g = sns.pointplot(data = df, x = 'Tswitch', y = 'predicted', ax = ax, hue = 'Age_Group', palette = new_palette, scale = 0.5)\n",
    "ax.set_ylabel('P(Context-Aligned Trial)', fontsize = 9)\n",
    "ax.set_xlabel('Trials since Switch', fontsize = 9)\n",
    "ax.set_xlim([-0.5,7.5])\n",
    "#ax.set_title('Age x Aligned Trial', fontsize = 10)\n",
    "ax.set_xticks([0,1,2,3,4,5,6,7])\n",
    "ax.set_yticks([0.1,0.3,0.5,0.7,0.9])\n",
    "ax.set_ylim([0.1,0.9])\n",
    "ax.set_xticklabels([0,1,2,3,4,5,6,7])\n",
    "ax.tick_params(labelsize = 8)\n",
    "ax.hlines(y = 0.5,xmin = -0.5, xmax = 7.5, linestyle = '--', lw = 0.75, color = 'k')\n",
    "#plt.legend(bbox_to_anchor = (1.02,1), fontsize = 9)\n",
    "g.legend_.remove()\n",
    "for l in g.lines:\n",
    "    plt.setp(l,linewidth = 0.75)\n",
    "\n",
    "#scatter plot actual raw data:\n",
    "for i in range(0,len(salignedprobfitted_seg_aged)):\n",
    "    print('\\nn aged, MA, young mice on trials from switch ' + str(i))\n",
    "    print(len(sessioncount_fitted_aged[i]),len(sessioncount_fitted_MA[i]), len(sessioncount_fitted_young[i]))\n",
    "    ax.scatter(sessioncount_fitted_aged[i] + 0.2, salignedprobfitted_seg_aged[i], s = 5, alpha = 0.4, c = 'C1', edgecolor = 'none')\n",
    "    ax.scatter(sessioncount_fitted_MA[i], salignedprobfitted_seg_MA[i], s = 5, alpha = 0.4, c = 'C2', edgecolor = 'none')\n",
    "    ax.scatter(sessioncount_fitted_young[i] - 0.2, salignedprobfitted_seg_young[i], s = 5, alpha = 0.4, c = 'C0', edgecolor = 'none')\n",
    "\n",
    "#fig.savefig(save_folder + 'alignmentsinceswitch.png', dpi = 400, bbox_inches='tight')\n",
    "#fig.savefig(save_folder + 'alignmentsinceswitch.svg', dpi = 400, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9411219",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Model Probability of a Reward Request on an Alternation Trial'''\n",
    "\n",
    "# Add remap trial as a categorical variable to the model\n",
    "allremap = []\n",
    "for m, session in zip(mice, sessions):\n",
    "    for s in session:\n",
    "        d = data[m][s]\n",
    "        rawdata_file = 'RAW_' + m + '_' + s + '.npy'\n",
    "        behavior_file = 'BEHAVIOR_' + m + '_' + s + '.npy'\n",
    "        raw = np.load(load_folder + rawdata_file, allow_pickle=True)\n",
    "        behaviorfil = np.load(load_folder + behavior_file, allow_pickle=False)\n",
    "        cell_IDs = raw.item().get('cellsfil')\n",
    "        spatialcell = d['spatialcell99'].astype(bool)\n",
    "        spatialcells = cell_IDs[spatialcell]\n",
    "        \n",
    "        if len(spatialcells) > 10: \n",
    "            onemap = d['kmeans']['onemap']\n",
    "            \n",
    "            if onemap[0].astype(bool) == True:\n",
    "                continue\n",
    "            else:\n",
    "                W = d['kmeans']['W']\n",
    "                trials = np.arange(0, W.shape[0]-1)\n",
    "                remap_idx = d['remap_idx'][1] #zero-index to the beginning of VR period \n",
    "\n",
    "                # Load in left vs. right info\n",
    "                trialinfo = raw.item().get('trialinfo')\n",
    "                left = trialinfo['left']\n",
    "                skippedrawtrialfil = d['skippedrawtrialfil'].astype(int)\n",
    "                VRbackidx = d['VRbackidx'].astype(int)\n",
    "\n",
    "                alt_idx = 140\n",
    "                leftsort = left.copy()\n",
    "                lefttail = left[alt_idx:]\n",
    "                trials = np.unique(skippedrawtrialfil[VRbackidx])\n",
    "                alttrials = trials[trials >= 139]\n",
    "                \n",
    "                leftsort[alt_idx:] = lefttail[np.argsort(-1*lefttail, kind = 'stable')]\n",
    "                \n",
    "                leftsmall = left[alttrials]\n",
    "                sortindices = np.argsort(-1*leftsmall, kind = 'stable')\n",
    "\n",
    "                context = []\n",
    "                for i, t in enumerate(np.unique(skippedrawtrialfil[VRbackidx])):\n",
    "                    context = np.append(context, leftsort[t.astype(int)])\n",
    "                altcontextidx = np.where(np.diff(context) == 1.)[0][0] #index where alternation begins in context vectors\n",
    "\n",
    "                #get remap_idx for alt only, unsort it\n",
    "                remap_idx = remap_idx[remap_idx >= altcontextidx]\n",
    "                trials = np.unique(skippedrawtrialfil[VRbackidx])\n",
    "                remaptrials = trials[remap_idx]\n",
    "                \n",
    "                remaptrial = np.zeros(len(trials[trials >= 139]))\n",
    "                for i, t in enumerate(trials[trials >= 139]):\n",
    "                    \n",
    "                    trial_idx = np.where(skippedrawtrialfil == t)[0]\n",
    "                    if t in remaptrials:\n",
    "                        remaptrial[i] = 1\n",
    "            \n",
    "                unsortremaptrial = np.empty(remaptrial.shape)\n",
    "                unsortremaptrial[sortindices] = remaptrial\n",
    "                allremap = np.append(allremap, unsortremaptrial)\n",
    "\n",
    "Remap = list(allremap)\n",
    "tuples = list(zip(Animal_ID, Session, Sex, Age_Group, Trial_ID, Cohort, K, Req, Aligned, Context, Tswitch, Switch, Remap))\n",
    "tuples\n",
    "\n",
    "df = pd.DataFrame(tuples, columns = ['Animal_ID', 'Session', 'Sex', 'Age_Group', 'Trial_ID', 'Cohort', 'K','Req', 'Aligned', 'Context', 'Tswitch', 'Switch', 'Remap'])\n",
    "df = df.dropna(axis = 0)\n",
    "\n",
    "# model probability of a correct response\n",
    "y,X = dmatrices('Req ~ 1 + C(Age_Group) + C(Sex):C(Age_Group) + Session:C(Age_Group) + C(Remap):C(Age_Group) + C(Aligned):C(Age_Group) + C(Context):C(Age_Group) + Tswitch:C(Age_Group)', data = df, return_type = 'dataframe')\n",
    "#y,X = dmatrices('Req ~ 1 + C(Age_Group) + C(Sex):C(Age_Group) + Session:C(Age_Group) + C(Aligned):C(Age_Group) + C(Context):C(Age_Group) + C(Switch):C(Age_Group)', data = df, return_type = 'dataframe')\n",
    "mreq = sm.Logit(y,X).fit()\n",
    "print(mreq.summary())\n",
    "\n",
    "#plot fitted values\n",
    "pvalues = pd.concat([mreq.pvalues[1:].T.to_frame()], \n",
    "                   ignore_index=False)\n",
    "pvalues.index.name = 'Features'\n",
    "pvalues.reset_index()\n",
    "\n",
    "params = pd.concat([mreq.params[1:].T.to_frame()], \n",
    "                   ignore_index=False)\n",
    "params.index.name = 'Features'\n",
    "params.reset_index()\n",
    "\n",
    "results = pd.merge(params, pvalues, how = \"left\", on = \"Features\",suffixes=(\"params\",\"pvalues\")).fillna(0).reset_index()\n",
    "results = results.rename(columns={'0params': 'Params', \"0pvalues\":'Pvalues'})\n",
    "\n",
    "plt.figure(figsize=(2,10))\n",
    "pvalues.plot.barh()\n",
    "plt.axvline(x = 0.05)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(2,10))\n",
    "params.plot.barh()\n",
    "plt.show()\n",
    "\n",
    "final = results.loc[(results['Pvalues'] < 0.05)].reset_index(drop=True)\n",
    "final['Odds'] = np.exp(final['Params'])\n",
    "final['Percent'] = (final['Odds'] - 1)*100\n",
    "final.sort_values(by=['Odds'], ascending = False).reset_index(drop=True)\n",
    "\n",
    "#plot fitted values\n",
    "hue_order = [1.0, 3.0, 2.0]\n",
    "df['predicted'] = mreq.predict(X)\n",
    "new_palette =  sns.color_palette(n_colors = 3)\n",
    "new_palette[1], new_palette[2] = new_palette[2], new_palette[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b38488f",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Table of All Predictors '''\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0eccacd",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Table of only Significant Predictors with OR'''\n",
    "\n",
    "final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b9cea2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Plot Figure 3e \n",
    "\n",
    "Notes:\n",
    "1. In Illustrator, we jittered Age Group average markers and lines (in black) for visibility.\n",
    "2. In Illustrator, we also colored the edge of Age Group average markers black for visibility. \n",
    "\n",
    "'''\n",
    "##Get predicted results by session\n",
    "results = df.groupby(by = ['Animal_ID','Session'], as_index = False)['predicted'].aggregate('mean')\n",
    "seshanimal = np.asarray(results['Animal_ID'])\n",
    "seshcount = np.asarray(results['Session'])\n",
    "seshmean = np.asarray(results['predicted'])\n",
    "\n",
    "r = 6\n",
    "sreqprobfitted_seg_aged = [[] * r for i in range(r)]\n",
    "sreqprobfitted_seg_MA = [[] * r for i in range(r)]\n",
    "sreqprobfitted_seg_young = [[] * r for i in range(r)]\n",
    "\n",
    "sessioncount_fitted_aged = [[] * r for i in range(r)]\n",
    "sessioncount_fitted_MA = [[] * r for i in range(r)]\n",
    "sessioncount_fitted_young = [[] * r for i in range(r)]\n",
    "\n",
    "for m, session in zip(mice, sessions): \n",
    "    \n",
    "    if m in seshanimal: \n",
    "        animalidx = np.where(seshanimal == m)[0][0]\n",
    "        session_idx = np.where(seshanimal == m)[0]\n",
    "\n",
    "        if m in SM_aged_mice:\n",
    "            for i, c in enumerate(seshcount[session_idx]):\n",
    "                idx = c.astype(int)\n",
    "                sreqprobfitted_seg_aged[idx] = np.append(sreqprobfitted_seg_aged[idx], seshmean[session_idx][i])\n",
    "                sessioncount_fitted_aged[idx] = np.append(sessioncount_fitted_aged[idx], c)\n",
    "        elif m in SM_MA_mice:\n",
    "            for i, c in enumerate(seshcount[session_idx]):\n",
    "                idx = c.astype(int)\n",
    "                sreqprobfitted_seg_MA[idx] = np.append(sreqprobfitted_seg_MA[idx], seshmean[session_idx][i])\n",
    "                sessioncount_fitted_MA[idx] = np.append(sessioncount_fitted_MA[idx], c)\n",
    "        else:\n",
    "            for i, c in enumerate(seshcount[session_idx]):\n",
    "                idx = c.astype(int)\n",
    "                sreqprobfitted_seg_young[idx] = np.append(sreqprobfitted_seg_young[idx], seshmean[session_idx][i])\n",
    "                sessioncount_fitted_young[idx] = np.append(sessioncount_fitted_young[idx], c)\n",
    "    else:\n",
    "        #print(m, session)\n",
    "        pass\n",
    "    \n",
    "# Get results by aligned boolean\n",
    "results = df.groupby(by = ['Animal_ID','Remap'], as_index = False)['predicted'].aggregate('mean')\n",
    "remapanimal = np.asarray(results['Animal_ID'])\n",
    "remapcount = np.asarray(results['Remap'])\n",
    "remapmean = np.asarray(results['predicted'])\n",
    "\n",
    "##PLOT Figure 3e (left)\n",
    "fig, ax = plt.subplots(figsize = (1.05,1.05))\n",
    "\n",
    "g = sns.pointplot(data = df, x = 'Remap', y = 'predicted', hue= 'Age_Group', palette = new_palette, scale = 0.5)\n",
    "g.legend_.remove()\n",
    "for l in g.lines:\n",
    "    plt.setp(l,linewidth = 0.75, color = 'k')\n",
    "\n",
    "for m, session in zip(mice, sessions):   \n",
    "    if m in remapanimal: \n",
    "        animalidx = np.where(remapanimal == m)[0][0]\n",
    "        aligned_idx = np.arange(animalidx, (animalidx + 2))\n",
    "        if m in SM_aged_mice:\n",
    "            ax.plot(remapcount[aligned_idx] + 0.1 + np.random.rand(1)/8, remapmean[aligned_idx], alpha = 0.4, linewidth = 0.2, marker = '.', markersize = 3, markerfacecolor = 'C1', markeredgecolor = 'None', color = 'C1')\n",
    "        elif m in SM_MA_mice:\n",
    "            ax.plot(remapcount[aligned_idx], remapmean[aligned_idx], alpha = 0.4, linewidth = 0.2, marker = '.', markersize = 3, markerfacecolor = 'C2', markeredgecolor = 'None', color = 'C2')\n",
    "        else:\n",
    "            ax.plot(remapcount[aligned_idx] - 0.1, remapmean[aligned_idx], alpha = 0.4, linewidth = 0.2, marker = '.', markersize = 3, markerfacecolor = 'C0', markeredgecolor = 'None', color = 'C0')\n",
    "    \n",
    "ax.set_ylabel('P(Request)', fontsize = 9)\n",
    "ax.set_xlabel('Remap Trial', fontsize = 9)\n",
    "ax.set_xticks(ticks = [0,1], labels = ['No','Yes'])\n",
    "ax.set_yticks([0.25,0.5,0.75,1.0])\n",
    "ax.tick_params(labelsize = 8)\n",
    "ax.set_xlim([-0.5,1.5])\n",
    "ax.set_ylim([0.15,1.05])\n",
    "    \n",
    "#fig.savefig(save_folder + 'remapeffect.png', dpi = 400, bbox_inches='tight')\n",
    "#fig.savefig(save_folder + 'remapeffect.svg', dpi = 400, bbox_inches='tight')\n",
    "plt.show()\n",
    "    \n",
    "# Get results by aligned boolean\n",
    "results = df.groupby(by = ['Animal_ID','Aligned'], as_index = False)['predicted'].aggregate('mean')\n",
    "alignedanimal = np.asarray(results['Animal_ID'])\n",
    "alignedcount = np.asarray(results['Aligned'])\n",
    "alignedmean = np.asarray(results['predicted'])\n",
    "    \n",
    "##PLOT Figure 3e (right)\n",
    "fig, ax = plt.subplots(figsize = (1.05,1.05))\n",
    "\n",
    "g = sns.pointplot(data = df, x = 'Aligned', y = 'predicted', hue= 'Age_Group', palette = new_palette, scale = 0.5)\n",
    "g.legend_.remove()\n",
    "for l in g.lines:\n",
    "    plt.setp(l, linewidth = 0.75, color = 'k')\n",
    "\n",
    "for m, session in zip(mice, sessions):   \n",
    "    if m in alignedanimal: \n",
    "        animalidx = np.where(alignedanimal == m)[0][0]\n",
    "        aligned_idx = np.arange(animalidx, (animalidx + 2))\n",
    "        if m in SM_aged_mice:\n",
    "            ax.plot(alignedcount[aligned_idx] + 0.1 + np.random.rand(1)/8, alignedmean[aligned_idx], alpha = 0.4, linewidth = 0.2, marker = '.', markersize = 3, markerfacecolor = 'C1', markeredgecolor = 'None', color = 'C1')\n",
    "        elif m in SM_MA_mice:\n",
    "            ax.plot(alignedcount[aligned_idx], alignedmean[aligned_idx], alpha = 0.4, linewidth = 0.2, marker = '.', markersize = 3, markerfacecolor = 'C2', markeredgecolor = 'None', color = 'C2')\n",
    "        else:\n",
    "            ax.plot(alignedcount[aligned_idx] - 0.1, alignedmean[aligned_idx], alpha = 0.4, linewidth = 0.2, marker = '.', markersize = 3, markerfacecolor = 'C0', markeredgecolor = 'None', color = 'C0')\n",
    "    \n",
    "ax.set_ylabel('P(Request)', fontsize = 9)\n",
    "ax.set_xlabel('Aligned Trial', fontsize = 9)\n",
    "ax.set_yticks([0.25,0.5,0.75,1.0])\n",
    "ax.set_xticks(ticks = [0,1], labels = ['No','Yes'])\n",
    "ax.tick_params(labelsize = 8)\n",
    "ax.set_xlim([-0.5,1.5])\n",
    "ax.set_ylim([0.15,1.05])\n",
    "    \n",
    "#fig.savefig(save_folder + 'alignmenteffect.png', dpi = 400, bbox_inches='tight')\n",
    "#fig.savefig(save_folder + 'alignmenteffect.svg', dpi = 400, bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
