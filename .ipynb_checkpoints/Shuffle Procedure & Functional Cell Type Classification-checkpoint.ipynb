{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2c6050d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' magic 4u'''\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "16bcc95b",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Get stuff you need'''\n",
    "import numpy as np\n",
    "from tqdm import tnrange\n",
    "from tqdm.notebook import tqdm as tdqm\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams.update(mpl.rcParamsDefault)\n",
    "from matplotlib import gridspec\n",
    "from scipy.interpolate import interp1d\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "from scipy import stats\n",
    "import scipy.io\n",
    "from IPython.core.debugger import set_trace\n",
    "import scipy.ndimage.filters as filt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import math\n",
    "\n",
    "from pipeline import get_data as get\n",
    "from pipeline import process_spikes as ps\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn_pandas import DataFrameMapper\n",
    "from sklearn.metrics import silhouette_samples, silhouette_score\n",
    "\n",
    "from statsmodels.tsa.stattools import acf\n",
    "from scipy.signal import find_peaks\n",
    "from itertools import combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "28a07630",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Define some functions for later '''\n",
    "def tuning_curve_bytrial(x, trial, Y, dt, b, smooth=True, normalize=False, occupancy=True):\n",
    "    '''\n",
    "    Params\n",
    "    ------\n",
    "    x : ndarray\n",
    "        variable of interest by observation; shape (n_obs, )\n",
    "    trial : ndarray\n",
    "        trial num for each observation; shape (n_obs, )\n",
    "    Y : ndarray\n",
    "        spikes per observation; shape (n_obs, n_cells)\n",
    "    dt : int\n",
    "        time per observation in seconds\n",
    "    b : int\n",
    "        bin size\n",
    "    smooth : bool\n",
    "        apply gaussian filter to firing rate; optional, default is True\n",
    "    normalize : bool\n",
    "        normalize the firing rate of each cell such that its max FR is 1, min is 0;\n",
    "        optional, default is False\n",
    "    occupancy : bool\n",
    "        return occupancy (dwell time in each bin); optional, default is True\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    firing_rate : ndarray\n",
    "        binned firing rate for each trial for each cell; shape (n_trials, n_bins, n_cells)\n",
    "    centers : ndarray\n",
    "        center of each bin\n",
    "    occ : ndarray\n",
    "       dwell time in each bin; shape (n_bins, n_cells)\n",
    "    '''\n",
    "    edges = np.arange(0, np.max(x) + b, b)\n",
    "    centers = (edges[:-1] + edges[1:])/2\n",
    "    b_idx = np.digitize(x, edges)\n",
    "    if np.max(x) == edges[-1]:\n",
    "        b_idx[b_idx==np.max(b_idx)] = np.max(b_idx) - 1\n",
    "    unique_bdx = np.unique(b_idx)\n",
    "\n",
    "    # find FR in each bin\n",
    "    firing_rate = np.zeros((np.unique(trial).shape[0], unique_bdx.shape[0], Y.shape[1]))\n",
    "    occ = np.zeros((np.unique(trial).shape[0], unique_bdx.shape[0], Y.shape[1]))\n",
    "    for j in range(unique_bdx.shape[0]):\n",
    "        idx1 = (b_idx == unique_bdx[j])\n",
    "        for i, t in enumerate(np.unique(trial)):\n",
    "            idx = idx1 & (trial == t)\n",
    "            if np.sum(idx)==0:\n",
    "                print('warning: zero occupancy!')\n",
    "                firing_rate[i, j, :] = firing_rate[i, j-1, :]\n",
    "                occ[i, j, :] = 0\n",
    "            else:    \n",
    "                spike_ct = np.sum(Y[idx, :], axis=0)\n",
    "                occupancy = dt * np.sum(idx)\n",
    "                occ[i, j, :] = occupancy\n",
    "                firing_rate[i, j, :] = spike_ct / occupancy\n",
    "    if smooth:\n",
    "        firing_rate = gaussian_filter1d(firing_rate, 2, axis=1, mode='wrap')\n",
    "\n",
    "    if normalize:\n",
    "        for c in range(firing_rate.shape[1]):\n",
    "            firing_rate[:, :, c] = (firing_rate[:, :, c] - np.min(firing_rate[:, :, c]))/np.max(firing_rate[:, :, c] - np.min(firing_rate[:, :, c]))\n",
    "    \n",
    "    if occupancy:\n",
    "        return firing_rate, centers, occ\n",
    "    else: \n",
    "        return firing_rate, centers\n",
    "    \n",
    "def find8adjacentElements(test_list):\n",
    "    ''' \n",
    "    Params\n",
    "    ------\n",
    "    test_list : ndarray\n",
    "        1d array to be sorted\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    neighbors : list\n",
    "        nested list where each element is a list of 8 adjacent elements to the element with the same \n",
    "        index in test_list, adjusting for the first and last four elements and not including \n",
    "    '''\n",
    "    \n",
    "    neighbors = []\n",
    "    for idx, ele in enumerate(test_list):\n",
    "    # Checking for all cases to append\n",
    "        if idx == 0:\n",
    "            neighbors.append(test_list[(idx+1):(idx + 9)])\n",
    "        elif idx == 1:\n",
    "            neighbors.append(np.concatenate((test_list[(idx - 1)],test_list[(idx+1):(idx + 8)]),axis=None))\n",
    "        elif idx == 2:\n",
    "            neighbors.append(np.concatenate((test_list[:idx],test_list[(idx+1):(idx + 7)]),axis=None))\n",
    "        elif idx == 3:\n",
    "            neighbors.append(np.concatenate((test_list[:idx],test_list[(idx+1):(idx + 6)]),axis=None))\n",
    "        elif idx == len(test_list) - 1:\n",
    "            neighbors.append(np.concatenate((test_list[(idx-8):idx]),axis=None))                     \n",
    "        elif idx == len(test_list) - 2:\n",
    "            neighbors.append(np.concatenate((test_list[(idx-7):idx],test_list[(idx + 1):]),axis=None))\n",
    "        elif idx == len(test_list) - 3:\n",
    "            neighbors.append(np.concatenate((test_list[(idx-6):idx],test_list[(idx + 1):]),axis=None))\n",
    "        elif idx == len(test_list) - 4:\n",
    "            neighbors.append(np.concatenate((test_list[(idx-5):idx],test_list[(idx + 1):]),axis = None))\n",
    "        else:\n",
    "            neighbors.append(np.concatenate((test_list[(idx - 4):idx],test_list[(idx+1):(idx + 5)]),axis=None))\n",
    "    return neighbors \n",
    "\n",
    "    return (phi ** np.arange(nt)) * sigma2 / (1 - phi ** 2)\n",
    "\n",
    "def autocorr(x,lags):\n",
    "    '''numpy.correlate'''\n",
    "    mean=x.mean()\n",
    "    var=np.var(x)\n",
    "    xp=x-mean\n",
    "    corr=np.correlate(xp,xp,'full')[len(x)-1:]/var/len(x)\n",
    "\n",
    "    return corr[:len(lags)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7ddee405",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Animal_ID</th>\n",
       "      <th>Task</th>\n",
       "      <th>Cohort</th>\n",
       "      <th>Probe_Control</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Sac_Date</th>\n",
       "      <th>Frozen_Hemisphere</th>\n",
       "      <th>DOB</th>\n",
       "      <th>Age_WholeMonth</th>\n",
       "      <th>Age_ExtraDays</th>\n",
       "      <th>Age_Month</th>\n",
       "      <th>Aged_Days</th>\n",
       "      <th>Age_Group</th>\n",
       "      <th>Behavior_Sessions</th>\n",
       "      <th>Neural_Sessions</th>\n",
       "      <th>Total_Cells</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A3</td>\n",
       "      <td>RF</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "      <td>F</td>\n",
       "      <td>1/27/2021</td>\n",
       "      <td>R</td>\n",
       "      <td>4/23/2019</td>\n",
       "      <td>21</td>\n",
       "      <td>4</td>\n",
       "      <td>21.217</td>\n",
       "      <td>645</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>1540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A4</td>\n",
       "      <td>RF</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "      <td>F</td>\n",
       "      <td>1/27/2021</td>\n",
       "      <td>R</td>\n",
       "      <td>4/23/2019</td>\n",
       "      <td>21</td>\n",
       "      <td>4</td>\n",
       "      <td>21.217</td>\n",
       "      <td>645</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>1574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A5</td>\n",
       "      <td>RF</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "      <td>F</td>\n",
       "      <td>4/6/2021</td>\n",
       "      <td>L</td>\n",
       "      <td>4/23/2019</td>\n",
       "      <td>23</td>\n",
       "      <td>14</td>\n",
       "      <td>23.487</td>\n",
       "      <td>714</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>1002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A6</td>\n",
       "      <td>RF</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "      <td>F</td>\n",
       "      <td>4/6/2021</td>\n",
       "      <td>R</td>\n",
       "      <td>4/23/2019</td>\n",
       "      <td>23</td>\n",
       "      <td>14</td>\n",
       "      <td>23.487</td>\n",
       "      <td>714</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A7</td>\n",
       "      <td>RF</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "      <td>F</td>\n",
       "      <td>4/19/2021</td>\n",
       "      <td>L</td>\n",
       "      <td>5/29/2019</td>\n",
       "      <td>22</td>\n",
       "      <td>21</td>\n",
       "      <td>22.730</td>\n",
       "      <td>691</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>1691</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Animal_ID Task Cohort  Probe_Control Sex   Sac_Date Frozen_Hemisphere   \n",
       "0        A3   RF      A              0   F  1/27/2021                 R  \\\n",
       "1        A4   RF      A              0   F  1/27/2021                 R   \n",
       "2        A5   RF      A              0   F   4/6/2021                 L   \n",
       "3        A6   RF      A              0   F   4/6/2021                 R   \n",
       "4        A7   RF      A              0   F  4/19/2021                 L   \n",
       "\n",
       "         DOB  Age_WholeMonth  Age_ExtraDays  Age_Month  Aged_Days  Age_Group   \n",
       "0  4/23/2019              21              4     21.217        645          3  \\\n",
       "1  4/23/2019              21              4     21.217        645          3   \n",
       "2  4/23/2019              23             14     23.487        714          3   \n",
       "3  4/23/2019              23             14     23.487        714          3   \n",
       "4  5/29/2019              22             21     22.730        691          3   \n",
       "\n",
       "   Behavior_Sessions  Neural_Sessions  Total_Cells  \n",
       "0                  6                6         1540  \n",
       "1                  6                6         1574  \n",
       "2                  6                6         1002  \n",
       "3                  6                6          985  \n",
       "4                  6                6         1691  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' Load in Animal Metadata '''\n",
    "\n",
    "animalmeta = pd.read_csv('C:/Users/Python/Desktop/Dryad/MouseMetadata.csv') # adjust path name\n",
    "\n",
    "# define some useful lists of animals based on metadata\n",
    "all_aged_mice = np.array(animalmeta.loc[(animalmeta.Age_Group == 3),'Animal_ID'])\n",
    "all_MA_mice = np.array(animalmeta.loc[(animalmeta.Age_Group == 2),'Animal_ID'])\n",
    "all_young_mice = np.array(animalmeta.loc[(animalmeta.Age_Group == 1),'Animal_ID'])\n",
    "\n",
    "cohorta_mice = np.array(animalmeta.loc[(animalmeta.Cohort == 'A'),'Animal_ID'])\n",
    "cohortb_mice = np.array(animalmeta.loc[(animalmeta.Cohort == 'B'),'Animal_ID'])\n",
    "cohortc_mice = np.array(animalmeta.loc[(animalmeta.Cohort == 'C'),'Animal_ID'])\n",
    "cohortd_mice = np.array(animalmeta.loc[(animalmeta.Cohort == 'D'),'Animal_ID'])\n",
    "\n",
    "RF_aged_mice = np.array(animalmeta.loc[(animalmeta.Age_Group == 3) & (animalmeta.Task == 'RF'),'Animal_ID'])\n",
    "RF_young_mice = np.array(animalmeta.loc[(animalmeta.Age_Group == 1) & (animalmeta.Task == 'RF'),'Animal_ID'])\n",
    "SM_aged_mice = np.array(animalmeta.loc[(animalmeta.Age_Group == 3) & (animalmeta.Task == 'SM'),'Animal_ID'])\n",
    "SM_MA_mice = np.array(animalmeta.loc[(animalmeta.Age_Group == 2) & (animalmeta.Task == 'SM'),'Animal_ID'])\n",
    "SM_young_mice = np.array(animalmeta.loc[(animalmeta.Age_Group == 1) & (animalmeta.Task == 'SM'),'Animal_ID'])\n",
    "\n",
    "all_female_mice = np.array(animalmeta.loc[(animalmeta.Sex == 'F'),'Animal_ID'])\n",
    "all_male_mice = np.array(animalmeta.loc[(animalmeta.Sex == 'M'), 'Animal_ID'])\n",
    "RF_female_mice = np.array(animalmeta.loc[(animalmeta.Sex == 'F') & (animalmeta.Task == 'RF'),'Animal_ID'])\n",
    "RF_male_mice = np.array(animalmeta.loc[(animalmeta.Sex == 'M') & (animalmeta.Task == 'RF'),'Animal_ID'])\n",
    "SM_female_mice = np.array(animalmeta.loc[(animalmeta.Sex == 'F') & (animalmeta.Task == 'SM'),'Animal_ID'])\n",
    "SM_male_mice = np.array(animalmeta.loc[(animalmeta.Sex == 'M') & (animalmeta.Task == 'SM'),'Animal_ID'])\n",
    "\n",
    "animalmeta.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "be947817",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Complete List of Mice & Neural Data Sessions '''\n",
    "all_mice = np.array(animalmeta.Animal_ID)\n",
    "print(all_mice)\n",
    "\n",
    "#list of session IDs in order of mouse names\n",
    "all_sessions = ([['0122_record1','0123_record2','0124_record3','0125_record4','0126_record5','0127_record6'], #A3\n",
    "             ['0122_record1','0123_record2','0124_record3','0125_record4','0126_record5','0127_record6'], #A4\n",
    "             ['0401_record1','0401_record2b','0403_record3','0404_record4','0405_record5','0406_record6'], #A5\n",
    "             ['0401_record1','0402_record2','0403_record3','0404_record4','0405_record5','0406_record6'], #A6\n",
    "             ['0414_record1','0415_record2','0416_record3','0417_record4','0418_record5','0419_record6'], #A7\n",
    "             ['1024_record1','1025_record2','1026_record3','1027_record4','1028_record5_2'], #Y2; _6 excluded\n",
    "             ['1016_record1','1019_record3','1020_record4','1021_record5','1022_record6'], #Y3; _2 not collected\n",
    "             ['1114_record1','1115_record2','1116_record3','1117_record4','1118_record5','1119_record6'], # end cohort A\n",
    "             ['051822_record1','051922_record2','052022_record3','052122_record4','052222_record5','052322_record6'],\n",
    "             ['050522_record1','050622_record2','050722_record3','050822_record4','050922_record5','051022_record6'],\n",
    "             ['050522_record1','050622_record2','050722_record3','050822_record4','051022_record6'], #Y11_5 not collected\n",
    "             ['062222_record3','062322_record4','062522_record5'], #Y16_1 & 2 not collected, _6 neural excluded\n",
    "             ['062822_record1','062922_record2','063022_record3','070122_record4','070222_record5','070322_record6'],\n",
    "             ['062022_record1','062122_record2','062222_record3','062322_record4','062522_record5','062622_record6'],\n",
    "             ['062822_record1','062922_record2','063022_record3','070122_record4','070222_record5','070322_record6'], \n",
    "             ['051922_record2','052022_record3'], # end cohort B; Y9 051822_1 excluded; _2 and &_3 excluded from behavior\n",
    "             ['083022_record1','083122_record2','090122_record3'], \n",
    "             ['083022_record1','083122_record2','090122_record3','090222_record4','090322_record5','090422_record6'],\n",
    "             ['083022_record1','083122_record2','090122_record3','090222_record4'], #A16_5 excluded, A16_6 not collected \n",
    "             ['082322_record1','082422_record2','082522_record3','082622_record4','082722_record5','082822_record6'],\n",
    "             ['082322_record1real','082422_record2','082522_record3','082622_record4','082722_record5','082822_record6'],\n",
    "             ['102322_record1','102422_record2','102522_record3','102622_record4','102722_record5','102822_record6'],\n",
    "             ['102322_record1','102422_record2','102522_record3','102622_record4','102722_record5','102822_record6'],\n",
    "             ['102322_record1','102422_record2','102522_record3','102622_record4','102722_record5','102822_record6'],\n",
    "             ['103122_record2','110122_record3','110222_record4','110322_record5rep','110422_record6','110522_record7'],\n",
    "             ['110622_record1','110722_record2','110822_record3','110922_record4','111022_record5','111122_record6'],\n",
    "             ['103022_record1','103122_record2','110122_record3','110222_record4','110322_record5','110422_record6'],\n",
    "             ['103022_record1','103122_record2','110122_record3','110222_record4'], #MA7_5 excluded, 6 not collected\n",
    "             ['111322_record1','111422_record2','111522_record3','111622_record4','111722_record5','111822_record6'],\n",
    "             ['111322_record1','111422_record2','111522_record3','111622_record4','111722_record5','111822_record6'],\n",
    "             ['111322_record1','111422_record2','111522_record3','111622_record4','111722_record5','111822_record6'], \n",
    "             ['092522_record1','092622_record2','092722_record3','092822_record4','092922_record5','093022_record6'],\n",
    "             ['091822_record1','091922_record2','092022_record3','092122_record4','092222_record5','092322_record6'],\n",
    "             ['092522_record1','092622_record2','092722_record3','092822_record4','092922_record5','093022_record6'],\n",
    "             ['092522_record1','092622_record2','092722_record3','092822_record4','092922_record5','093022_record6'],\n",
    "             ['091822_record1','091922_record2','092022_record3','092122_record4','092222_record5','092322_record6'], #end cohortc\n",
    "             ['012723_record2','012823_record3','012923_record4','013023_record5','013123_record6','020123_record7'],\n",
    "             ['012623_record1','012723_record2','012823_record3','012923_record4','013023_record5','013123_record6'],\n",
    "             ['012923_record2','013023_record3','013123_record4','020123_record5','020223_record6','020323_record7'],\n",
    "             ['020923_record1','021023_record2','021123_record3','021223_record4','021323_record5','021423_record6'],\n",
    "             ['022623_record1','022723_record2','022823_record3','030123_record4','030223_record5','030323_record6'],\n",
    "             ['021623_record1','021723_record2','021823_record3','021923_record4','022023_record5','022123_record6'],\n",
    "             ['021623_record1','021723_record2','021823_record3','021923_record4','022023_record5','022123_record6'],\n",
    "             ['021623_record1','021723_record2','021823_record3','021923_record4','022023_record5rep','022123_record6'],\n",
    "             ['022623_record1','022723_record2','022823_record3','030123_record4','030223_record5','030323_record6'] #end cohort d \n",
    "            ]) #list of sessions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c04fca0f",
   "metadata": {},
   "source": [
    "First, in all sessions, you will identify putative inhibitory interneurons based on dual thresholds on FR and waveform duration. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cbef3b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Classify putative inhibitory interneurons & plot Extended Figure Data 6A'''\n",
    "\n",
    "#load all neural data sessions\n",
    "mice = all_mice\n",
    "sessions = all_sessions\n",
    "\n",
    "# Make a dict to hold data\n",
    "data = {}\n",
    "\n",
    "for session, m in zip(sessions, mice):\n",
    "    data[m] = {}\n",
    "    \n",
    "    for s in session:\n",
    "        data[m][s] = {}\n",
    "\n",
    "folder = 'C:/Users/Python/Dryad/metrics/' # adjust to location of downloaded metrics folders\n",
    "save_folder = 'C:/Users/Python/Desktop/LocalData/intnspeedcells/' # adjust to save folder path\n",
    "load_folder = 'C:/Users/Python/Desktop/LocalData/filtered/' # adjust to data folder\n",
    "    \n",
    "intperc = [] \n",
    "\n",
    "for m, session in zip(mice,sessions):\n",
    "    \n",
    "    seshcount = 1 \n",
    "    \n",
    "    for s in session:\n",
    "        d = data[m][s]   \n",
    "        rawdata_file = 'RAW_' + m + '_' + s + '.npy'\n",
    "        raw = np.load(load_folder + rawdata_file, allow_pickle=True)\n",
    "        cell_IDs = raw.item().get('cellsfil')\n",
    "        \n",
    "        # load waveform parameters of interest for good cells only, drop rows w/ NaN, standardize for kmeans clustering\n",
    "        file_name = m + '_' + str(seshcount) + '_metrics.csv'\n",
    "        metrics = pd.read_csv(folder + file_name)\n",
    "        fullgcmetrics = metrics[metrics['cluster_id'].isin(list(cell_IDs))]\n",
    "        gcmetrics = fullgcmetrics.dropna(subset = ['duration','PT_ratio'])\n",
    "        \n",
    "        duration = np.asarray(gcmetrics['duration'])\n",
    "        PTR = np.asarray(gcmetrics['PT_ratio'])\n",
    "        halfwidth = np.asarray(gcmetrics['halfwidth'])\n",
    "        recslope = np.asarray(gcmetrics['recovery_slope'])\n",
    "        firingrate = np.asarray(gcmetrics['firing_rate'])\n",
    "        \n",
    "        #examine duration threshold and plot\n",
    "        idx = np.where((duration < 0.35) | (firingrate > 40))[0]\n",
    "        print('Interneurons %: ' + str(len(idx)/len(cell_IDs)*100))\n",
    "        oppidx = np.setdiff1d(np.arange(0,len(firingrate),1), idx)\n",
    "        \n",
    "        intperc = np.append(intperc, np.round(100*len(idx)/len(cell_IDs), 2))\n",
    "        \n",
    "        #Plot Extended Data Figure 6A:\n",
    "        if (m == 'A12') and (s == '051922_record2')\n",
    "            fig, (ax1, ax2, ax3) = plt.subplots(1,3, figsize = (3.75,1.25))\n",
    "            ax1.scatter(PTR[idx], duration[idx], color = 'blue', alpha = 1, s = 5, edgecolor = 'None')\n",
    "            ax1.scatter(PTR[oppidx], duration[oppidx], color = 'green', alpha = 1, s = 5, edgecolor = 'None')\n",
    "            ax1.set_xlabel('Peak:Trough', fontsize = 9)\n",
    "            ax1.set_ylabel('Duration (ms)', fontsize = 9)\n",
    "            ax1.hlines(0.35,0,1.25, colors = 'k', linestyles = '--', linewidth = 0.75)\n",
    "            ax1.set_xlim([0,1.25])\n",
    "            ax1.set_xticks([0,0.5,1])\n",
    "            ax1.tick_params(labelsize = 8)\n",
    "\n",
    "            #plot histograms of widths w/ cluster labels applied\n",
    "            ax2.hist(halfwidth[idx], color = 'blue', histtype = 'step')\n",
    "            ax2.hist(halfwidth[oppidx], color = 'green', histtype = 'step')\n",
    "            ax2.set_xlabel('Width (ms)', fontsize = 9)\n",
    "            ax2.set_ylabel('Cells', fontsize = 9)\n",
    "            ax2.tick_params(labelsize = 8)\n",
    "\n",
    "            #plot histograms of widths w/ cluster labels applied\n",
    "            ax3.hist(firingrate[idx], color = 'blue', histtype = 'step')\n",
    "            ax3.hist(firingrate[oppidx], color = 'green', histtype = 'step')\n",
    "            ax3.set_xlabel('FR (Hz)', fontsize = 9)\n",
    "            ax3.tick_params(labelsize = 8)\n",
    "            ax3.set_ylim(ax2.get_ylim())\n",
    "\n",
    "            fig.suptitle(m + '_' + s[-1:] + ', IN %: ' + str(np.round(100*len(idx)/len(cell_IDs) , 2)), fontsize = 10)\n",
    "            plt.subplots_adjust(top = 0.8)\n",
    "            #plt.savefig(save_folder + m + '_' + s + '_' + 'qualityint.png', dpi=400, bbox_inches='tight')\n",
    "            #plt.savefig(save_folder + m + '_' + s + '_' + 'qualityint.svg', dpi=400, bbox_inches='tight')\n",
    "            plt.show()\n",
    "\n",
    "        seshcount += 1\n",
    "        \n",
    "        #create boolean (0 = excitatory cell; 1 = interneuron)\n",
    "        intn = np.zeros(len(cell_IDs))\n",
    "        intn[idx] = 1\n",
    "        intn[oppidx] = 0\n",
    "          \n",
    "        #save the boolean interneuron classifcation    \n",
    "        intn_file = 'intn_' + m + '_' + s + '.npy'\n",
    "        #np.save(save_folder + intn_file, intn)\n",
    "        print('saved interneuron classification as npy file for mouse ' + m + ' session '+ s)\n",
    "\n",
    "print('Mean, SEM % interneurons / session:')\n",
    "print(np.mean(intperc), stats.sem(intperc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9440851c",
   "metadata": {},
   "source": [
    "In Random Foraging (RF) sessions, we will now classify speed-tuned cells and spatial cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4f275a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Load in the RF sessions only & reset dictionary'''\n",
    "# Define mice, sessions for particular cohorts\n",
    "mice , mice_ind, _  = np.intersect1d(all_mice,(np.union1d(cohorta_mice, cohortb_mice)), return_indices = True) # RF mice\n",
    "#mice , mice_ind, _  = np.intersect1d(all_mice,np.union1d(cohortc_mice, cohortd_mice), return_indices = True) # SM mice\n",
    "\n",
    "# If you found the intersection \n",
    "sessions = []\n",
    "for i in mice_ind:\n",
    "    sessions.append(all_sessions[i])\n",
    "\n",
    "# Make a dict to hold data\n",
    "data = {}\n",
    "\n",
    "for session, m in zip(sessions, mice):\n",
    "    data[m] = {}\n",
    "    \n",
    "    for s in session:\n",
    "        data[m][s] = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e6b5b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Calculate 100x Shuffled Scores for each Cell in all RF Sessions \n",
    "\n",
    "Shuffle speed & speed stability scores are used to classify speed-tuning. \n",
    "Shuffle spatial sparsity & coherence scores are used to classify position-tuning, identifying spatial cells.\n",
    "\n",
    "Expected run time is hours per session.\n",
    "\n",
    "'''\n",
    "n_rep = 100 # number of shuffles\n",
    "sigma = 20  # smoothing factor for speed & speed stability scores\n",
    "n_bin = 8 #n position bins considered for speed stability score\n",
    "track_length = 400 #cm\n",
    "bins = np.arange(0,track_length + (track_length/n_bin),(track_length/n_bin))\n",
    "\n",
    "save_folder = 'C:/Users/Python/Desktop/LocalData/shuffscores/' #adjust path \n",
    "dataload_folder = 'C:/Users/Python/Desktop/LocalData/filtered/'#adjust path to output of Import & Filter notebook\n",
    "\n",
    "for m, session in zip(mice,sessions):\n",
    "    for s in tdqm(session):\n",
    "        d = data[m][s]\n",
    "        \n",
    "        #load in data\n",
    "        rawdata_file = 'RAW_' + m + '_' + s + '.npy'\n",
    "        behavior_file = 'BEHAVIOR_' + m + '_' + s + '.npy'\n",
    "        \n",
    "        raw = np.load(dataload_folder + rawdata_file, allow_pickle=True)\n",
    "        behaviorfil = np.load(dataload_folder + behavior_file, allow_pickle=False)\n",
    "        rawspeed = raw.item().get('speed')\n",
    "        speed = behaviorfil[:,1]\n",
    "        \n",
    "        sp = raw.item().get('sp')\n",
    "        spiket = sp['st'].copy()\n",
    "        cluster_id = sp['clu'].copy()\n",
    "        cell_IDs = raw.item().get('cellsfil')\n",
    "        posx = raw.item().get('posx')\n",
    "        post = raw.item().get('post')\n",
    "        \n",
    "        dt = np.unique(np.round(np.diff(post),4))\n",
    "        if len(dt) > 1: # discard duplicate frame entries if they occurred\n",
    "            dt = dt[dt != 0]\n",
    "            dt_to_trash = np.where(np.diff(post) == 0)[0]\n",
    "        else:\n",
    "            dt_to_trash = [] \n",
    "            \n",
    "        posxfil = behaviorfil[:,0]\n",
    "        trial = behaviorfil[:,2]\n",
    "        postfil = behaviorfil[:,3]\n",
    "        \n",
    "        # filter spikes & position frames by speed < 2cm/s or out of track limits \n",
    "        speed_to_trash = find(rawspeed < 2)\n",
    "        pos_to_trash = find((posx < 0) | (posx > 400))\n",
    "        trash_idx = np.unique(np.concatenate((dt_to_trash, speed_to_trash, pos_to_trash)))\n",
    "        keep_idx = np.setdiff1d(np.arange(len(rawspeed)), trash_idx)\n",
    "        \n",
    "        # find indices of spike corresponding to 8 x 50cm bins along the track based on filtered position\n",
    "        bin_idx = []\n",
    "        for i in range(n_bin):\n",
    "            if i == (n_bin - 1):\n",
    "                idx = np.where((posxfil >= bins[i]) & (posxfil <= bins[i + 1]))[0]\n",
    "            else:\n",
    "                idx = np.where((posxfil >= bins[i]) & (posxfil < bins[i + 1]))[0]\n",
    "            bin_idx.append(idx)\n",
    "            \n",
    "        #calculate & save shuffled speed scores\n",
    "        shuffspeedscore = np.zeros((n_rep, len(cell_IDs)))\n",
    "        shuffspeedstabscore = np.zeros((n_rep, len(cell_IDs)))\n",
    "        shuffspatialcoherencescores = np.zeros((n_rep,len(cell_IDs)))\n",
    "        shuffsparsityscores = np.zeros((n_rep,len(cell_IDs)))\n",
    "        \n",
    "        for n in tdqm(range(0, n_rep)):\n",
    "            \n",
    "            shuffspeed_score = []\n",
    "            shuffspeedstab_score = []\n",
    "            shuffspatialsparseness = []\n",
    "            shuffspatialcoherence = []\n",
    "            shuffspatialasparseness = []\n",
    "            shuffspatialacoherence = []\n",
    "            \n",
    "            B = np.zeros((len(rawspeed), len(cell_IDs))) # set empty shuffled FR matrix shape n_obs, n_cells\n",
    "            for i, c in enumerate(cell_IDs):\n",
    "                sdx = (np.where(cell_IDs==c)[0][0]).astype(int)\n",
    "                \n",
    "                #get actual spike times for each cell\n",
    "                st = spiket[cluster_id == c]\n",
    "                st = st[(st >= min(post)) & (st <= max(post))]\n",
    "\n",
    "                #get shuffle times\n",
    "                st_shuf = st - min(post)\n",
    "                total_time = max(post) - min(post)\n",
    "                add = np.random.uniform(0.02,total_time,1)\n",
    "                st_shuf = (st_shuf + add) % total_time\n",
    "                st_shuf = st_shuf + min(post)\n",
    "                                                        \n",
    "                #get unfiltered spike train\n",
    "                spike_ct = np.zeros_like(post)\n",
    "                spike_idx = np.digitize(st_shuf,post) #obs corresponding to where each shuffled spike occurs\n",
    "\n",
    "                idx, cts = np.unique(spike_idx, return_counts = True)\n",
    "                spike_ct[idx] = cts\n",
    "                B[:,i] = spike_ct\n",
    "\n",
    "                #check for & interpolate any missing values; smooth if necessary\n",
    "                if sum(np.isnan(B[:,i])) > 0:\n",
    "                    B[:,i] = get.nan_interp(B[:,i])  \n",
    "\n",
    "            #apply filter spike train by speed & posx errors\n",
    "            B = B[keep_idx,:]\n",
    "            total_time = max(postfil) - min(postfil)\n",
    "            \n",
    "            #convert spike train / instantaneous FR into smoothed & unsmoothed FR vectors\n",
    "            smoothFR, _ , smoothocc = ps.tuning_curve(posxfil, B, dt, b = 2, l=2, smooth=True, SEM=False, occupancy=True)\n",
    "            FR, _ , _ = ps.tuning_curve(posxfil, B, dt, b = 2, l=2, smooth=False, SEM=False, occupancy=True)\n",
    "\n",
    "            for i, c in enumerate(cell_IDs):\n",
    "                sdx = (np.where(cell_IDs==c)[0][0]).astype(int)\n",
    "\n",
    "                #calculate & store speed score for this cell's smoothed spike train\n",
    "                B[:,i] = gaussian_filter1d(B[:,i],sigma)\n",
    "                sscore, _ = stats.pearsonr(B[:,i],speed)\n",
    "                shuffspeed_score = np.append(shuffspeed_score,sscore)\n",
    "                \n",
    "                #calculate & store speed stability score for this cell's smoothed spike train\n",
    "                bin_pspikes = []\n",
    "                for j in range(n_bin):\n",
    "                    idx = bin_idx[j]\n",
    "                    psscore, _ = stats.pearsonr(B[idx,i],speed[idx])\n",
    "                    bin_pspikes = np.append(bin_pspikes, (psscore *  np.sum(B[idx,i])))\n",
    "                \n",
    "                sstabscore = np.sum(bin_pspikes) / np.sum(B[:,i])\n",
    "                shuffspeedstab_score = np.append(shuffspeedstab_score,sstabscore)\n",
    "                \n",
    "                #calculate spatial sparsity score with smoothed FR \n",
    "                meanFRsqr = np.square(np.mean(smoothFR[:,i]))\n",
    "                products = []\n",
    "                for b in range(smoothFR.shape[0]):\n",
    "                    binmeanFRsqr = np.square(smoothFR[b,i])\n",
    "                    prob = smoothocc[b,i]/total_time\n",
    "                    prod = prob * binmeanFRsqr\n",
    "                    products = np.append(products,prod)\n",
    "                sparsity = np.sum(products) / meanFRsqr\n",
    "                shuffspatialsparseness = np.append(shuffspatialsparseness,sparsity)  \n",
    "                \n",
    "                # calculate spatial tuning coherence score with non-smoothed FR\n",
    "                neighbors = find8adjacentElements(FR[:,i])\n",
    "                meanFR_neighbors = []\n",
    "                for b in range(FR.shape[0]):\n",
    "                    meanFR_neigh = np.mean(neighbors[b])\n",
    "                    meanFR_neighbors = np.append(meanFR_neighbors, meanFR_neigh)\n",
    "                coherence, _ = stats.pearsonr(FR[:,i],meanFR_neighbors)\n",
    "                if math.isnan(coherence):\n",
    "                    shuffspatialcoherence = np.append(shuffspatialcoherence,0)\n",
    "                else:\n",
    "                    shuffspatialcoherence = np.append(shuffspatialcoherence,coherence)\n",
    "                \n",
    "            shuffspeedscore[n,:] = shuffspeed_score #forms array (n_shuffreps, n_goodcells)\n",
    "            shuffspeedstabscore[n,:] = shuffspeedstab_score #forms array (n_shuffreps, n_goodcells)\n",
    "            shuffsparsityscores[n,:] = shuffspatialsparseness\n",
    "            shuffspatialcoherencescores[n,:] = shuffspatialcoherence\n",
    "            \n",
    "        #save scores for all cells in a session in nested lists    \n",
    "        d['shuffspeedscore'] = shuffspeedscore\n",
    "        d['shuffspeedstabscore'] = shuffspeedstabscore\n",
    "        d['shuffspatialcoherencescores'] = shuffspatialcoherencescores\n",
    "        d['shuffsparsityscores'] = shuffsparsityscores\n",
    "                \n",
    "        #Get file names & save shuffled scores as npy files\n",
    "        shufinstspeedscore_file = 'shufinstspeedscore_' + m + '_' + s + '.npy'\n",
    "        shufspeedstabscore_file = 'shufspeedstabscore_' + m + '_' + s + '.npy'\n",
    "        shufsparsityscore_file = 'shufsparsityscores_' + m + '_' + s + '.npy'\n",
    "        shufspatialcoherencescore_file = 'shufspatialcoherencescores_' + m + '_' + s + '.npy'\n",
    "        \n",
    "        np.save(save_folder + shufinstspeedscore_file, d['shuffspeedscore'])\n",
    "        print('saved shuffled speed score data as npy file for mouse ' + m + ' session '+ s)\n",
    "        \n",
    "        np.save(save_folder + shufspeedstabscore_file, d['shuffspeedstabscore'])\n",
    "        print('saved shuffled speed stability score data as npy file for mouse ' + m + ' session '+ s)\n",
    "\n",
    "        np.save(save_folder + shufsparsityscore_file, d['shuffsparsityscores'])\n",
    "        print('saved shuffled sparsity scores as npy file for mouse ' + m + ' session '+ s)\n",
    "\n",
    "        np.save(save_folder + shufspatialcoherencescore_file, d['shuffspatialcoherencescores'])\n",
    "        print('saved shuffled spatial coherence scores as npy file for mouse ' + m + ' session '+ s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d1dedea",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Classify Speed Tuned & Spatial Cells among RF Sessions '''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "198e21e8",
   "metadata": {},
   "source": [
    "For Split Maze sessions as for RF sessions, we will classify speed-tuned cells and spatial cells. Given the multiple contexts in the SM task and spatial maps for each context, I calculated the spatial tuning curve for Block A (trials 20-80) only and sparsity and coherence scores for that period only to classify spatial cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8699f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Load in the SM sessions only'''\n",
    "# Define mice, sessions for particular cohorts\n",
    "#mice , mice_ind, _  = np.intersect1d(all_mice,(np.union1d(cohorta_mice, cohortb_mice)), return_indices = True) # RF mice\n",
    "mice , mice_ind, _  = np.intersect1d(all_mice,np.union1d(cohortc_mice, cohortd_mice), return_indices = True) # SM mice\n",
    "\n",
    "# If you found the intersection \n",
    "sessions = []\n",
    "for i in mice_ind:\n",
    "    sessions.append(all_sessions[i])\n",
    "\n",
    "# Make a dict to hold data\n",
    "data = {}\n",
    "\n",
    "for session, m in zip(sessions, mice):\n",
    "    data[m] = {}\n",
    "    \n",
    "    for s in session:\n",
    "        data[m][s] = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72469063",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Calculate 100x Shuffled Scores for each Cell in all SM Sessions \n",
    "\n",
    "Shuffle speed & speed stability scores are used to classify speed-tuning. \n",
    "Shuffle spatial sparsity & coherence scores are used to classify position-tuning, identifying spatial cells.\n",
    "Shuffle dark FR autocorrelation max peak height at the same lag as the actual dark max peak is used to differentiate\n",
    "grid from non-grid spatial cells in the spatial cell pool. \n",
    "\n",
    "Expected run time is hours per session.\n",
    "\n",
    "'''\n",
    "n_rep = 100 # number of shuffles\n",
    "sigma = 20  # smoothing factor for speed & speed stability scores\n",
    "n_bin = 8 #n position bins considered for speed stability score\n",
    "track_length = 400 #cm\n",
    "bins = np.arange(0,track_length + (track_length/n_bin),(track_length/n_bin))\n",
    "\n",
    "save_folder = 'C:/Users/Python/Desktop/LocalData/shuffscores/' #adjust path \n",
    "dataload_folder = 'C:/Users/Python/Desktop/LocalData/filtered/'#adjust path to output of Import & Filter notebook\n",
    "\n",
    "for m, session in zip(mice,sessions):\n",
    "    for s in tdqm(session):\n",
    "        d = data[m][s]\n",
    "        \n",
    "        #load in data\n",
    "        rawdata_file = 'RAW_' + m + '_' + s + '.npy'\n",
    "        behavior_file = 'BEHAVIOR_' + m + '_' + s + '.npy'\n",
    "        \n",
    "        raw = np.load(dataload_folder + rawdata_file, allow_pickle=True)\n",
    "        behaviorfil = np.load(dataload_folder + behavior_file, allow_pickle=False)\n",
    "        rawspeed = raw.item().get('speed')\n",
    "        speed = behaviorfil[:,1]\n",
    "        \n",
    "        sp = raw.item().get('sp')\n",
    "        spiket = sp['st'].copy()\n",
    "        cluster_id = sp['clu'].copy()\n",
    "        cell_IDs = raw.item().get('cellsfil')\n",
    "        posx = raw.item().get('posx')\n",
    "        post = raw.item().get('post')\n",
    "        \n",
    "        dt = np.unique(np.round(np.diff(post),4))\n",
    "        if len(dt) > 1: # discard duplicate frame entries if they occurred\n",
    "            dt = dt[dt != 0]\n",
    "            dt_to_trash = np.where(np.diff(post) == 0)[0]\n",
    "        else:\n",
    "            dt_to_trash = [] \n",
    "            \n",
    "        posxfil = behaviorfil[:,0]\n",
    "        trial = behaviorfil[:,2]\n",
    "        postfil = behaviorfil[:,3]\n",
    "        \n",
    "        # filter spikes & position frames by speed < 2cm/s or out of track limits \n",
    "        speed_to_trash = find(rawspeed < 2)\n",
    "        pos_to_trash = find((posx < 0) | (posx > 400))\n",
    "        trash_idx = np.unique(np.concatenate((dt_to_trash, speed_to_trash, pos_to_trash)))\n",
    "        keep_idx = np.setdiff1d(np.arange(len(rawspeed)), trash_idx)\n",
    "        \n",
    "        # find indices of spike corresponding to 8 x 50cm bins along the track based on filtered position\n",
    "        bin_idx = []\n",
    "        for i in range(n_bin):\n",
    "            if i == (n_bin - 1):\n",
    "                idx = np.where((posxfil >= bins[i]) & (posxfil <= bins[i + 1]))[0]\n",
    "            else:\n",
    "                idx = np.where((posxfil >= bins[i]) & (posxfil < bins[i + 1]))[0]\n",
    "            bin_idx.append(idx)\n",
    "        \n",
    "        #find start and end of the Block A trials\n",
    "        start_idx = (np.where(trial == 20)[0][0]).astype(int) # trial is zero-indexed, 20 full dark trials\n",
    "        end_idx = (np.where(trial == 79)[0][-1]).astype(int) # get indices of all 60 context_a trials that follow dark\n",
    "            \n",
    "        #calculate & save shuffled speed scores\n",
    "        shuffspeedscore = np.zeros((n_rep, len(cell_IDs)))\n",
    "        shuffspeedstabscore = np.zeros((n_rep, len(cell_IDs)))\n",
    "        shuffspatialacoherencescores = np.zeros((n_rep,len(cell_IDs)))\n",
    "        shuffsparsityascores = np.zeros((n_rep,len(cell_IDs)))\n",
    "\n",
    "        for n in tdqm(range(0, n_rep)):\n",
    "            \n",
    "            shuffspeed_score = []\n",
    "            shuffspeedstab_score = []\n",
    "            shuffspatialasparseness = []\n",
    "            shuffspatialacoherence = []\n",
    "            \n",
    "            B = np.zeros((len(rawspeed), len(cell_IDs))) # reset empty shuffled FR matrix\n",
    "            for i, c in enumerate(cell_IDs):\n",
    "                sdx = (np.where(cell_IDs==c)[0][0]).astype(int)\n",
    "                \n",
    "                #get actual spike times for each cell\n",
    "                st = spiket[cluster_id == c]\n",
    "                st = st[(st >= min(post)) & (st <= max(post))]\n",
    "\n",
    "                #get shuffle times\n",
    "                st_shuf = st - min(post)\n",
    "                total_time = max(post) - min(post)\n",
    "                add = np.random.uniform(0.02,total_time,1)\n",
    "                st_shuf = (st_shuf + add) % total_time\n",
    "                st_shuf = st_shuf + min(post)\n",
    "                                                        \n",
    "                #get unfiltered spike train\n",
    "                spike_ct = np.zeros_like(post)\n",
    "                spike_idx = np.digitize(st_shuf,post) #obs corresponding to where each shuffled spike occurs\n",
    "\n",
    "                idx, cts = np.unique(spike_idx, return_counts = True)\n",
    "                spike_ct[idx] = cts\n",
    "                B[:,i] = spike_ct\n",
    "\n",
    "                #check for & interpolate any missing values; smooth if necessary\n",
    "                if sum(np.isnan(B[:,i])) > 0:\n",
    "                    B[:,i] = get.nan_interp(B[:,i])  \n",
    "\n",
    "            #apply filter spike train by speed & posx errors\n",
    "            B = B[keep_idx,:]\n",
    "            atotal_time = max(postfil[start_idx:end_idx]) - min(postfil[start_idx:end_idx])\n",
    "            A = B[start_idx:end_idx, :]\n",
    "            aposxfil = posxfil[start_idx:end_idx]\n",
    "            \n",
    "            #convert spike train / instantaneous FR into smoothed & unsmoothed FR vectors\n",
    "            asmoothFR, _, asmoothocc = ps.tuning_curve(aposxfil, A, dt, b = 2, l=2, smooth=True, SEM=False, occupancy=True)\n",
    "            aFR, _ , _ = ps.tuning_curve(aposxfil, A, dt, b = 2, l=2, smooth=False, SEM=False, occupancy=True)\n",
    "\n",
    "            for i, c in enumerate(cell_IDs):\n",
    "\n",
    "                #calculate & store speed score for this cell's smoothed spike train\n",
    "                B[:,i] = gaussian_filter1d(B[:,i],sigma)\n",
    "                sscore, _ = stats.pearsonr(B[:,i],speed)\n",
    "                shuffspeed_score = np.append(shuffspeed_score,sscore)\n",
    "                \n",
    "                #calculate & store speed stability score for this cell's smoothed spike train\n",
    "                bin_pspikes = []\n",
    "                for j in range(n_bin):\n",
    "                    idx = bin_idx[j]\n",
    "                    psscore, _ = stats.pearsonr(B[idx,i],speed[idx])\n",
    "                    bin_pspikes = np.append(bin_pspikes, (psscore *  np.sum(B[idx,i])))\n",
    "                \n",
    "                sstabscore = np.sum(bin_pspikes) / np.sum(B[:,i])\n",
    "                shuffspeedstab_score = np.append(shuffspeedstab_score,sstabscore)\n",
    "                \n",
    "                #calculate sparsity with smoothed FR in Context A\n",
    "                meanFRsqr = np.square(np.mean(asmoothFR[:,i]))\n",
    "                products = []\n",
    "                for b in range(asmoothFR.shape[0]):\n",
    "                    binmeanFRsqr = np.square(asmoothFR[b,i])\n",
    "                    prob = asmoothocc[b,i]/atotal_time\n",
    "                    prod = prob * binmeanFRsqr\n",
    "                    products = np.append(products,prod)\n",
    "                asparsity = np.sum(products) / meanFRsqr\n",
    "                shuffspatialasparseness = np.append(shuffspatialasparseness,asparsity)  \n",
    "\n",
    "                # calculate spatial tuning coherence score with non-smoothed FR\n",
    "                neighbors = find8adjacentElements(aFR[:,i])\n",
    "                meanFR_neighbors = []\n",
    "                for b in range(aFR.shape[0]):\n",
    "                    meanFR_neigh = np.mean(neighbors[b])\n",
    "                    meanFR_neighbors = np.append(meanFR_neighbors, meanFR_neigh)\n",
    "                acoherence, _ = stats.pearsonr(aFR[:,i],meanFR_neighbors)\n",
    "                if math.isnan(acoherence):\n",
    "                    shuffspatialacoherence = np.append(shuffspatialacoherence,0)\n",
    "                else:\n",
    "                    shuffspatialacoherence = np.append(shuffspatialacoherence,acoherence)\n",
    "                    \n",
    "            shuffspeedscore[n,:] = shuffspeed_score #forms array (n_shuffreps, n_goodcells)\n",
    "            shuffspeedstabscore[n,:] = shuffspeedstab_score #forms array (n_shuffreps, n_goodcells)\n",
    "            shuffsparsityascores[n,:] = shuffspatialasparseness #forms array (n_shuffreps, n_goodcells)\n",
    "            shuffspatialacoherencescores[n,:] = shuffspatialacoherence #forms array (n_shuffreps, n_goodcells)\n",
    "            \n",
    "        #save scores for all cells in a session in nested lists    \n",
    "        d['shuffspeedscore'] = shuffspeedscore\n",
    "        d['shuffspeedstabscore'] = shuffspeedstabscore\n",
    "        d['shuffspatialacoherencescores'] = shuffspatialacoherencescores\n",
    "        d['shuffsparsityascores'] = shuffsparsityascores\n",
    "                      \n",
    "        #Get file names & save shuffled scores as npy files\n",
    "        shufinstspeedscore_file = 'shufinstspeedscore_' + m + '_' + s + '.npy'\n",
    "        shufspeedstabscore_file = 'shufspeedstabscore_' + m + '_' + s + '.npy'\n",
    "        shufsparsityascore_file = 'shufsparsityascores_' + m + '_' + s + '.npy'\n",
    "        shufspatialacoherencescore_file = 'shufspatialacoherencescores_' + m + '_' + s + '.npy'\n",
    "        \n",
    "        np.save(save_folder + shufinstspeedscore_file, d['shuffspeedscore'])\n",
    "        print('saved shuffled speed score data as npy file for mouse ' + m + ' session '+ s)\n",
    "        \n",
    "        np.save(save_folder + shufspeedstabscore_file, d['shuffspeedstabscore'])\n",
    "        print('saved shuffled speed stability score data as npy file for mouse ' + m + ' session '+ s)\n",
    "\n",
    "        np.save(save_folder + shufsparsityascore_file, d['shuffsparsityascores'])\n",
    "        print('saved shuffled Context A sparsity scores as npy file for mouse ' + m + ' session '+ s)\n",
    "\n",
    "        np.save(save_folder + shufspatialacoherencescore_file, d['shuffspatialacoherencescores'])\n",
    "        print('saved shuffled Context A spatial coherence scores as npy file for mouse ' + m + ' session '+ s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fecc98e",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Classify Speed Tuned & Spatial Cells among SM Sessions '''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2894f01",
   "metadata": {},
   "source": [
    "For SM sessions and RF sessions with dark trials, we also calculate the peakiness of the dark FR autocorrelation on each shuffle to differentiate grid from non-grid spatial cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eb4f98c",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Load in the Cohort B - D sessions only'''\n",
    "\n",
    "mice = np.setdiff1d(all_mice, cohorta_mice, assume_unique = True) # Cohorts B-D\n",
    "\n",
    "sessions = []\n",
    "for i, m in enumerate(mice):\n",
    "    idx = np.where(all_mice == m)[0][0]\n",
    "    sessions.append(all_sessions[idx])\n",
    "\n",
    "# Make a dict to hold data\n",
    "data = {}\n",
    "\n",
    "for session, m in zip(sessions, mice):\n",
    "    data[m] = {}\n",
    "    \n",
    "    for s in session:\n",
    "        data[m][s] = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f528b87d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e28e678d5cb494ea574a81ae0660858",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "123 86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Python\\AppData\\Local\\Temp\\ipykernel_9604\\2342781379.py:131: RuntimeWarning: invalid value encountered in divide\n",
      "  corr=np.correlate(xp,xp,'full')[len(x)-1:]/var/len(x)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e30e1a2c9574a3393392f85080669be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 38  73  78  80  86  93  94  95  97  99 101 102 103 104 105 109 110 111\n",
      " 115 116 118 121 122 125 127 128 132 133 135 139 141 143 145 147 149 150\n",
      " 151 152 153 154 155 158 159 161 162 171 177 178 216 217 220 229 241 259\n",
      " 271 274 276 288 290 438 439 442 446 447 450 451 452 455 468 476 477 480\n",
      " 481 483 496 497 500 559 596 615] 93.02 36.04\n",
      "saved shuffled max peak heights data as npy file for mouse A12 session 051822_record1\n",
      "saved grid cell boolean for spatial cells as npy file for mouse A12 session 051822_record1\n",
      "252 241\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a24b640267d348e0a6698a036c51e00d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  3   9  15  22  24  26  27  31  37  39  42  48  50  52  55  56  58  61\n",
      "  64  66  68  75  76  84  89  91  92  96  97  99 101 103 107 108 109 110\n",
      " 114 115 116 117 118 119 121 122 123 124 125 126 127 129 131 133 136 138\n",
      " 140 141 144 145 146 147 148 149 154 156 157 158 160 161 163 167 169 170\n",
      " 174 178 180 181 183 185 188 189 191 192 196 198 199 200 201 202 203 204\n",
      " 205 206 207 209 213 214 216 217 218 223 224 230 231 233 234 236 250 252\n",
      " 254 258 261 262 268 274 275 276 279 280 289 307 313 314 329 369 384 385\n",
      " 402 404 407 408 411 412 413 414 416 417 418 419 420 425 426 427 429 431\n",
      " 433 439 441 448 451 452 453 458 463 465 467 469 471 472 474 477 478 481\n",
      " 490 494 495 497 499 501 531 538 540 544 547 550 565 566 570 571 573 574\n",
      " 575 577 578 579 582 583] 77.18 50.82\n",
      "saved shuffled max peak heights data as npy file for mouse A12 session 051922_record2\n",
      "saved grid cell boolean for spatial cells as npy file for mouse A12 session 051922_record2\n",
      "119 128\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34b21482126e45d090e2c3e44f2050f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 16  34  40  42  43  54  55  58  59  61  62  64  66  69  70  71  75  76\n",
      "  77  81  82  84  85  87  88  91  92  93  94  96  97 100 101 102 103 106\n",
      " 107 117 125 127 131 145 172 179 181 184 194 198 206 212 220 228 284 285\n",
      " 286 289 292 294 296 297 298 299 301 302 304 305 306 308 328 342 343 353\n",
      " 354 362 365 366 376 381 383 384 387] 63.28 36.32\n",
      "saved shuffled max peak heights data as npy file for mouse A12 session 052022_record3\n",
      "saved grid cell boolean for spatial cells as npy file for mouse A12 session 052022_record3\n",
      "129 62\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e0349d6b0a64274b608a3a4e22e2144",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 15  17  20  30  32  54 156 162 184 187 189 226 241 259 274 275 300 312\n",
      " 313 323 333 351 363 470 473 487 546 572 579 585 594 596 602 603 615 634\n",
      " 635 649 726 730 754 771 773 812 894 899 908 926 927 928 929] 82.26 13.49\n",
      "saved shuffled max peak heights data as npy file for mouse A12 session 052122_record4\n",
      "saved grid cell boolean for spatial cells as npy file for mouse A12 session 052122_record4\n",
      "101 93\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97816d26ca9b4a86ab96a944a7e2c078",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 23  24  27  28  34  39  48  55  56  58  60  61  63  64  65  66  69  72\n",
      "  74  79  81  82  84  86  89  90  91  92  93  94  95  96 102 103 105 106\n",
      " 110 113 114 116 117 118 120 122 123 125 137 149 165 170 267 270 271 274\n",
      " 275 277 281 285 286 288 289 291 298 301 302 307 317 370 393 394 402 406\n",
      " 424 425 426 428 431 433 435 436 438 440 443] 89.25 42.35\n",
      "saved shuffled max peak heights data as npy file for mouse A12 session 052222_record5\n",
      "saved grid cell boolean for spatial cells as npy file for mouse A12 session 052222_record5\n",
      "63 32\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "720515dfcd0d45beb37f63a1c8d7e16e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 30  47  58  60  61  62  65  66  67  68  74  75  76  77  80  86  95  96\n",
      "  97  98 115 125 195 202 203 212 215 239 252 255 256 257 258 261 263 264] 112.5 39.13\n",
      "saved shuffled max peak heights data as npy file for mouse A12 session 052322_record6\n",
      "saved grid cell boolean for spatial cells as npy file for mouse A12 session 052322_record6\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59299e6a098941a4a535f9b86ed3f890",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "142 96\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c3ffaead904421a9c186989b26a0501",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  34  113  119  125  130  134  155  157  159  160  165  166  170  175\n",
      "  179  184  188  190  191  192  194  196  198  200  201  206  210  216\n",
      "  230  239  249  254  268  271  272  293  296  299  308  312  328  348\n",
      "  355  647  655  656  657  664  665  670  682  690  691  704  705  707\n",
      "  713  730  737  739  744  755  756  766  767  768  802  891  893  897\n",
      "  908  919  920  925  932  983 1040 1050 1058 1059 1061 1067 1068 1074\n",
      " 1080 1086 1087] 90.62 28.71\n",
      "saved shuffled max peak heights data as npy file for mouse A13 session 050522_record1\n",
      "saved grid cell boolean for spatial cells as npy file for mouse A13 session 050522_record1\n",
      "212 298\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26ca2b20fbb749ac8dc34ca0072dff64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  34   37   44   51   52   59   73   79   83   91   94  102  114  118\n",
      "  125  126  129  134  139  141  146  153  175  181  182  188  190  192\n",
      "  201  204  221  239  257  268  273  283  284  321  326  329  335  338\n",
      "  339  346  349  366  374  386  388  401  408  415  421  422  430  431\n",
      "  432  444  453  461  539  572  642  669  690  707  712  734  768  809\n",
      "  810  831  854  856  949  960  984  992 1339 1340 1342 1349 1361 1380\n",
      " 1384 1390 1404 1406 1418 1419 1425 1430 1445 1456 1457 1462 1478 1482\n",
      " 1491 1498 1636 1728 1771 1792 1854 1976 1981 2013 2021 2024 2033 2042\n",
      " 2059 2066 2103 2138 2153 2182 2222 2284 2311 2357 2358 2362 2364 2367\n",
      " 2409 2436] 42.95 18.16\n",
      "saved shuffled max peak heights data as npy file for mouse A13 session 050622_record2\n",
      "saved grid cell boolean for spatial cells as npy file for mouse A13 session 050622_record2\n",
      "179 269\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9943e962aa54dc6a0a93c5cae6f1df0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 38  49  54  61  69  70  85  95 101 106 110 117 118 119 127 130 135 137\n",
      " 140 143 146 156 157 158 163 166 168 172 174 177 180 181 182 189 200 202\n",
      " 213 215 218 223 226 237 239 241 242 249 250 251 253 260 261 264 265 272\n",
      " 277 279 288 296 298 302 305 307 310 312 321 322 330 335 336 343 349 354\n",
      " 357 367 379 395 397 404 413 414 420 421 426 429 433 436 437 443 444 471\n",
      " 513 514 516 517 520 521 528 530 534 544 549 562 575 579 586 593 594 606\n",
      " 608 612 613 617 624 629 639 642 657 708 716 738 740 768 772 773 776 777\n",
      " 779 787 790 795 796 798 799 801 802 803 805 808 809 813 814 816 817] 53.16 40.86\n",
      "saved shuffled max peak heights data as npy file for mouse A13 session 050722_record3\n",
      "saved grid cell boolean for spatial cells as npy file for mouse A13 session 050722_record3\n",
      "86 92\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae6451ad450440cfb531522c1c62824e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 13  28  44  48  49  52  59  60  64  68  71  73  77  88  93  95 110 115\n",
      " 135 137 139 148 149 151 164 165 173 176 178 187 188 189 192 194 197 202\n",
      " 205 206 211 224 279 288 290 292 298 319 342 343 358 364 383 386] 56.52 25.24\n",
      "saved shuffled max peak heights data as npy file for mouse A13 session 050822_record4\n",
      "saved grid cell boolean for spatial cells as npy file for mouse A13 session 050822_record4\n",
      "57 26\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4992a13868ef4fc9a36d5eeb5c3b46ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  6  15  19  35  37  48  50  52  97 105 116 118 126 140 142 211 284 290\n",
      " 316 322 385 401 408] 88.46 11.11\n",
      "saved shuffled max peak heights data as npy file for mouse A13 session 050922_record5\n",
      "saved grid cell boolean for spatial cells as npy file for mouse A13 session 050922_record5\n",
      "198 116\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7cc75b9991a442598d5a83e5dd5dfe86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  8  14  21  24  31  32  45  48  51  54  64  76  79  90  96 118 164 165\n",
      " 166 169 170 175 178 179 180 184 185 186 189 190 191 192 193 196 202 204\n",
      " 205 206 208 210 211 212 213 214 215 217 218 219 221 224 225 227 228 232\n",
      " 236 238 242 243 244 246 252 254 255 256 257 260 261 264 265 267 268 272\n",
      " 280 281 282 285 288 289 291 292 295 297 298 299 300 307 308 309 310 312\n",
      " 319 342 389 390 395 403 404 411 413 414 420 432 435 436 437 443 444 446\n",
      " 448 449 455 456 462 469 470 472 473 474 476 477 478 480 483 494 499 512\n",
      " 519 526 531 540 542 544 546 551 552 553 554 558 561 562 563 564] 122.41 47.65\n",
      "saved shuffled max peak heights data as npy file for mouse A13 session 051022_record6\n",
      "saved grid cell boolean for spatial cells as npy file for mouse A13 session 051022_record6\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e5ce5d50a78433db1ae9811a6a54c41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90 52\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "525c95ce77634a87bea00829d11be2bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  4  20  47  52  55  56  88  93  98 114 161 170 212 222 226 247 321 363\n",
      " 393 394 395 396 473 492 496 502 503 506 509 515 539 542 554 571 696 755\n",
      " 760] 71.15 12.67\n",
      "saved shuffled max peak heights data as npy file for mouse Y11 session 050522_record1\n",
      "saved grid cell boolean for spatial cells as npy file for mouse Y11 session 050522_record1\n",
      "266 146\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98765f64a0634cd8a83187d3e7147b9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  68  170  187  195  198  243  245  265  283  288  289  292  306  310\n",
      "  313  317  327  338  340  354  361  363  366  374  380  391  407  414\n",
      "  421  427  445  454  455  465  494  511  515  530  551  600  617  634\n",
      "  642  646  647  652  653  655  660  665  668  669  670  677  686  687\n",
      "  689  699  708  709  722  729  750  754  760  762  776  777  778  786\n",
      "  792  797  798  799  802  804  821  824  841  854  858  859  863  877\n",
      "  879  887  895  898  904  910  914  921  948  957  961  963  965  967\n",
      "  984  993  994  996  997 1008 1028 1042 1071 1146 1185 1190 1191 1192\n",
      " 1196 1199 1200 1211 1216 1232 1244 1249 1252 1266 1268 1317 1421 1460\n",
      " 1461 1477 1484 1488 1492 1500 1502 1503 1505 1515 1516 1518 1522 1530\n",
      " 1547 1569 1581 1589 1594 1610 1646 1651 1654 1658 1661 1662 1664 1671\n",
      " 1673 1711 1734 1786 1795 1805 1897 1909 1914 1917 1923 2015 2034 2041] 115.07 28.38\n",
      "saved shuffled max peak heights data as npy file for mouse Y11 session 050622_record2\n",
      "saved grid cell boolean for spatial cells as npy file for mouse Y11 session 050622_record2\n",
      "205 274\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1b1b21f9a0f4863b9e2919be3659d48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  27   61   64   80   85   86   89   92   93   98  107  124  128  131\n",
      "  161  166  172  177  180  183  187  195  203  208  217  222  235  239\n",
      "  246  252  268  269  277  278  279  283  291  296  301  304  306  307\n",
      "  311  314  315  316  324  325  327  354  357  371  376  393  395  402\n",
      "  407  414  424  427  438  443  461  462  463  470  488  491  498  499\n",
      "  509  526  556  560  594  596  626  647  713  744  757  758  759  762\n",
      "  768  770  775  780  784  790  793  794  801  803  806  808  816  822\n",
      "  833  835  839  843  845  849  853  858  863  870  880  890  892  902\n",
      "  940  959  966  986  988  989 1005 1006 1007 1009 1010 1018 1024 1042\n",
      " 1069 1084 1101 1137 1140 1151 1170 1214 1215 1217] 49.64 31.12\n",
      "saved shuffled max peak heights data as npy file for mouse Y11 session 050722_record3\n",
      "saved grid cell boolean for spatial cells as npy file for mouse Y11 session 050722_record3\n",
      "108 51\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fda280ab2ac541a68d5fa9f4c8747e81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  14   22   36   52   53   56   75   76   78   91   92   95   99  100\n",
      "  103  104  105  108  109  113  114  116  119  130  144  150  156  157\n",
      "  167  169  170  180  193  201  202  204  206  222  224  231  234  256\n",
      "  258  295  299  336  362  712  713  715  718  719  724  726  728  729\n",
      "  731  732  738  739  744  745  748  749  752  758  780  781  812  815\n",
      "  816  819  821  855 1032] 147.06 24.27\n",
      "saved shuffled max peak heights data as npy file for mouse Y11 session 050822_record4\n",
      "saved grid cell boolean for spatial cells as npy file for mouse Y11 session 050822_record4\n",
      "173 125\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e8e69e5f2054623975ddf07d4e1c7cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 38  88 126 155 166 168 188 189 190 197 198 199 204 209 215 219 220 234\n",
      " 238 248 250 288 291 307 313 315 317 318 342 347 357 374 379 380 382 385\n",
      " 388 399 401 408 418 425 427 440 445 451 452 471 472 543 547 552 557 561\n",
      " 579 586 597 606 634 639 646 667 676 677 685 688 689 691 695 701 705 706\n",
      " 711 714 716 721 726 787 797 806 807 817 824 836 846 862 873 878 886 891\n",
      " 915 918] 73.6 25.34\n",
      "saved shuffled max peak heights data as npy file for mouse Y11 session 051022_record6\n",
      "saved grid cell boolean for spatial cells as npy file for mouse Y11 session 051022_record6\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c20e564796cb418e9486e43f97f42386",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30 54\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8bb272a6c14746caa663d1ac355fb5cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 17  44  66  81 125 367 380 507 594 596 613 614 615 617 629] 27.78 11.03\n",
      "saved shuffled max peak heights data as npy file for mouse Y16 session 062222_record3\n",
      "saved grid cell boolean for spatial cells as npy file for mouse Y16 session 062222_record3\n",
      "86 6\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e1ddd6e2aaf43b8a8ade7c7c293d8b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 16  30  32  47  49  53  58  60  63  65  66  85  91 147 154 286 292 312\n",
      " 314 326 345 349 376 394 467 471 472 480 482 484 494 515 523 528 539] 583.33 15.56\n",
      "saved shuffled max peak heights data as npy file for mouse Y16 session 062322_record4\n",
      "saved grid cell boolean for spatial cells as npy file for mouse Y16 session 062322_record4\n",
      "1 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b04cdf454ab04ec781052daa21d3f8de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[] 0.0 0.0\n",
      "saved shuffled max peak heights data as npy file for mouse Y16 session 062522_record5\n",
      "saved grid cell boolean for spatial cells as npy file for mouse Y16 session 062522_record5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d79c93b951144a0e957cabd8ef118d4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26 59\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e09c1fcc9d744e8bca09b9012d1091f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 22  32  62  89 100 106 107 110 136 151 153 340 343 369 372 564] 27.12 11.03\n",
      "saved shuffled max peak heights data as npy file for mouse Y17 session 062822_record1\n",
      "saved grid cell boolean for spatial cells as npy file for mouse Y17 session 062822_record1\n",
      "49 111\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "871cc9476d4649509425d748ed742180",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 18  29  32  38  41  49  88 107 111 119 124 143 342 372 387 393 394 406\n",
      " 535 547 676 679 769 771 783 800] 23.42 14.69\n",
      "saved shuffled max peak heights data as npy file for mouse Y17 session 062922_record2\n",
      "saved grid cell boolean for spatial cells as npy file for mouse Y17 session 062922_record2\n",
      "41 63\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b04def1903b4a0bba04a1742c703711",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 11  17  19  20  21  22  26  27  30  36  39  45  48  52  57  62  63  64\n",
      "  67  72  76  78  84 107 110 121 383 391 393 395 403 406 410 478] 53.97 37.78\n",
      "saved shuffled max peak heights data as npy file for mouse Y17 session 063022_record3\n",
      "saved grid cell boolean for spatial cells as npy file for mouse Y17 session 063022_record3\n",
      "165 245\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f182fd3b54d742ada3c1d63cf04246ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  14   22   40   47   56   85   98  106  108  111  120  128  130  133\n",
      "  136  149  159  160  166  172  173  178  181  191  192  200  213  219\n",
      "  231  232  250  251  254  272  277  283  286  289  296  297  299  302\n",
      "  303  306  307  312  314  325  327  329  330  332  333  334  336  340\n",
      "  342  349  351  353  354  356  361  363  371  373  382  412  431  436\n",
      "  444  974  975  980  984  995 1018 1033 1035 1044 1056 1063 1068 1069\n",
      " 1100 1110 1112 1113 1115 1118 1127 1130 1143 1183 1210 1281 1308 1311\n",
      " 1383 1407 1409 1417 1418 1422] 42.45 28.73\n",
      "saved shuffled max peak heights data as npy file for mouse Y17 session 070122_record4\n",
      "saved grid cell boolean for spatial cells as npy file for mouse Y17 session 070122_record4\n",
      "140 215\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28244225f9804fc4a247be67abc294a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  35   46   49   52  145  155  171  177  180  196  204  213  218  221\n",
      "  236  241  242  243  253  257  258  260  263  273  275  278  285  293\n",
      "  295  297  298  299  316  321  323  324  325  332  333  337  354  368\n",
      "  389  456  460  464  478  640  657  660  676  682  699  700  701  706\n",
      "  707  711  719  722  728  729  731  738  742  744  749  750  751  753\n",
      "  754  756  757  776  805  807  840  843  849  929  931  971  981  983\n",
      "  984  990  997 1001 1005 1006] 41.86 28.04\n",
      "saved shuffled max peak heights data as npy file for mouse Y17 session 070222_record5\n",
      "saved grid cell boolean for spatial cells as npy file for mouse Y17 session 070222_record5\n",
      "112 177\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de34a767734f41fbaa5e9bbbe6551101",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 20  44  78  79  80  90 108 112 115 118 119 131 142 143 145 147 149 151\n",
      " 153 154 157 158 161 172 191 216 233 236 249 252 255 446 451 455 456 467\n",
      " 468 469 471 484 486 491 495 498 503 517 519 522 523 525 526 527 528 532\n",
      " 538 566 587 668 671 676 678 713 730 731 732] 36.72 28.89\n",
      "saved shuffled max peak heights data as npy file for mouse Y17 session 070322_record6\n",
      "saved grid cell boolean for spatial cells as npy file for mouse Y17 session 070322_record6\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ca4006a6a504fdca99721c1bd1e227c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "184 231\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fcd7f4b3097c4c368458ad4a8268fa9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  52   93  135  167  172  248  255  260  267  308  312  313  314  320\n",
      "  327  330  336  346  365  366  369  371  396  398  400  404  406  407\n",
      "  425  435  437  438  440  448  450  453  467  470  473  488  491  498\n",
      "  504  514  522  527  538  550  562  567  572  574  579  580  582  584\n",
      "  596  597  617  627  637  641  660  683  762  768  804  821  837  842\n",
      "  849  853  858  864  890  899  906  910  913  920  921  925  929  953\n",
      "  971  972  980  993  995  996  997 1001 1008 1012 1037 1159 1185 1198\n",
      " 1209 1216 1325 1327 1330 1338 1339 1345 1347 1356 1359 1360 1375 1390] 48.48 29.63\n",
      "saved shuffled max peak heights data as npy file for mouse Y18 session 062022_record1\n",
      "saved grid cell boolean for spatial cells as npy file for mouse Y18 session 062022_record1\n",
      "99 193\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96827d2eef3b482a815f0e5bee65bf9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 19  40  42  46  67  73  92  97  99 117 118 120 122 159 171 176 179 182\n",
      " 203 215 217 250 275 284 285 310 316 319 322 344 345 364 389 409 412 426\n",
      " 430 434 437 441 443 444 517 518 561 588 590 592 601 614 627 631 637 640\n",
      " 641 649 652 661 669 671 687 693 694 696 698 708 711 716 737 751 767 769\n",
      " 774 793 847 850 855] 39.9 27.21\n",
      "saved shuffled max peak heights data as npy file for mouse Y18 session 062122_record2\n",
      "saved grid cell boolean for spatial cells as npy file for mouse Y18 session 062122_record2\n",
      "95 202\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09a2c47687204fcba8cd9aa5b355831e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 17  24  31  33  40  42  53  56  59  66  69  72  79  88 100 101 102 122\n",
      " 128 134 138 141 142 176 183 185 187 189 191 198 200 207 210 213 220 243\n",
      " 254 259 282 289 408 411 425 426 441 442 443 444 445 447 452 458 460 462\n",
      " 469 470 486 488 493 499 508 523 527 532 548 563 568 572 576 579 586 600\n",
      " 608 613 618 629] 37.62 27.84\n",
      "saved shuffled max peak heights data as npy file for mouse Y18 session 062222_record3\n",
      "saved grid cell boolean for spatial cells as npy file for mouse Y18 session 062222_record3\n",
      "148 100\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8594faac10b4502be76e1ac1d32ee47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   6   15   17   24   35   49   50   63   78   81  108  114  118  137\n",
      "  140  151  161  175  176  193  209  231  234  236  281  294  295  301\n",
      "  312  334  369  399  402  407  421  436  461  477  507  522  524  540\n",
      "  542  545  555  556  563  577  589  598  623  627  630  656  658  685\n",
      "  731  749  758  788  855  879  895  907  971 1022 1037 1042 1047 1048\n",
      " 1054 1057 1060 1070 1075 1076 1081 1083 1085] 79.0 19.32\n",
      "saved shuffled max peak heights data as npy file for mouse Y18 session 062322_record4\n",
      "saved grid cell boolean for spatial cells as npy file for mouse Y18 session 062322_record4\n",
      "184 235\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec78bc7155d44fd4bfb5df84307f8a0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 23  42  43  45  50  51  56  76  77  91  99 105 106 117 120 121 125 126\n",
      " 129 134 136 137 140 142 145 148 150 151 154 156 159 162 167 168 177 179\n",
      " 182 184 186 187 189 200 204 208 209 210 212 213 214 218 220 222 223 225\n",
      " 229 231 232 233 237 245 270 274 276 278 281 282 283 289 299 300 318 319\n",
      " 321 322 344 349 353 354 366 370 382 383 395 397 399 438 440 453 469 480\n",
      " 483 484 486 494 497 498 505 506 512 516 519 520 524 530 534 541 553 562\n",
      " 563 580 585 592 605 610 646 650 651 652 655 659 663 666 670 674 682 685\n",
      " 687 692 707 709 715 716 718 720 721 722 725 727 733 735] 59.57 39.22\n",
      "saved shuffled max peak heights data as npy file for mouse Y18 session 062522_record5\n",
      "saved grid cell boolean for spatial cells as npy file for mouse Y18 session 062522_record5\n",
      "116 139\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85759b2cc4f44b63bdb68a1daf099127",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  6   7  16  18  25  26  33  37  43  44  47  54  58  62  63  64  70  73\n",
      "  74  77  82  85  91  92  95  99 100 101 106 111 112 113 114 115 134 135\n",
      " 143 145 146 154 159 169 171 184 201 216 231 249 265 288 290 298 302 320\n",
      " 323 325 372 375 377 380 382 386 387 388 390 393 395 400 401 412 414 415\n",
      " 419 423 424 437 440 448 453 462 475 490 494 526 545 547 548 549 550 553\n",
      " 569 570] 66.19 43.81\n",
      "saved shuffled max peak heights data as npy file for mouse Y18 session 062622_record6\n",
      "saved grid cell boolean for spatial cells as npy file for mouse Y18 session 062622_record6\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76b74dba139e4d359dcfb744e4b7d630",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "108 102\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c2bb9e4ff3c463c9e32f439f4dcb881",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  26   42   44   51   75   82   96   98  150  156  165  167  168  171\n",
      "  184  187  188  205  208  209  217  226  231  234  236  237  239  244\n",
      "  248  265  270  295  304  305  319  387  398  404  410  411  470  516\n",
      "  684  715  735  740  755  756  758  788  789  804  805  823  842  848\n",
      "  858  863 1016 1049 1050 1133] 60.78 25.2\n",
      "saved shuffled max peak heights data as npy file for mouse Y19 session 062822_record1\n",
      "saved grid cell boolean for spatial cells as npy file for mouse Y19 session 062822_record1\n",
      "97 106\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d002021624684b8bb407382b48fe99c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  18   19   49   65   69   72   76   77   84   98  100  106  116  125\n",
      "  137  138  182  205  221  258  264  279  287  293  297  303  862  869\n",
      "  877  881  886  888  890  891  893  930  949  955  958  964  968  969\n",
      "  973  974  977  978  981  996  997 1073 1079 1089 1124 1146 1178 1182\n",
      " 1186 1189] 54.72 22.14\n",
      "saved shuffled max peak heights data as npy file for mouse Y19 session 062922_record2\n",
      "saved grid cell boolean for spatial cells as npy file for mouse Y19 session 062922_record2\n",
      "81 78\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "263f41ba70704ef7bc3cbf2124b65b01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  11   18   43   51   56   67   70   73   75   87   94   95   98  106\n",
      "  107  111  113  116  128  137  140  153  154  158  184  196  222  230\n",
      "  240  241  256  316  323  583  586  590  631  635  640  663  667  903\n",
      "  917  981 1119 1197 1212 1257 1263 1265] 64.1 20.0\n",
      "saved shuffled max peak heights data as npy file for mouse Y19 session 063022_record3\n",
      "saved grid cell boolean for spatial cells as npy file for mouse Y19 session 063022_record3\n",
      "199 190\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95fd9728ebfb44aabd1bed28806169fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 23  31  34  47  69  77  78  90 104 108 113 116 120 121 133 135 136 138\n",
      " 140 147 153 158 159 165 168 174 177 183 185 187 188 189 192 195 200 201\n",
      " 202 203 204 205 214 216 217 219 227 230 231 233 234 236 237 238 241 243\n",
      " 247 250 251 252 258 259 260 261 269 273 275 276 284 285 286 287 293 294\n",
      " 295 299 300 302 304 306 317 318 337 340 341 343 360 361 370 377 381 387\n",
      " 395 397 405 409 411 416 421 424 432 433 435 439 440 443 446 449 450 452\n",
      " 518 532 533 538 543 544 545 553 569 570 575 576 577 584 587 589 590 594\n",
      " 597 598 599 601 604 609 613 619 620 622 626 627 639 640 651 654 664 669\n",
      " 701 709 723 724 732 734 757 773 776 780 781 784 811 814 819 847 849 858\n",
      " 866 874 877 878 880 881] 88.42 41.28\n",
      "saved shuffled max peak heights data as npy file for mouse Y19 session 070122_record4\n",
      "saved grid cell boolean for spatial cells as npy file for mouse Y19 session 070122_record4\n",
      "165 206\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94248293cdfa4f1dab81058c12f4181f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 11  15  18  24  25  37  55  68  71  73  85 109 123 124 136 137 140 142\n",
      " 143 144 158 161 163 171 174 187 188 198 201 204 205 208 217 219 220 224\n",
      " 228 229 230 232 239 241 244 249 250 251 262 267 268 269 277 281 287 288\n",
      " 289 291 296 321 325 326 363 368 381 385 386 406 412 413 422 425 427 428\n",
      " 438 495 507 508 527 540 541 542 547 550 556 567 570 572 576 582 583 585\n",
      " 587 593 595 600 602 603 609 610 612 614 615 617 619 635 636 643 652 659\n",
      " 667 673 682 687 695 759 761 764 767 771 775 778 779 787 789 791 793 794\n",
      " 811 837 842 848 849 850] 64.08 39.76\n",
      "saved shuffled max peak heights data as npy file for mouse Y19 session 070222_record5\n",
      "saved grid cell boolean for spatial cells as npy file for mouse Y19 session 070222_record5\n",
      "114 175\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "971017c36660433abdf7353c1c1e914b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 13  15  18  21  46  55  72  78  84  92 112 145 160 161 172 176 177 180\n",
      " 184 185 193 194 195 199 202 203 208 221 227 230 231 234 235 239 246 255\n",
      " 265 268 276 291 309 313 354 447 456 461 467 468 470 475 477 492 507 521\n",
      " 522 553 569 570 572 577 578 579 581 583 587 590 598 611 616 625 677 681\n",
      " 686 689 694 696 704 709 711 713 714 717 720 767 768 769 771 772 773] 50.86 33.21\n",
      "saved shuffled max peak heights data as npy file for mouse Y19 session 070322_record6\n",
      "saved grid cell boolean for spatial cells as npy file for mouse Y19 session 070322_record6\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e7b134089a9427da7521e970170443d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73 7\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "249a19a0da934c75b2fbed05a5e5119f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  1   2   6  24  25  28  40  43  49  64  69 133 152 160 169 177 200 209\n",
      " 214 353 395 398 409 477 522 549 554 563 599 605 612 655 766 772 798 880\n",
      " 885] 528.57 18.41\n",
      "saved shuffled max peak heights data as npy file for mouse Y9 session 051922_record2\n",
      "saved grid cell boolean for spatial cells as npy file for mouse Y9 session 051922_record2\n",
      "52 0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33255d300c714bb383c55c0f23ab5d8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Python\\Desktop\\GitHub\\CSHerb_agingmec\\pipeline\\process_spikes.py:289: RuntimeWarning: invalid value encountered in divide\n",
      "  firing_rate[:, :, c] = (firing_rate[:, :, c] - np.min(firing_rate[:, :, c]))/np.max(firing_rate[:, :, c] - np.min(firing_rate[:, :, c]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  36   64   94  116  188  200  209  210  213  419  483  494  501  505\n",
      "  526  543  558  570  737  858  897  963  975 1006 1007 1022] inf 23.85\n",
      "saved shuffled max peak heights data as npy file for mouse Y9 session 052022_record3\n",
      "saved grid cell boolean for spatial cells as npy file for mouse Y9 session 052022_record3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Python\\AppData\\Local\\Temp\\ipykernel_9604\\2286090294.py:175: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  print(cell_IDs[gridcell], np.round(100*np.sum(gridcell)/len(spatialcells),2), np.round(100*np.sum(gridcell)/len(cell_IDs),2))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee139c0ecfb743bdad426e8a5f1efddf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:/Users/Python/Desktop/LocalData/spatialcellsrf/spatialcell99_A14_083022_record1.npy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [45]\u001b[0m, in \u001b[0;36m<cell line: 18>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     66\u001b[0m FR \u001b[38;5;241m=\u001b[39m (np\u001b[38;5;241m.\u001b[39mreshape(FR, (n_trials\u001b[38;5;241m*\u001b[39mn_pos, n_cells)))\u001b[38;5;241m.\u001b[39mT\n\u001b[0;32m     68\u001b[0m \u001b[38;5;66;03m#load in spatial cells classified elsewhere\u001b[39;00m\n\u001b[1;32m---> 69\u001b[0m spatialcell99 \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mscoreload_folder\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mspatialcell99_file\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     70\u001b[0m spatialcell99 \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(spatialcell99)\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mbool\u001b[39m)\n\u001b[0;32m     71\u001b[0m spatialcells \u001b[38;5;241m=\u001b[39m cell_IDs[spatialcell99]\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\agingmec\\lib\\site-packages\\numpy\\lib\\npyio.py:405\u001b[0m, in \u001b[0;36mload\u001b[1;34m(file, mmap_mode, allow_pickle, fix_imports, encoding, max_header_size)\u001b[0m\n\u001b[0;32m    403\u001b[0m     own_fid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    404\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 405\u001b[0m     fid \u001b[38;5;241m=\u001b[39m stack\u001b[38;5;241m.\u001b[39menter_context(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mos_fspath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    406\u001b[0m     own_fid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    408\u001b[0m \u001b[38;5;66;03m# Code to distinguish from NumPy binary files and pickles.\u001b[39;00m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:/Users/Python/Desktop/LocalData/spatialcellsrf/spatialcell99_A14_083022_record1.npy'"
     ]
    }
   ],
   "source": [
    "''' Calculate Height at Max Peak Lag in Shuffled Dark FR Autocorrelation to Identify Grid Cells \n",
    "\n",
    "Requires a recording with a dark period. In my case, this will be cohort B (RF males) and SM mice. \n",
    "\n",
    "Expected run time: hours per session\n",
    "\n",
    "'''\n",
    "\n",
    "n_rep = 100 # number of shuffles\n",
    "track_length = 400 #cm\n",
    "b = 2 # cm / spatial bin\n",
    "n_dark = 20 #n dark trials\n",
    "lags = np.arange(0,801,1) # FR autocorrelation lag\n",
    "\n",
    "save_folder = 'C:/Users/Python/Desktop/LocalData/shuffscores/' #adjust path to match save folder\n",
    "dataload_folder = 'C:/Users/Python/Desktop/LocalData/filtered/'#adjust path to match output of Import & Filter\n",
    "\n",
    "for m, session in zip(mice,sessions):\n",
    "    for s in tdqm(session):\n",
    "        d = data[m][s]\n",
    "        \n",
    "        #load in data\n",
    "        rawdata_file = 'RAW_' + m + '_' + s + '.npy'\n",
    "        behavior_file = 'BEHAVIOR_' + m + '_' + s + '.npy'\n",
    "        spatialcell99_file = 'spatialcell99_' + m + '_' + s + '.npy'\n",
    "        spikes_file = 'SPIKES_' + m + '_' + s +'.npy'\n",
    "        \n",
    "        if m in cohortb_mice:\n",
    "            scoreload_folder = 'C:/Users/Python/Desktop/LocalData/spatialcellsrf/'\n",
    "        else:\n",
    "            scoreload_folder = 'C:/Users/Python/Desktop/LocalData/spatialcellssm/'\n",
    "        \n",
    "        raw = np.load(dataload_folder + rawdata_file, allow_pickle=True)\n",
    "        behaviorfil = np.load(dataload_folder + behavior_file, allow_pickle=False)\n",
    "        Y = np.load(dataload_folder + spikes_file, allow_pickle=False) #pre-filtered for speeds >2cm/s, position-corrected spikes, 20 ms timebins\n",
    "        \n",
    "        posxfil = behaviorfil[:,0]\n",
    "        trial = behaviorfil[:,2]\n",
    "        trials = np.unique(trial)\n",
    "        postfil = behaviorfil[:,3]\n",
    "        cell_IDs = raw.item().get('cellsfil')\n",
    "        \n",
    "        #get stuff you will need later to shuffle & re-filter spike times to confirm putative grid spatial cells\n",
    "        sp = raw.item().get('sp')\n",
    "        spiket = sp['st'].copy()\n",
    "        cluster_id = sp['clu'].copy()\n",
    "        posx = raw.item().get('posx')\n",
    "        post = raw.item().get('post')\n",
    "        rawspeed = raw.item().get('speed')\n",
    "        \n",
    "        dt = np.unique(np.round(np.diff(post),4))\n",
    "        if len(dt) > 1: # discard duplicate frame entries if they occurred\n",
    "            dt = dt[dt != 0]\n",
    "            dt_to_trash = np.where(np.diff(post) == 0)[0]\n",
    "        else:\n",
    "            dt_to_trash = [] \n",
    "\n",
    "        # filter spikes & position frames by speed < 2cm/s or out of track limits \n",
    "        speed_to_trash = find(rawspeed < 2)\n",
    "        pos_to_trash = find((posx < 0) | (posx > 400))\n",
    "        trash_idx = np.unique(np.concatenate((dt_to_trash, speed_to_trash, pos_to_trash)))\n",
    "        keep_idx = np.setdiff1d(np.arange(len(rawspeed)), trash_idx)\n",
    "        \n",
    "        #get dark-only, normalized, smoothed spatial map & reshape into continuous vector for each cell\n",
    "        FR, _ , _ = ps.tuning_curve_bytrial(posxfil, trial, Y, dt, b, smooth=True, normalize=True, occupancy=True)\n",
    "        stop_idx = np.where(trials == n_dark)[0][0]\n",
    "        FR = FR[:stop_idx,:,:]\n",
    "        n_trials = FR.shape[0]\n",
    "        n_pos = FR.shape[1]\n",
    "        n_cells = FR.shape[2]\n",
    "        FR = (np.reshape(FR, (n_trials*n_pos, n_cells))).T\n",
    "        \n",
    "        #find max autocorrelation peaks for all cells; store height & prom of most prominent peak\n",
    "        peak = [] # boolean if peak found\n",
    "        maxpeak_locs = [] #stored lag of max peak if peak exist\n",
    "        maxpeak_heights = [] # stored height of max peak, otherwise 0 if not exist\n",
    "        maxpeak_proms = [] # stored prominence of max peak, otherwise 0 if not exist\n",
    "        for i, c in enumerate(cell_IDs):\n",
    "            sdx = np.where(cell_IDs == c)[0][0]\n",
    "            autocorrelation = autocorr(FR[sdx,:],lags)\n",
    "            normauto = autocorrelation / autocorrelation[0]\n",
    "            peaks, properties = find_peaks(normauto, width = 10, height = 0.10, prominence = 0.15)\n",
    "            proms = properties[\"prominences\"]\n",
    "            heights = properties[\"peak_heights\"]\n",
    "\n",
    "            if peaks.size > 0:\n",
    "                peak = np.append(peak,1)\n",
    "                maxpeak_locs = np.append(maxpeak_locs, peaks[np.argmax(proms)])\n",
    "                maxpeak_heights = np.append(maxpeak_heights, heights[np.argmax(proms)])\n",
    "                maxpeak_proms = np.append(maxpeak_proms, proms[np.argmax(proms)])\n",
    "            else:\n",
    "                peak = np.append(peak,0)\n",
    "                maxpeak_heights = np.append(maxpeak_heights,0)\n",
    "                maxpeak_proms = np.append(maxpeak_proms,0)\n",
    "                \n",
    "        peak = peak.astype(bool)\n",
    "\n",
    "        # shuffle procedure to find max autocorrelation peak heights for any cells w/ peaks in regular autocorrelation\n",
    "        shuffmaxpeak_heights = np.zeros((n_rep, len(cell_IDs[peak])))\n",
    "        \n",
    "        for n in tdqm(range(0, n_rep)):\n",
    "            \n",
    "            shuffheights = []\n",
    "            B = np.zeros((len(rawspeed), len(cell_IDs[peak]))) # reset empty shuffled FR matrix\n",
    "            \n",
    "            for i, c in enumerate(cell_IDs[peak]):\n",
    "                sdx = (np.where(cell_IDs==c)[0][0]).astype(int)\n",
    "                \n",
    "                #get actual spike times for each cell\n",
    "                st = spiket[cluster_id == c]\n",
    "                st = st[(st >= min(post)) & (st <= max(post))]\n",
    "\n",
    "                #get shuffle times\n",
    "                st_shuf = st - min(post)\n",
    "                total_time = max(post) - min(post)\n",
    "                add = np.random.uniform(0.02,total_time,1)\n",
    "                st_shuf = (st_shuf + add) % total_time\n",
    "                st_shuf = st_shuf + min(post)\n",
    "                                                        \n",
    "                #get unfiltered spike train\n",
    "                spike_ct = np.zeros_like(post)\n",
    "                spike_idx = np.digitize(st_shuf,post) #obs corresponding to where each shuffled spike occurs\n",
    "\n",
    "                idx, cts = np.unique(spike_idx, return_counts = True)\n",
    "                spike_ct[idx] = cts\n",
    "                B[:,i] = spike_ct\n",
    "\n",
    "                #check for & interpolate any missing values; smooth if necessary\n",
    "                if sum(np.isnan(B[:,i])) > 0:\n",
    "                    B[:,i] = get.nan_interp(B[:,i])  \n",
    "\n",
    "            #apply filter spike train by speed & posx errors & get dark spatial map\n",
    "            B = B[keep_idx,:]\n",
    "            \n",
    "            #generate shuffle dark FR autocorrelation & find height at lag of max peak\n",
    "            FR, _ , _ = ps.tuning_curve_bytrial(posxfil, trial, B, dt, b, smooth=True, normalize=True, occupancy=True)\n",
    "            FR = FR[:stop_idx,:,:]\n",
    "            n_trials = FR.shape[0]\n",
    "            n_pos = FR.shape[1]\n",
    "            n_cells = FR.shape[2]\n",
    "            FR = (np.reshape(FR, (n_trials*n_pos, n_cells))).T\n",
    "            \n",
    "            for i, c in enumerate(cell_IDs[peak]):\n",
    "                autocorrelation = autocorr(FR[i,:],lags)\n",
    "                normauto = autocorrelation / autocorrelation[0]\n",
    "                preflag_height = normauto[maxpeak_locs[i].astype(int)]\n",
    "                shuffheights = np.append(shuffheights, preflag_height)\n",
    "                    \n",
    "            shuffmaxpeak_heights[n,:] = shuffheights\n",
    "            \n",
    "        #save scores for all cells in a session in nested lists    \n",
    "        d['shuffmaxpeak_heights'] = shuffmaxpeak_heights\n",
    "                \n",
    "        #Get file names & save shuffled scores, grid cell boolean for spatial cells as npy files\n",
    "        shufmaxpeak_heights_file = 'shufmaxpeak_heights__' + m + '_' + s + '.npy'\n",
    "        \n",
    "        np.save(save_folder + shufmaxpeak_heights_file, d['shuffmaxpeak_heights'])\n",
    "        print('saved shuffled max peak heights data as npy file for mouse ' + m + ' session '+ s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3394311",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Classify Grid vs. Non-Grid Spatial Cells in Cohort B - D Sessions '''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
